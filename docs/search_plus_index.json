{"./":{"url":"./","title":"首页","keywords":"","body":"EarthStudy 生而为人，学无止境。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 11:14:26 "},"golang/":{"url":"golang/","title":"GO语言","keywords":"","body":"GO语言 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"golang/base.html":{"url":"golang/base.html","title":"语法基础","keywords":"","body":"语法基础 Go语言只有值传递，地址（&）是指针（*）的值，指针是地址的变量 Go语言没有隐式类型转化 Go语言变量类型写在变量名后面 Go语言支持封装，不支持继承、多态；只有struct没有class var 包内、函数内 var aa int = 3 var ( aa int = 3 ss = ”kkk” bb = true ) var aa, ss, bb = 3, “kkk”, true 函数内 aa, ss, bb := 3, “kkk”, true 内建类型 bool, string (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr（指针）//(u)int根据操作系统32 64决定位数 byte（8位）, rune（32位） float32, float63, complex64, complex128 const const aa int = 3 const aa, ss, bb = 3, “kkk”, true const( cpp = iota //iota是自增值 _ python java javascript ) iota在const关键字出现时将被重置为0 const中每新增一行常量声明将使iota计数+1（注意在同一行计数不+1） 控制语句 if、for、switch、select 没有while，for即是while 遍历可使用 for i, v := range xxx { } 函数 func function_name( [parameter list] ) [return_types / return parameter list] { defer xxxx return x //若有返回参数名则无需return，直接给返回参数赋值 } Array 数组是值类型，，长度不同类型不同，赋值即拷贝，一般不直接使用数组 var variable_name [SIZE] variable_type variable_name = [SIZE] variable_type{v1, v2, v3} //SIZE为...时根据初始化元素的个数设置大小 Slice 声明： var s []Type //nil 空切片 初始化： m := []Type{ , , , , } m := make([]Type, len, cap) //len长度，cap可达最大长度 m := a[ s:e] //a可以是已有的slice或数组，前闭后开 //其中e不能大于数组的长度或slice的cap slice的len根据可读元素决定，cap根据开辟的内存决定 读取元素： m[n] //其中n不能超过len-1 遍历： for i, v := range s { } 操作： append( s1, v1, v2 ) //若cap不够会重新开辟一个内存，并赋值原值过去 append( s1, s2... ) //...将s2分解为一个个元素 copy(s1, s2) //只将覆盖s1 len范围内的值 len(s) //返回长度 cap(s) //返回可达最大长度 Map 声明： var m map[K]V //nil 初始化： m := map[K]V { k1 : v1 } m := make(map[K]V) //EmptyMap 读取： Map[K]=v value , ok := map[K] //若找不到键值 ok为false 遍历： for k, v := range m{ } 操作： delete(map , K) //删除对应键值 len(m) //获取元素数量 String、Rune len(string) 返回的是字节长度，可使用utf8.RuneCountString获得字符数量 range遍历string得到的是pos是字节坐标，不适合处理非unicode编码的字符，可先使用[]rune(string)转换后再遍历 结构体 声明： type StructName struct{ var1 int var2 *T } 初始化： var t StructName t = StructName { 1, nil } 使用new函数初始化： t = new(StructName) t.var1 = 1 t.var2 = nil 使用工厂创建函数初始化： func createStruct(var1 int) *StructName { return &StructName { var1, nil } //局部变量的地址也可以返回给别人用，内存分配在堆还是栈由编译器决定 } 为结构定义方法： // 指针接收者（要改变内容、结构过大、建议有指针接收者则保持一致性也使用指针接收者） func (StructName *t) funcname { } // 值接收者 func (StructName t) funcname { } 指针能直接调用方法，当做值来用 nil指针也可以调用方法 包 一个目录下文件只能有同一个包名 main包有一个可执行入口 结构体的方法必须放在同一个包内，但可在不同文件里 扩展系统类型或别人类型的方法： 定义别名，给要扩展的类型创建一个其他名字，再加方法 使用组合，将要扩展的类型放进自己的类型中 Duck Typing 描述事物的外部行为而非内部结构 -- 像鸭子走路，像鸭子叫，像鸭子就是鸭子 Go严格来说属于结构化类型系统，是类似duck typing（duck typing要动态绑定，Go没有） Python 运行时检查，需要注释来说明接口 C++ 使用模板实现，编译时检查，需要注释来说明接口 Java 没有duck typing，必须实现接口方法，无需注释 接口 接口由使用者定义+组合，实现者无需了解如何组合 接口变量： 接口变量包含 {指向的实现者的类型或类型指针，指向的实现者的值或指针} 接口变量可指向实现者的值，也可指向实现者的指针 接口变量蕴含一个指针，故几乎不需要使用接口的指针 若实现的方法是指针接收者，则接口变量必须指向实现者的指针 Type Assertion：将接口变量转换为指定实现者类型 v, ok := i.(int) //接口变量.(实现者类型/类型指针) Type Switch： 判断实现者类型/类型指针 switch v := i.(type) { case T1: // TODO case T2: // TODO } 表示任何类型： v := interface{} 常用接口： Stringer接口：相当于tostring Reader/Writer接口：文件的抽象 嵌入类型 当我们嵌入一个类型，这个类型的方法就变成了外部类型的方法，但是当它被调用时，方法的接受者是内部类型(嵌入类型)，而非外部类型。 函数式编程 函数体 = {局部变量，自由变量} 闭包 = 函数体 + 所有相关自由变量指向的值（递归） 斐波那契数列 为函数实现接口 defer 确保调用在函数结束（return或panic）时发生 参数在defer语句时计算结果 多个defer时，遵循后进先出 常用场景： Open/Close Lock/Unlock PrintHeader/PrintFooter error error接口用于实现自定义错误 type error interface{ Error() string } 判断错误类型，MyError为自定义错误类型 if dError, ok = err.(*MyError); !ok{ painc(\"unknown err\") } else{ //TODO } panic 尽量不要用 recover 在defer中使用recover()，来保护panic defer func(){ r := recover() // TODO }() 表格驱动测试 分离测试数据和测试逻辑 更详细的自定义出错信息 可部分失败 Go语言语法更易实现表格驱动测试 单元测试testing.T func TestTriangle(t *testing.T) { tests := []struct{ a, b, c int }{ {3, 4, 5}, {5, 12, 13}, {8, 15, 17}, {12, 35, 37}, {30000, 40000, 50000}, } for _, tt := range tests { if actual := calcTriangle(tt.a, tt.b); actual != tt.c { t.Errorf(\"calcTriangle(%d, %d); got %d; expected %d\", tt.a, tt.b, actual, tt.c) } } } 命令行运行： go test . 代码覆盖率： go test -coverprofile=c.out go tool cover go tool cover -html=c.out 性能测试testing.B func BenchmarkSubstr(b *testing.B) { s := \"黑化肥挥发发灰会花飞灰化肥挥发发黑会飞花\" for i := 0; i 命令行运行 go test -bench . 性能分析： go test -bench . -cpuprofile cpu.out go tool pprof cpu.out help web quit http测试： 1. 通过使用假的Request/Response response := httptest.NewRecorder() request := httptest.NewRequest( http.MethodGet, \"http://xxxxxxxxxx\", nil) 2. 通过起服务器 server := httptest.NewServer( http.HandlerFunc(f)) resp, _ := http.Get(server.URL) 文档 命令行运行 go doc 命令行指令帮助 go help doc 启动帮助文档服务器 godoc -http :6060 Example Example是另一种测试，也可运行 在给文档提供示例 func ExampleTypename_Funcname() { // 函数调用，期望的函数返回结果 } goroutine 协程Coroutine： 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟机层面的多任务，GO语言有自己的调度器 多个协程可能在一个或多个线程上运行 子程序是协程的一个特例 C++：Boost.Coroutine Java：不支持 Python：使用yield关键字、async def Go语言：goroutine go func() { // TODO runtime.Gosched(); //让出控制权 }() 任何加上go就能送给调度器运行 不需要在定义时区分是否是异步函数 调度器会在合适的点进行切换 切换点： I/O，select channel 等待锁 函数调用（有时） Runtime.Gosched() 以上只是参考，不能保证切换，不能保证在其他地方不切换 使用-race来检测数据访问冲突 go run -race xxxx.go channel 类似Python的yield 当一个channel的数据未传输成功时（未发、未收、无缓冲区），当前协程会阻塞等待 声明： var c chan int //可发可收 var c chan初始化： c := make(chan int) c := make(chan int, 3) //创建一个缓冲区大小为3的channel 操作： cGo语言channel基于CSP模型 “不要通过共享内存来通信；通过通信来共享内存”，可创建两个channel来完成双向发送数据 WaitGroup 利用WaitGroup判断协程工作是否完毕 var wg = sync.WaitGroup wg.add(1) //添加任务数 wg.done() //完成一个任务 wg.wait() //挂起等待所有任务完成 select 利用select来进行调度，实现非阻塞式获取channel数据，select中若case不可运行且没有default则阻塞直到有case可运行 select { case n:= 注：在select中使用Nil Channel时会直接跳过而非阻塞 时间channel： time.After(10 * time.Second) //倒计时 time.Tick(time.Second) //周期定时触发 传统同步机制 非CPS模型，在GO中尽量少使用 WaitGroup MuteX Cond http标准库 http.Get(“https://xxxxxxxxxxxxxx.com”) request, err := http.NewRequest(http.MethodGet, \"https://xxxxxxxxxxxxxxx.com\", nil) request.Header.Add(\"\",\"\") client := http.DefaultClient() client := http.Client{ xxx : xxx CheckRedirect : func(){ }, } client.Do(request) httputil.DumpResponse(resp, true) http调试： 浏览器访问 http服务地址/debug/pprof 命令行go tool pprof 服务地址/debug/pprof/profile获得30秒服务的CPU使用情况 结束后对话输入web 命令行go tool pprof 服务地址/debug/pprof/heap 获得服务的内存使用情况 结束后对话输入web 其他标准库 bufio log encoding/json regexp time string/math/rand 使用 godoc -http:6060 启动帮助文档服务器 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-26 16:50:57 "},"cryptography/":{"url":"cryptography/","title":"密码学","keywords":"","body":"密码学 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"cryptography/hash.html":{"url":"cryptography/hash.html","title":"哈希","keywords":"","body":"哈希 哈希函数 任意输入，固定输出，有效计算O(n) SHA-0： SHA-1：HASH160 SHA-2：HASH256、HASH512、HASH244、HASH384 SHA-3：Keccak RIPEMD：RIPEMD-128、RIPEMD-160、RIPEMD-256、RIPEMD-320 加密安全的哈希函数： 碰撞阻力（collision-resistance） 隐秘性（hiding） 谜题友好（puzzle-friendliness） 应用： 信息摘要（message diget） 承诺（commitment） com := commit(msg , nonce) verify(com , msg , nonce) 搜索谜题 安全哈希算法（Secure Hash Algorithm 256，SHA-256） 压缩函数（compression function）：接受固定长度，具有碰撞阻力的哈希函数 MD（Merkle-Damgard）变换：将接受固定长度的哈希函数变换为可接受任意长度 SHA256 算法输入报文的最大长度不超过2^64 bit，输入按512-bit 分组进行处理，产生的输出是一个256-bit 的报文摘要 将报文进行512位分组 + 488位补位 + 64位长度信息 = 512整数倍位数 初始化8个共256位常量缓存 A=0x6A09E667，B=0xBB67AE85，C=0x3C6EF372，D=0xA54FF53A， E=0x510E527F，F=0x9B05688C，G=0x1F83D9AB，H=0x5BE0CD19 处理512-bit（16 个字）报文分组序列。该算法使用了六种基本逻辑函数，由64步迭代运算组成。每步都以256-bit缓存值ABCDEFGH为输入，然后更新缓存内容，每步使用一个32-bit 常数值Kt和一个32-bit Wt 上图参与运算的都是32 bit的数，Wt是分组之后的报文，512 bit=32bit*16. Wt t=1,2..16 由每一组512位报文再分16组产生 Wt t=17,18,..,64 由前面的Wt按递推公式计算出来。Wt递推公式为： Kt t=1,2..64是已知的常数。 所有512-bit分组处理完毕后，对于SHA-256算法最后一个分组产生的输出便是256-bit的报文摘要 哈希指针（hash pointer）：一个指向数据存储位置及其位置数据的哈希值的指针 可应用于任何基于指针且不包含闭环的数据结构 区块链（block chain）：通过哈希指针建立的链表 防篡改日志 梅克尔树（Merkle trees）：通过哈希指针建立的二叉树 隶属证明，验证时间与空间与log(n)同级 排序梅克尔树 非隶属证明 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 12:26:00 "},"cryptography/signature.html":{"url":"cryptography/signature.html","title":"数字签名","keywords":"","body":"数字签名 (sk , pk) := generateKeys(Keysize) sig := sign(sk , message) isValid := verify(pk , message , sig) 可验证，不可伪造，签名算法随机性的良好来源，信息大小处理（签署哈希值） 椭圆曲线数字签名算法（ECDSA） 比特币使用ECDSA而非标准椭圆曲线“secp256k1” 需要使用良好随机来源（就算密钥完美无缺只在签名时使用了不良随机，也可能导致密钥泄露） 是单向加密函数，输入私钥获得公钥 ​ 个人密钥：256位 ​ 公钥（未压缩）：512位 ​ 公钥（压缩）：257位 ​ 待签名信息：256位 ​ 签名：512位 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 12:26:26 "},"bitcoin/":{"url":"bitcoin/","title":"比特币","keywords":"","body":"比特币 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"bitcoin/decentration.html":{"url":"bitcoin/decentration.html","title":"去中心化","keywords":"","body":"去中心化 比特币如何做到去中心化 去中心化 去中心化（Decentralization）：在一个分布有众多节点的系统中，每个节点都具有高度自治的特征。节点之间可以自有链接，形成新的连接单元。任何一个节点都可能成为阶段性的中心，但不具备强制性的中心控制模式。节点与节点之间的影响，会通过网络而形成非线性因果关系。这种开放式、扁平化、平等性的系统现象或结构，被称为去中心化。 没有一个系统是完全中心化（Centralization）或完全去中心化的，去中心化不是不要中心，而是由节点来自由选择中心、自由决定中心。简单地说，中心化的意思，是中心决定节点。节点必须依赖中心，节点离开了中心就无法生存。在去中心化系统中，任何人都是一个节点，任何人也都可以成为一个中心。任何中心都不是永久的，而是阶段性的，任何中心对节点都不具有强制性。 分布式共识 共识（consensus） 分布式共识协议（distributed consensus protocol） 在一个有n个节点的系统中，每一个节点都有一个输入值，其中一些节点具有故障，甚至是恶意的。一个分布式共识协议有以下两个属性： 输入值的中止必须经由所有诚实节点来确定 这个输入值必须由诚实节点来生成 比特币是一个点对点系统 比特币协议达成共识时直面两大障碍： 不完美的网络，例如信息延迟和节点死机 某些故意搞破坏的节点 拜占庭将军问题（Byzantine Generals Problem） 如果叛徒数量超过1/3，则无法达成统一的作战计划 不可能结果（Fischer-Lynch-Paterson） 在一定条件下（包括节点行为具有确定特征），甚至在只有一个缺陷的过程中，达成共识都是不可能的 Paxos算法协议 一方面做到不产生不一致结果；另一方面做出妥协：在一定条件下，协议会死机卡住，无法继续运行 以上三个问题都是针对分布式数据库的研究，而比特币打破了很多原来分布式数据库所做的假设。 比特币打破的假设： 引进了奖励的理念 包含随机性概念 使用区块链达成没有身份的共识 化名制（pseudonyity），缺少真实身份 隐性共识（inplicit consensus），共识协议有多个回合，每个回合随机选取一个节点提议下一个区块，其他节点通过隐性接受或拒绝，如果接受则在该区块之后接龙下去，如果拒绝则忽略该区块而选择曾经接受的区块然后接龙下去 新的交易被广播到所有节点之上 每个节点都将新的交易放进一个区块 在每个回合，一个随机的节点可以广播它的区块 其他节点可以选择接受这个区块，前提是如果区块里的交易都是正当的（有真的签名） 节点们可以把以上区块的哈希值放进自己的区块里，以此来表示他们对那个新区块的认可 可避免的攻击：窃取比特币、拒绝服务攻击、双重支付攻击（商家需通过多次确认交易来避免双重支付攻击，一般是6个确认） 孤块（orphan block）：被网络完全遗忘的链块 零验证交易（zero confirmation transaction）：在没有区块被创建之前就完成交易 诚实节点一般会延长最长有效分支 奖励机制与工作量证明 奖励机制 ：比特币创造的唯一途径 奖励一：区块奖励，每创建一个区块，可在该区块中加入一笔奖励交易，地址由区块创建者指定。最初奖励为50个比特币，每生成210000个区块，奖励减半，最终限制比特币上限为2100万个 奖励二：交易费，交易的制造者可以让交易输出值比输入值小，而第一个节点的区块创建者能将这个差额付到指定的地址中 工作量证明（proof of work） 核心理念是把随机选取节点改为根据节点占有某种资源的比例来选取节点，该资源是无法垄断的，比如计算能力 权益证明（proof of stake） 某种币的拥有量 工作量证明函数三个特性： 难于计算，挖矿成本高 可参数化成本，每产生2016个区块之后，所有节点会自动重新计算目标区域的比例大小，使得后续区块产生的时间间隔约为10分钟 易于证实，其他节点很容易就能验证随机数的正确性 比特币挖矿：解哈希谜题 H( nonce || prev_hash || tx || tx || … || tx ) 挖矿能力：哈希速度（哈希/秒） 比特币最小单位：1中本聪 = 0.00000001 BTC（1E-8） 总结 比特币的共识： 账本情况、拥有的比特币、系统规则都是通过共识表达的 区块链安全性 – 挖矿生态系统的健康程度 – 货币的价值 三者相互作用的自举过程（bootstrapping） 51%攻击： 成本极高，且开发者可升级比特币来应对，但51%攻击的存在本身就是大家对比特币信息的巨大威胁 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:17:48 "},"bitcoin/operation.html":{"url":"bitcoin/operation.html","title":"运行机制","keywords":"","body":"运行机制 比特币的运行机制 比特币的交易 一个交易包含： 比特币的来源 输出地址 输出地址可以是任意地址，可多个，可用于找零 地址转换：将比特币转入同一人的不同地址 有效验证：不需要从账本建立之初的交易开始核查，只需从引用的输出核查到账本最新记录 资金合并：同一人的两笔比特币收入同时作为输入，输出到他的一个地址中 共同支付：不同人的比特币作为输入同时作为输入，输出到收款人的地址中，需要多个签名 交易语法： 元数据 { “hash”:”0xxxxxx” “ver”:1, “vin_sz”:2 “vout_sz”:1, “lock_time”:0, “size”:404, 输入 “in”:[ { “prev_out”:{ “hash”:”1xxxxxx”, “n”:0 }, “scriptsig”:”...” } { “prev_out”:{ “hash”:”2xxxxxx”, “n”:0 }, “scriptsig”:”...” }, ] 输出 “out”:[ { “value”:”xxx”, “scriptPubKey”:”OP_DUP OP_HASH160 3xxxxxx OP_EQUALVERIFY OP_CHECKSIG” } ] } 输入总金额 – 输出总金额 = 记账交易费 根据目标地址区分的交易类型： 支付到公钥Hash，Pay-To-PubkeyHash Tx .（P2PKH Tx） 支付到脚本Hash，Pay-To-ScriptHash Tx .（P2SH Tx） 挖矿交易（coinbase） 比特币的脚本 可以为比特币支付设定条件 堆栈式编程语言（stack-based programming language），非图灵完备（避免无限循环） 和Forth语言有很多相似的地方 将输入脚本和输入比特币的前一笔交易的输出脚本链接起来，然后执行 一共只有256个指令，每个指令一个字节（目前15个不可用，75个保留） 包含其他语言里常见的基本指令（基本算数、逻辑语句、抛出错误、过早返回） 包含一个重要的特殊指令（CHECKISIG）可查证多个签名，该指令有一个缺陷即会返回一个没用的值，它要求堆栈的一个变量去储存然后忽略，这个缺陷也是比特币的一个特性 脚本在交易的时候执行 脚本分两类： 数据指令（<>），作用是把数据推到堆栈的最上面 工作码指令，用堆栈顶部的数据作为输入值，用来计算一个函数 比特币脚本的应用 销毁证明（proof of burn）：用于销毁比特币（防止资金被赎回） 使用OP_RETURN直接抛错 P2SH：对堆栈顶部数据进行哈希运算，核验哈希结果与另一个给定的哈希值一致，通过后将最顶层的数据重新解读为一系列指令，然后运行一次这些指令，此时堆栈中的其他数据作为脚本的输入值 P2SH简化了支付工作，收款方只需告诉付款方一个哈希值，无需付款方写入复杂的脚本；还提升了挖矿效率 第三方支付交易（escrow transation） 使用多重签名（MULTISIG）实现，加入第三方仲裁员，三人中有两人签名后资金才能被支取 场景：货到付款&见款发货&退款 绿色地址（green address） 即第三方银行（可以是交易所或者其他金融媒介）控制的账户，第三方银行保证不会双重支付，故收款人无需等待区块链的6次确认 绿色地址使用的越来越少，人们认为，对“银行”过分信任是有风险的 高效小额支付（efficient micro-payments） 使用多重签名（MULTISIG）实现，需要收款人和付款人两个签名才能完成交易，如此可允许短时间重复支付，收款人在所有支付结束后再签名完成交易，可减少交易次数（交易费），而重复支付没有签名的那些交易会被丢弃掉 步骤： 付款人创建一个交易到MULTISIG，金额为可能花费的最大金额，MULTISIG需要收付款两方的签名才能使用 在付款人发布步骤1的交易之前，要求收款人先发布一个从MULTISIG退款给付款人的交易，该交易的lock_time=t，t>0，即t时间后才计入区块链 在有退款交易的保证下，付款人发布步骤1的交易 付款人在每次需要小额支付的时候签名一个从MULTISIG到收款人的交易，金额为所有累计的费用，剩余金额转给付款人自己 消费结束时付款人签名最后一个交易，同时收款人在最后一个交易上签名 场景：手机流量提供商根据每分钟使用的流量计费 锁定时间 利用lock_time防止小额支付中的收款人一直不签名，而扣押了付款人的剩余比特币 lock_time是一个非零数值t，告诉矿工记账时候，要等到t时间之后才将交易记入区块链 智能合约 即无需通过法律或者仲裁机构来保护执行的普通合约， 比特币的特性能用脚本、矿工和交易验证来实现第三方托管协议或是小额支付 但比特币脚本语言的设计也有很多缺陷，有很多现实需求无法实现，因此需要像以太坊等实现了图灵完备的智能合约 比特币的区块 区块的哈希链，每个区块都有一个区块头部，里面有 一个哈希指针指向上一个区块（prev） 一个矿工可修改的“临时随机数”（nonce） 一个时间戳 一个点数（表示找到区块的难度） 梅克尔树（树状数据结构），把区块内所有交易的哈希值进行排列存储 梅克尔树中都有一个币基交易 币基交易（coinbase） 永远只有一个单一的输入与单一的输出 交易不消费之前交易输出的比特币，因此没有指针指向“上一交易” 输出的值 = 区块奖励 + 区块中所有交易费 币基交易的参数可以是任何数据，矿工可以放任何值进去 比特币的网络 泛洪算法（flooding algorithm）/八卦协议（gossip） 发起交易 传播给其他相连节点 节点接收到交易后进行核验 节点判断若交易池中没有该交易则放入交易池并继续传播给其他相连节点，否则中止传播 泛洪算法的效率偏低（比较大的区块需要30秒左右才能传播到大部分节点） 节点核验交易的四个关卡 交易验证，找到所有输入的前序交易的输出脚本来核验，确保所有结果都为真 检查是否有双重支付 检查是否已经被本节点接收过 只接收和传递在白名单上的标准脚本 上述检查都是非强制的 竞态条件（race condition）/紊乱情况：众多节点对哪些交易应该被纳入区块链产生分歧 该情况会被打包下一个节点的矿工打破 比特币网络大小：很难测量，因为随时都在变化。 往低说5000-10000节点永远在线并处理交易，往高说有100万个IP成为节点 存储空间需求：需要将整个完整的共识区块链存储下来，并将所有未被消费的比特币的完整列表放在内存中以便快速验证 轻量节点（lightweight nodes）/轻客户端/简单付款验证（Simple Payment Verification, SPV）: 不存储整个比特币区块链，而只存储它们关心的、需要核验的部分交易 依赖全节点去验证全部交易，但在矿工挖出来之前会做一些核验来确保这个区块不会被拒绝 限制与优化 更新协议：硬分叉、软分叉 硬分叉：新的特性会使前一版本的协议失效，网络上的节点根据其所运行的协议版本去扩展不同的区块链，分叉不会合并，该情况是比特币社区不能接受的 软分叉：新的特性让现有核验规则更加严格，这样老节点会接受所有区块，新的节点会拒绝一些，能避免永久分裂；可以说更新后的新交易和新区块在旧协议下是有效的，新协议是原协议的一个子集 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:58:56 "},"bitcoin/coin_storage.html":{"url":"bitcoin/coin_storage.html","title":"货币存储","keywords":"","body":"货币存储 如何储存和使用比特币 储存比特币就是储存与管理比特币私钥 三个目标：获取性、安全性、便利性 简单的本地设备储存 获取性、安全性差 一般会使用比特币钱包软件 地址使用Base58对二进制字符进行编码 交换地址一般使用字符串或QR二维码 虚荣地址（vanity address）：使用工具不停生成私钥，以达到含有个性化字符的地址（平均生成58的k次方次地址，k为个性化字符的个数） 特储存与冷储存 热储存：连入互联网，随时可以给冷储存转账 冷储存：不连入互联网，生成地址发送给热储存 第一种方法 分层确定性钱包（hierarchical deterministic wallet）：可让冷储存制造无限制的地址数量，一次性让热储存知晓所有地址 生成“密钥生成信息”和“地址生成信息”来代替“密钥”和“地址” 比特币使用的ECDSA支持分层密钥 生成分层确定性密钥需要两个随机数k、y 私钥生成信息：k、y 第i个私钥：xi = H( k || i ) +y 地址生成信息：k、gy 第i个公钥：gxi= g H( k || i ) · gy 第i个地址：H(gxi) 第二种方法 大脑钱包（brain wallet）：用一个可预测的算法把一个口令变成一对公钥/私钥，还可结合分层确定性钱包技术生成一整套地址和私钥 第三种方法 纸钱包：将密钥印在纸上，二维码或base58编码 第四种方法 防损硬件（tamper-resistant device） 密钥分存和密钥共享 密钥分存：将密钥转换成N个子密钥，只要获取K（K 若K=N，可以先生成N-1个随机数，然后最后一个子密钥就是原密钥与所有其他N-1个子密钥的异或 若K 门限密码（threshold cryptography） 门限签名（threshold signature） 可实现双重安全机制或多重安全机制 多重签名（multisignature） 可实现多人对共同财产实现共同控制 通过比特币脚本把一个比特币的控制权交给多个密钥 在线钱包和交易所 在线钱包：将密钥储存在云端（Coinbase、blockchain.info） 比特币交易所 和银行一样主要面临三大类风险： 挤兑 庞氏骗局 黑客入侵 银行有政府的监管： 最低准备金要求 投资类型、资金管理监管 提供必要保护 交易所的措施： 准备金证明（proof of reserve），证明其“至少”有多少准备金，交易所发起一笔收款人是自身的交易，之后用同一私钥为一条查询指令签名，这个查询指令是公正第三方随意发出的字符串 负债证明（proof of liabilities），证明其“至多”有多少存款，交易所构建一个梅克尔树（叶子节点为所有储户信息，每个节点增加一个金额字段，该字段显示最近两个子节点的金额之和），然后将根节点加密签名后广播 “准备金”（provision）协议，可提供偿付能力证明，无需披露总负债和总的存款准备金规模 准备金证明和负债证明会泄露很多私密信息，实际应用中用的很少 支付服务 支付服务一般流程： 客户购买 – 支付服务商提供比特币支付按钮 – 客户付款给支付服务商 – 支付服务商给商户发送支付凭证 – 客户购买成功 – 支付服务商定时结算指定货币给商户 该流程支付服务商几乎承担了所有风险 2015年初无需交易费默认条件： 交易小于1000个字节 所有输出为0.01BTC或更大 优先权足够高 优先权 = 所有（账龄x输入金额）的总和 / 交易规模 账龄 = 输入对应的上一笔交易到现在所经过的时间 2015年初交易费默认标准：每1000个字节需要支付0.0001BTC 货币兑换市场 简单的市场行为模型： P = TD/S P为比特币价格 T为比特币价格对应货币的交易量（每秒） D为比特币处于交易状态的时间间隔（暂时退出流通体系） S为比特币总量 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:00:23 "},"bitcoin/mine.html":{"url":"bitcoin/mine.html","title":"挖矿","keywords":"","body":"挖矿 矿工的任务 （一类是验证交易和区块，一类是和其他矿工竞争） 一类是和其他矿工竞争 监听交易广播 维护区块链网络和监听新的区块 组装一个备选区块 找到新区块对应的有效的随机数 先尝试头部的临时随机数，若试过所有32位可能的取值后仍然不能产生一个有效的哈希值，还可以改动币基里的随机数，但后者改动涉及到梅克尔树的更新，代价更大 2015年目标区域值为： 小于 0000000000000000172EC0000000000000000000000000000000000000000000 新区块被全网接受 获得利润 决定难度：每挖出2016个区块（约两周时间）则所有矿工自己重新计算一次难度 下一个难度 = 上一个难度 x 2016 x 10 / 产生上2016个区块所花费的分钟 挖矿所需硬件 挖矿设备： CPU挖矿非常困难 GPU的高吞吐量和高并行处理能力更适合用于挖矿，且大多数显卡支持超频，能家加快运算速度；OpenCL是一个可以使GPU进行非图像处理类工作的通用语言；但是GPU内置了很多与挖矿无关的硬件，同时还有耗电多、散热难等问题；GPU挖矿的运算速度仍然 现场可编程门阵列挖矿（Field-Programmable Gate Array,FPGA）+Verilog（硬件设计语言），优点是比GPU性能好、容易冷却，缺点是性能提升不大、一直超频导致报错和故障、算法优化难、采购搭建难，故短暂存在后便退出舞台 专用集成电路技术挖矿（ASIC），主导当今挖矿市场 大型专业挖矿中心，建立的三个重要因素：气候、电费、网络接入速度 新的另类币总会经历一个ASIC蜜月期（还没有ASIC的时期，个人参与挖矿的利润比较高） 能源消耗和生态环保 蓝道尔原理（Landauer’s principle）：任何一个不可逆转的计算都会消耗一定的能源 任何位移运算都会消耗一定量（kTln2）的焦耳 比特币的能源消耗： 内涵能源：设备的制造和运输消耗的能源，会越来越小 电能：根据蓝道尔原理，是不可避免的 冷却：一般也是利用电力，寒冷环境可以减少消耗 比特币的能耗预估： 自上而下：将所有区块奖励的收入都用于电费来计算 自下而上：利用算力除以矿机功效来计算 得到比特币挖矿大搞所耗电力为几百万瓦特（MW）的数量级 矿池 总的发现区块的期望值可以是泊松概率分布 矿池：一组矿工形成一个矿池共同进行挖矿，并指定同一个币基接受人，最终无论谁发现了有效区块，币基接受人都根据每个参与者所贡献的工作量按比例分配奖励 挖矿工分（mining shares）：那些接近目标值的区块 工分分红：矿工发送工分后，管理员马上对其支付奖励；对矿工最有利，管理员需要承担风险但也会收取更高的管理费用；矿工没有动力追求有效区块 按实际比例分红：当找到一个有效区块时，将奖励按矿工的实际工作量比例分配；降低了管理员的风险但要求管理员校验、计算和分配奖励；矿工有动力追求有效区块；矿池足够大时，发现有效区块的概率波动会相当低 获取有效区块模板（getblocktemplate，GBT）作为一种标准化的矿池协议放进了比特币改进方案（Bitcoin Improvement Proposal，BIP）中。一种被称为层（stratum）在实际中运用广泛 矿池跳换（pool hopping）：矿工通过切换矿池的方式提高自己的收益。例如在挖矿周期的早期（上一个区块刚刚被发现），在按实际比例分红的矿池中挖矿，只在周期的后期切换到一个工分分红模式的矿池 洗算力（laundering hashes）：大的挖矿机构通过同时参与多个不同的矿池来掩盖他们的真实规模 挖矿的激励和策略 挖矿策略： 需要包括哪些交易？默认选择交易费比较高的交易 在哪一个区块上进行挖矿？默认是在最长的那条区块链上继续挖下去 若两个不同的区块在同一时间被宣布发现，该如何做选择？默认选择最先被监听到的那个区块 什么时候宣布新的区块？默认立刻宣布 大部分矿工都选择了默认策略（default strategy）来挖矿 挖矿攻击 分叉攻击（forking attack）：利用分叉制造双重支付 设一个攻击者矿工掌握的比特币网络挖掘市场份额为ａ，如果ａ>0.5，很可能实现一个分叉攻击，拥有近乎50%算力的攻击者可能需要花很长时间，但算力超过50%越多，攻击就会越容易且越有效 可操作的对策：大家可以觉察到攻击，社区可以对此做出决定，即使分叉链更长也可以拒绝接受 这种攻击能摧毁比特币信心，使其没有价值，可被称为金手指攻击（Goldfinger attack）；攻击者可以做比特币空头交易或拥有大量竞争货币而获益 通过贿赂进行分叉攻击：系统外的贿赂、高奖励矿池、高额交易费 临时保留区块攻击（temporary block-whihholding attacks）：找到有效区块后不立刻宣布而是在新区快上继续挖矿，期望可以在其他矿工找到下一个区块之前连续找到两个有效区块，该行为称为自私挖矿（selfish mining） 惩罚分叉攻击（punitive forking）：宣布拒绝在包含来自该地址的交易的区块链上工作，若宣布者市场运算能力大，则其他矿工会为了避免自己的区块链被分叉而不将该交易放入区块链中 羽量级分叉攻击（feather forking）：当算力不足0.5时，通过宣布将会尝试分叉来封杀某个地址，若其他矿工相信你，也可能会为了避免自己的区块链被分叉而决定加入你的封杀行动 好的挖矿算法 挖矿解谜更精确的说法是“不完全哈希函数原像解谜”（partial hash-preimage puzzle） 一个好的解谜方案： 能够被及时验证 解谜难度可调整 给每个矿工按哈希算力的比例来获得谜底，即解谜是“无关过程”（progress free）的 上面也是比特币挖矿解谜的三大核心特征 永不枯竭的解谜库 谜题通过算法自动生成 反ASIC解谜 反ASIC解谜（ASIC-resistance puzzles）：抑制ASIC设备优势的解谜程序 刚性内存解谜（memory-hard puzzles）：一种需要大量的内存来计算的反ASIC解谜 Scrypt是一个刚性内存的哈希函数，先用随机数填充随机存取存储器（Random Access Memory，RAM）里的缓存空间，然后从这块内存区域里虚拟随机地读取（或更新）数据，同时要求整个缓存都存储在RAM里面，伪代码： def scrypt( N , seed ): V = [0]*N //初始化N长度的缓存区域 //往缓存区域里充满虚拟随机数 V[0] = seed For i = 1 to N: V[i] = SHA-256(V[i-1]) //然后从这个区域里虚拟随意地读取 X = SHA-256(V[N-1]) For i = 1 to N: j = X % N //根据X，选择一个随机的索引 X = SHA-256(X ^ V[j]) //根据X的索引来更新这个X return X 若不使用缓存V，时间复杂度为O(N2) 若使用缓存V，时间复杂度为O(N) 故只要N值足够大，就能确保使用内存是更快的选择 另外还可以只缓存一部分来平衡时间与内存：假设储存缓存区域V里的每个k排数据，则大致内存为N/k，SHA-256迭代计算次数为( k + 3 )N/2 Scrypt的一个局限性是需要用同样大小的内存来校验，增加了分叉攻击的风险 Scrypt在莱特币的实际应用由于N值较低中最终无法反ASIC 布谷鸟周期算法：于2014年提出，需要建立一个很大的哈希表来计算周期，但结果却可以通过发现一个相对小的周期来验证 X11：将11个不同的哈希函数结合在一起的反ASIC解谜方案，被应用在黑暗币（DASH）中，其反ASIC的方式并不科学 有效工作量证明 有效工作量证明：让比特币挖矿的工作量证明所消耗的能量对社会做出贡献 质数币（Primecoin）：被证明具有有效工作的系统，其工作量证明是为质数找到一个“坎宁安链” 坎宁安链（Cunningham chain）：k个质数的序列P1,P2,…,Pk，使得Pk = 2 Pi-1 + 1 质数币解谜算法： 三个关键参数m，n，k 对于解谜挑战x（上一个区块的哈希函数值），要找到一个长度为k的坎宁安链，其中第一个质数的位数是n，且它的前 m位数与x的前m位数相同（n>=m）；增加n的值可使问题难度指数型增长，增加k的值可使问题难度线性增长，m足够大使得知道前一个区块的值之前的预先计算没有意义 局限性是坎宁安链还没有实际的应用和解谜结果验证时间长 存储量证明（proof of storage）/可恢复性证明（proof of retrievabitlity）：一个需要本地存储大量数据用来运算的解谜算法 永久币（Permacoin）：用于共识机制的存储量证明方案 首先系统选择一个不变的有意义的大文件F，并用一个大型梅克尔树代表F，挖矿步骤如下： 矿工生成一个用于接受资金的公钥KM 矿工使用KM进行哈希运算生成的一个随机索引集，对应梅克尔树的区块集FM ⊆ F，区块数为k1 矿工存储FM到本地以实现挖矿（也可存储一部分，用运算时间换取存储空间） 矿工获得区块链前一个区块的哈希值s时，创建一个临时随机数n 矿工使用s、KM、n行哈希运算生成的一个随机索引集，对应k1个区块FM中的k2个区块FM, n（k2 最后矿工对n、FM, n进行SHA-256的哈希函数H( FM, n || n )运行，如果计算结果低于目标难度，则挖矿成功（与比特币相同） 校验结果步骤如下： 校验FM, n是由矿工的公钥KM和临时随机数n共同产生 通过梅克尔树检验FM, n中的每一个区块时正确的 校验H( FM, n || n )的值比目标难度要小（为何不把s放进哈希函数？） 若k2足够大，降低存储量带来的计算负担是指数型增长的，故矿工没法通过降低存储量来权衡成本；但太大的k2会增加校验结果的成本 若k1更小以为这挖矿更加民主化；但有能力存储更多的矿工没有动力存储多于k1的区块 反矿池解谜：不能外包的解谜算法 矿池依赖于比特币的两大技术特征： 矿工很容易通过工分来证明工作量（由于谜题本身就需要包含难度可调整的特征，故很难通过改变此特征来反矿池） 矿池成员可以容易地保证遵守规则并通过实际运算来寻找有效区块，最后让整个矿池受益 反矿池的方案有： “区块丢弃”攻击（block-discarding attack）：矿池成员在找到有效区块时不提交给管理员，而是直接丢弃 设计一个挖矿解谜算法使得“区块丢弃”攻击有利可图，从而抵抗矿池存在 奖励破坏：让分配奖励的过程无法可靠进行 设计一个挖矿解谜算法将私钥加入到运算中，如先用私钥对区块进行数字签名。在这种解谜算法下，解谜者即新铸币的控制者，管理员无法保证分配奖励的正常进行 争议：反矿池的解谜算法也许并不能抑制中心化，因为没有了矿池会让小矿工们不敢参与挖矿，只剩下大型挖矿团队 最理想的方案是小额度奖励每个找到低等难度解谜答案的矿工，让小矿工们在不需要组成矿池的前提下也能参与挖矿获利 权益证明和虚拟挖矿 虚拟挖矿（virtual mining）：直接将挖矿“算力”按比例分配给有权益证明的矿工，从而节省挖矿设备和能耗；理由是利益相关者会有强烈意愿成为系统的维护者 虚拟挖矿可以节省能源，同时也不会有ASIC 点点币（Peecoin）：于2012年启动，是第一个使用权益证明的另类币，它结合了工作量证明（PoW）与权益证明（PoS），“拥有量”以“币龄”为计价单位 币龄（Coin age）：币量x未被交易的时间 点点币区块中包含一种即能用于消耗币龄又能获得利息的交易，称为利息币（coinstake），利息币总和越大挖矿目标则越大，挖矿也越容易 权益的其他形式有： 权益证明：不考虑币龄，会让最有钱的参与者总是最容易挖矿 储量证明：用于铸造区块的货币会被冻结一定时间（与币龄的方案正好成镜像，矿工的收入都是来自不能使用货币去做其他事情的机会成本） 虚拟挖矿的缺点： “无利害关系问题”（nothing-at-stake problem）或“股权粉碎攻击”（stake-grinding attacks）：不像真实的算力，虚拟挖矿中的筹码可以同时用于两个挖矿，这就降低了矿工尝试分叉的成本 中心化的检查点、以太坊（Ethereum）的Slasher都是尝试解决上述问题的方案 检查点：用于给节点更新主链，更新由指定私钥签发 Slasher：在使用筹码挖矿时需要私钥签名这一前提下，若矿工使用相同的筹码去签署两个不连续的区块链，其他矿工可以在区块链上输入这两个签名，并拿走一部分筹码作为奖励 蓄力：虚拟挖矿可积蓄大量筹码进行一次剧烈的攻击 垄断：如果有一个拥有51%筹码的矿工持续挖矿，则会永远保持优势直到筹码慢慢接近100% Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:44:08 "},"bitcoin/apply.html":{"url":"bitcoin/apply.html","title":"应用","keywords":"","body":"应用 应用一：比特币作为一个只能被添加的记录 安全时间戳（secure timestamp）：在不披露具体内容的前提下，证明该内容于某时间点存在，并且这个证据具备永久性 实例： 专利、创意的优先权 工作完成的时间点 完全公钥签名方案，盖伊福克斯签名方案（Guy Fawkes signature scheme） 等… 方案： 将内容的哈希函数值作为输出地址，创建一笔微小交易 缺点是会产生永不能使用的比特币 承诺币（CommitCoin）：将内容的哈希函数值作为私钥，创建一个微小交易，随后再将交易分两次交易回来，两次交易的随机源相同（利用了ECDSA的不良随机源漏洞） 如此不会产生永不能使用的比特币 OP_RETURN交易 OP_RETURN，允许输出80字节 恶意用途：记录非法内容 附着币（overlay currencies）：利用比特币的共识机制，开发一种新币，将开发新币需要的所有数据写进比特币的区块链中；附着币的检查更依赖用户，故没有一个轻量级的SPV客户端 合约币（Counterparty）：一种比较优秀的附着币，功能更丰富比如智能合约、用户自定义货币等，API更丰富；但是，合约币有效率低和交易费规则受制于比特币的缺点 应用二：比特币作为一个“智能资产” 利用比特币具有可追溯性 染色币（Colored Coins）：在一个被称为“发行”的交易里，嵌入一些额外的元数据来宣布某些比特币具备了特定的“颜色”，这些比特币就成为了染色币；染色币交易后仍能追溯到发布 实例： 公司股票 有形资产交易 域名交易（有一种另类币叫域名币Namecoin是专门用于域名交易的） 等… 方案： 开放资产（OpenAsset）：利用P2SH发行，执行带有染色币的交易时必须嵌入一个有特殊标记的支出 应用三：比特币作为一个多方参与的安全博彩系统 可扩展为一个强大的系统模式：各自都有敏感数据的互不信任的一群参与者，共同来执行一个程序，不仅仅是为了控制数据，还可以控制与之关联的资金 假设三个参与者A/B/C，想以相同的概率选择一个号码1/2/3，最终与结果相同者获胜，则方案步骤为： 首先每个人选择一个大的随机数（x/y/z） 为了杜绝某人在知晓其他人的随机值后改变自己的数字，大家只发布随机数对应的哈希值（H(x)/ H(y)/ H(z)） 为了避免某人在知晓其他人的随机值后不公布自己的数字，所有参与者两两交换保证金： 例如A支付给特定脚本一笔交易作为A给B的保证金，输出脚本如下： scriptPubKey: OP_IF OP_CHECKSIGVERIFY OP_CHECKSIG OP_ELSE OP_CHECKSIGVERIFY OP_HASH OP_EQUAL OP_ENDIF 然后A和B同时签名将保证金支付给B，但交易的nLock_Time=t，t>0（所有人需要在t时间内公布自己选择的随机数） scriptSig: 1 A在公布x时，将保证金收回 scriptSig: x 0 同样方法B给A保证金 x/y/z都公布后，最终结果为(x+y+z)%3 应用四：比特币作为一个公共的随机源 密码学“信号塔”（cryptograph beacons）：提供公共随机源的服务，它源源不断在固定频率产生随机数，没人可以预测 方案： 在区块头部设置一个“随机数抽取器”（哈希函数），把所有的输入随机熵均匀压缩成一个随机字符串作为随机信号输出 缺点是不能精确定时，操纵信号所需的代价可能太低 实例： 抽奖：在比特币脚本中加入一个特殊的操作码来读取某一个（例如上一个区块或特定高度的区块）比特币信号塔的随机数，加上多回合的数据协议安全或有时效的函数，最后利用随机数将一个交易的输出分派到n个密钥中的一个，来达到抽奖的目的 应用五：比特币作为一个去中心化的预测市场和真实世界的数据源 预测市场方案： 未来币（Futurecoin） CreateMarket( event_id, arbitrator_key, num_outcomes ) BuyPortfolio( event_id ) TradeShares( … ) SellPortfolio( event_id ) CloseMarket( event_id, outcome_id ) 仲裁方案： 中心化仲裁员 多个仲裁员 用户投票 矿工投票 实时数据供给（真实数据的数据源） 现实密钥（reality keys）： 仲裁者制造出一组密钥，其中每个密钥签名一个事件的结果起到代表作用 仲裁者公布所有密钥的公钥 预测者们将各自的保证金发送到一个比特币输出 仲裁者公布正确结果对应的密钥的私钥 仲裁会面临复杂的难预料的实际情况 交易委托方案： 让矿工撮合两个交易，自己讲两者的差额留下作为交易费 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:53:56 "},"bitcoin/develop.html":{"url":"bitcoin/develop.html","title":"开发","keywords":"","body":"开发 区块链结构 魔法数 Magic no 区块大小 Blocksize ​ 区块头 Blockheader： ​ 版本号 Version ​ 前区块Hash值 hashPrevBlock ​ Merkle根节点Hash值 hashMerkleRoot ​ 时间戳 Time ​ 当前目标Hash值 Bits ​ 随机数 Nonce 交易数量 Transaction counter 交易 Transactions ​ 版本号 ​ 输入数量 ​ 输入列表 ​ 输出数量 ​ 输出列表 ​ 锁定时间lock_time 调用比特币API的方式 通过bitcoind-qt 通过bitcoind-cli 通过curl 通过语言库调用 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:56:22 "},"ethereum/":{"url":"ethereum/","title":"以太坊","keywords":"","body":"以太坊 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"ethereum/operation.html":{"url":"ethereum/operation.html","title":"运行机制","keywords":"","body":"运行机制 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"ethereum/solidity.html":{"url":"ethereum/solidity.html","title":"Solidity","keywords":"","body":"Solidity Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"ethereum/develop.html":{"url":"ethereum/develop.html","title":"开发","keywords":"","body":"开发 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/":{"url":"hyperledger/","title":"超级账本","keywords":"","body":"超级账本 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/operation.html":{"url":"hyperledger/operation.html","title":"运行机制","keywords":"","body":"运行机制 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/consensus.html":{"url":"hyperledger/consensus.html","title":"共识排序","keywords":"","body":"共识排序 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/ledger_storage.html":{"url":"hyperledger/ledger_storage.html","title":"账本存储","keywords":"","body":"账本存储 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/develop.html":{"url":"hyperledger/develop.html","title":"开发","keywords":"","body":"开发 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"network/":{"url":"network/","title":"网络安全","keywords":"","body":"网络 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"network/protocol.html":{"url":"network/protocol.html","title":"TCP/IP、UDP、HTTP协议","keywords":"","body":"TCP/IP、UDP、HTTP协议 OSI（Open System Interconnect）七层参考模型 物理层 – 数据链路层 – 网络层 – 传输层 – 会话层 – 表示层 – 应用层 网中各节点都有相同的层次 不同节点的同等层具有相同的功能 同一节点内相邻层之间通过接口通信 每一层使用下层提供的服务，并向其上层提供服务 不同节点的同等层按照协议实现对等层之间的通信 物理层协议： 负责0、1 比特流（0/1序列）与电压的高低、逛的闪灭之间的转换。规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性；该层为上层协议提供了一个传输数据的物理媒体，只是说明标准。 在这一层，数据的单位称为比特（bit）（注：bit和字节Byte，我们常说的1字节8位2进制即：1B=8bit）。属于物理层定义的典型规范代表包括：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45、fddi令牌环网。 数据链路层协议： 负责物理层面上的互联的、节点间的通信传输（例如一个以太网项链的2个节点之间的通信）；该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 在这一层，数据的单位称为帧（frame）。数据链路层协议的代表包括：ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等。 网络层协议： 将数据传输到目标地址；目标地址可以使多个网络通过路由器连接而成的某一个地址，主要负责寻找地址和路由选择，网络层还可以实现拥塞控制、网际互连等功能。 在这一层，数据的单位称为数据包（packet）。网络层协议的代表包括：IP、IPX、RIP、OSPF等。 传输层协议（核心层）： 传输层是OSI中最重要、最关键的一层,是唯一负责总体的数据传输和数据控制的一层； 传输层提供端到端的交换数据的机制，检查分组编号与次序，传输层对其上三层如会话层等，提供可靠的传输服务,对网络层提供可靠的目的地站点信息主要功能。在这一层，数据的单位称为数据段（segment）。主要功能： ①：为端到端连接提供传输服务。 ②：这种传输服务分为可靠和不可靠的,其中Tcp是典型的可靠传输,而Udp则是不可靠传输。 ③：为端到端连接提供流量控制,差错控制,服务质量(Quality of Service,QoS)等管理服务。 包括的协议如下： TCP：传输控制协议，传输效率低，可靠性强。 UDP：用户数据报协议，适用于传输可靠性要求不高，数据量小的数据。 DCCP、SCTP、RTP、RSVP、PPTP等协议。 会话层协议： 负责建立和断开通信连接（数据流动的逻辑通路），记忆数据的分隔等数据传输相关的管理。 表示层协议：将数据格式转换为标准格式 　　将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式；主要负责数据格式的转换，确保一个系统的应用层信息可被另一个系统应用层读取。具体来说，就是将设备固有的数据格式转换为网络标准传输格式，不同设备对同一比特流解释的结果可能会不同；因此，主要负责使它们保持一致。 应用层协议： ①：超文本传输协议HTTP：这是一种最基本的客户机/服务器的访问协议；浏览器向服务器发送请求，而服务器回应相应的网页。 ②：文件传送协议FTP：提供交互式的访问，基于客户服务器模式，面向连接 使用TCP可靠的运输服务。主要功能:减少/消除不同操作系统下文件的不兼容性。 ③：远程登录协议TELNET：客户服务器模式，能适应许多计算机和操作系统的差异，网络虚拟终端NVT的意义。 ④：简单邮件传送协议SMTP：Client/Server模式，面向连接。基本功能：写信、传送、报告传送情况、显示信件、接收方处理信件。 ⑤：DNS域名解析协议：DNS是一种用以将域名转换为IP地址的Internet服务。 ⑥：简单文件传送协议TFTP：客户服务器模式，使用UDP数据报，只支持文件传输，不支持交互，TFTP代码占内存小。 ⑦：简单网络管理协议（SNMP）: SNMP模型的4个组件：被管理结点、管理站、管理信息、管理协议。SNMP代理：运行SNMP管理进程的被管理结点。 ⑧：DHCP动态主机配置协议: 发现协议中的引导文件名、空终止符、属名或者空,DHCP供应协议中的受限目录路径名 Options –可选参数字段，参考定义选择列表中的选择文件。 TCP/IP（Transmission Control Protocol/Internet Protocol）协议 传输控制协议/因特网互联协议，又名网络通讯协议，是Internet最基本的协议、Internet国际互联网络的基础。包括 ARP，ICMP，IGMP，UDP，以及让域名访问成为可能的DNS，以及电脑/手机可以自动获取IP地址的DHCP，还有形形色色的应用层的协议如 HTTP / SMTP / FTP 等。 通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台电脑规定一个地址。 TCP/IP的四层模型： IP（Internet Protocol）协议 IP协议是将多个包交换网络连接起来，它在源地址和目的地址之间传送一种称之为数据包的东西，它还提供对数据大小的重新组装功能，以适应不同网络对包大小的要求。IP协议在OSI参考模型中应用于网络层，以“数据包（Package）”为单位。 IP协议特点 IP协议是一种无连接、不可靠的分组传送服务的协议。 IP协议是点-点线路的网络层通信协议。IP协议是针对原主机-路由器、路由器-路由器、路由器-目的主机之间的数据传输的点-点线路的网络层通信协议。 IP协议屏蔽了网络在数据链路层、物理层协议与实现技术上的差异。：通过IP协议，网络层向传输层提供的是统一的IP分组，传输层不需要考虑互联网在数据链路层、物理层协议与实现技术上的差异，IP协议使得异构网络的互联变得容易了。 IPV4 地址32位，数据报首部的长度是以4个字节为单位，长度可以是20-60字节，这跟首部的HLEN字段有关，格式如下： 首部长度：这个4位字段定义了数据报首部的长度，以4字节的字为单位。当首部没有选项时，首部长度位20字节；当这个字段值位最大值F时，首部长度最大为60字节。 服务类型：在最初这个字段有一部分用于定义数据报的优先级，剩下的一部分定义了服务类型。IETF已经改变了这个8位字段的解释，现在定义了一组区分服务。在这种解释种，前6位构成了码点（codepoint），最后两位未使用。当码点字段最右边的3位不全为0时，这6位定义了54种服务，低延时，高吞吐量等等。 总长度：这个16位字段定义了数据报总长度，其以字节为单位。故IPv4数据报总长度上限值位65536字节。注：为什么需要这个字段？在许多情况下，我们确实不需要这个字段值。但是有些情况下，封装在一个帧里的并不仅仅是数据报，还可能附加了一些填充。比如，以太网协议对帧的数据有最大值（1500字节）和最小值（46字节）的限制，当数据小于46字节时，数据将含有填充数据。 标识（identification）：这个16位字段标志了从源主机发出的一个数据报，这样就确定了数据报的唯一性。这样使得数据报被分片后，在到达终点时终点能根据标识号将同一个数据报的分片重新组装成一个数据报。 标志（flag）：第一位保留（未用），第二位为“不分片（do not fragment）”，第三位位“还有分片（more fragment）”。 分片偏移：这个13位字段表示的是分片在整个数据报中的相对位置。这是数据在原始数据报中的偏移量，以8字节位单位。 生存时间：这个8位字段用来控制数据报所经过的最大跳数（路由器），每经过一个路由器，这个字段数值都减1，减1后变位0时，路由器就丢弃这个数据报。 · 协议：这个8位字段定义了使用IPv4服务的高层协议，如TCP，UDP，ICMP，IGMP，OSPF等的数据都将被封装到IP数据报中。这个字段指明数据报必须交付给哪个最终目的协议。 检验和：检验IP数据报首部。 源地址：定义了源点的IP地址，这个字段始终保持不变。 目的地址：定义了终点的IP地址，这个字段始终保持不变。 IP地址分为A、B、C、D 、E五类，把32位的地址分为两个部分：前面的部分代表网络地址，后面部分是主机地址（局域网地址）。网络掩码(Netmask) 限制了网络的范围，1代表网络部分，0代表设备地址部分。A类保留给政府机构，B类分配给中等规模的公司，C类分配给任何需要的人，D类用于组播，E类用于实验。 A类地址： 1.0.0.1~126.155.255.254，以“0”开始，1字节网络地址3字节主机地址 10.X.X.X是私有地址（在互联网上不使用，而被用在局域网络中的地址） 127.X.X.X是保留地址，用做循环测试用的 默认子网掩码：255.0.0.0 B类地址： 128.0.0.1~191.255.255.254，以“10”开始，2字节网络地址2字节主机地址 默认子网掩码：255.255.0.0 172.16.0.0~172.31.255.255是私有地址 169.254.X.X是保留地址。如果你的IP地址是自动获取IP地址，而你在网络上又没有找到可用的DHCP服务器，就会得到其中一个IP C类地址： 192.0.0.1~223.255.255.254，网络地址的最高位必须是“110”，3字节网络地址1字节主机地址 192.168.X.X是私有地址 默认子网掩码：255.255.255.0 D类地址： 224.0.0.1~239.255.255.254，以“1110”开始，不分网络地址和主机地址，用于多点广播 E类地址： 240.0.0.1~255.255.255.254，以“11110”开始，不分网络地址和主机地址，将来使用 IPV6 地址128位， 冒分十六进制表示法： 格式为X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示 0位压缩表示法： 在某些情况下，一个IPv6地址中问可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中”::”只能出现一次。 内嵌IPv4地址表示法： 为了实现IPv4-IPv6互通，IPv4地址会嵌入IPv6地址中，此时地址常表示为：X:X:X:X:X:X:d.d.d.d 报文格式如下： TCP（Transmission Control Protocol）协议 TCP工作在网络OSI的七层模型中的第四层——Transport层（传输层），IP在第三层——Network层，ARP 在第二层——Data Link层。在第二层的数据，我们把它叫Frame（数据帧），在第三层的数据叫Packet（数据包），第四层的数据叫Segment（数据段）。 同时，我们需要简单的知道，数据从应用层发下来，会在每一层都会加上头部信息，进行封装，然后再发送到数据接收端。所以数据的发送和接收其实就是数据的封装和解封装的过程。 TCP报文格式： Source Port和Destination Port：分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程， 而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接； Sequence Number：用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的第一个数据 字节在数据流中的序号；主要用来解决网络报乱序的问题； Acknowledgment Number：32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志(下面介绍)为1时该确认序列号的字 段才有效。主要用来解决不丢包的问题； Offset：给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit(最多能 表示15个32bit的字，即4*15=60个字节的首部长度)，因此TCP最多有60字节的首部。然而，没有任选字段， 正常的长度是20字节； TCP Flags: TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次 为URG，ACK，PSH，RST，SYN，FIN。 URG：此标志表示TCP包的紧急指针域(后面马上就要说到)有效，用来保证TCP连接不被中断，并且督促 中间层设备要尽快处理这些数据； ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0； PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队； RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包； SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1， ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手； Window：窗口大小，也就是有名的滑动窗口，用来进行流量控制。这是一个复杂的问题，本文不再论述。 TCP协议的三次握手： 　　TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。如下图TCP的通信过程所示： 三次握手具体过程（状态）如下（其实可以类比打电话的过程：甲打电话，并等待接听→乙收到来电显示，“并表示可以接听”→“甲收到乙可以接听的信息”，甲接听电话。注：引号部分是打电话过程中没有的，但在TCP三次握手中存在）： 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认。（客户的建立连接并等待确认） 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段(即SYN+ACK报文段)中，一并发送给客户端，此时服务器进入SYN_RECV状态。（服务器端发送相关报文段信息并等待连接） 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。（客户的接收到服务端信息并实现连接） 　　然后，客户端和服务端就能实现正常的数据传输啦！ TCP协议的四次分手： 具体过程（状态）如下（同样也可以看做挂电话的过程：我说完了，挂？→我也说完了，挂吧？→好，拜拜→bye。简言之就是确认通信双方都交流完毕再确认断开连接）： 第一次分手：主机1(可以是客户端，也可以是服务器端)，设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了。（一方数据发送完成） 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我也没有数据要发送了，可以进行关闭连接了。（另一方数据发送完成） 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入CLOSE_WAIT状态。（请求关闭连接并等待） 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL（Maximum Segment Lifetime，“最长报文段寿命”）后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。（关闭连接） 现在，我们也应该理解为什么TCP协议是面向连接的、可靠的、基于IP协议的“通信控制协议”了。TCP的三次握手保证了数据的可靠性，保证资源不被浪费，而四次分手保证连接的可靠性而不至于随意断开连接，但TCP协议也由其可靠性，数据传输效率变得较低，而不像UDP那样进行实时快速传输。 UDP（User Datagram Protocol）协议 UDP （User Datagram Protocol的简称），用户数据报协议，是OSI参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，IETF RFC 768是UDP的正式规范。UDP在IP报文的协议号是17。 与TCP协议一样，UDP协议直接位于IP协议的顶层。根据OSI参考模型，UDP和TCP都属于传输层协议。UDP协议的主要作用是将网络数据流量压缩成数据包的形式。一个典型的数据包就是一个二进制数据的传输单位。每一个数据包的前8个字节用来包含报头信息，剩余字节则用来包含具体的传输数据。 UDP报文格式 与TCP协议不同，UDP协议是非面向连接的不可靠协议，因此没有了SYN等处理两端等待或连接的报文段，相比之下，UDP的报文格式更为简单，主要由报文头（由均16位的源端口号、目的端口号、UDP长度和UDP校验和组成）和具体传输数据组成。如图所示： UDP长度：UDP报文的整个大小，最小为8个字节（16*4位）（仅为首部）。 UDP检验和：在进行检验和计算时，会添加一个伪首部一起进行运算。伪首部（占用12个字节）为：4个字节的源IP地址、4个字节的目的IP地址、1个字节的0、一个字节的数字17、以及占用2个字节UDP长度。这个伪首部不是报文的真正首部，只是引入为了计算校验和。相对于IP协议的只计算首部，UDP检验和会把首部和数据一起进行校验。接收端进行的校验和与UDP报文中的校验和相与，如果无差错应该全为1。如果有误，则将报文丢弃或者发给应用层、并附上差错警告。 UDP特性 UDP是一个无连接协议，传输数据之前源端和终端不建立连接，当 UDP想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息。 UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小。 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制。 UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表（这里面有许多参数）。 UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。 虽然UDP是一个不可靠的协议，但它是分发信息的一个理想协议。例如，在屏幕上报告股票市场、在屏幕上显示航空信息等等。UDP也用在路由信息协议RIP（Routing Information Protocol）中修改路由表。在这些应用场合下，如果有一个消息丢失，在几秒之后另一个新的消息就会替换它。UDP广泛用在多媒体应用中，例如，Progressive Networks公司开发的RealAudio软件，它是在因特网上把预先录制的或者现场音乐实时传送给客户机的一种软件，该软件使用的RealAudio audio-on-demand protocol协议就是运行在UDP之上的协议，大多数因特网电话软件产品、聊天用的ICQ和QQ也都运行在UDP之上。 TCP协议和UDP协议的区别 1. 一般区别 TCP是面向连接的，传输数据保证可靠性和安全性；UDP协议是非面向连接的，是不可靠但高效率的协议。 TCP占用资源多而UDP占用少。 TCP是流模式而UDP是数据报模式。 TCP是面向连接的，用打电话的过程来类比，就是通信双方是互相明确的，所以进行的是“你一句我一句”的交流，TCP整个通信过程间有一个缓存区，由于通信主体明确，因此可以断断续续地进行交流，数据好比水流，知道源头和目的地，因此称为流模式。反过来，UDP是非面向连接的，好比写信的过程，假设我们只要知道佩奇的地址，我们就能写信给佩奇，而佩奇却不认识我们。这样发起通信方的身份是不明确的，每个发送端的信息都不能和别的发送端混淆，不然会造成数据失效，所以UDP要对数据进行“打包”发送，是面向报文的，就像写信需要用信封套起来，不然只发送数据甚至数据混合会变得毫无意义。 TCP和UDP的应用场景和编程方式也有很大差别。 2. TCP的粘包和UDP的丢包 TCP粘包现象：TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。 粘包原因： 发送端：TCP默认会使用Nagle算法。而Nagle算法主要做两件事：1）只有上一个分组得到确认，才会发送下一个分组；2）收集多个小分组，在一个确认到来时一起发送。所以，正是Nagle算法造成了发送方有可能造成粘包现象。 接收端：TCP接收到分组时，并不会立刻送至应用层处理，或者说，应用层并不一定会立即处理；实际上，TCP将收到的分组保存至接收缓存里，然后应用程序主动从缓存里读收到的分组。这样一来，如果TCP接收分组的速度大于应用程序读分组的速度，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包。 粘包处理：如果黏在一起的包是同一个整体，即同意部分数据分割而来的，那么就不用进行处理。如果是不同部分的数据粘到一起，就需要进行粘包解决： 发送端导致：使用TCP_NODELAY选项来关闭Nagle算法。 接收端导致：暂无。 统一解决（应用层）：可以解决接收方造成的粘包问题，还能解决发送方造成的粘包问题。 解决方法就是循环处理：应用程序在处理从缓存读来的分组时，读完一条数据时，就应该循环读下一条数据，直到所有的数据都被处理；但是如何判断每条数据的长度呢？ 两种途径： 　　1）格式化数据：每条数据有固定的格式（开始符、结束符），这种方法简单易行，但选择开始符和结束符的时候一定要注意每条数据的内部一定不能出现开始符或结束符； 2）**发送长度（推荐）**：发送每条数据的时候，**将数据的长度一并发送**，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以**根据长度来判断每条数据的开始和结束**。 UDP丢包现象：丢包现象即使用UDP发送时，由于不可靠连接方式，收到各种因素影响，数据包可能会在接受过程中丢失一部分，从而导致数据不完整。 UDP丢包原因： 发送端：发送的包太大导致send方法无法正常切割为小包导致丢包、发送的包太大超过缓存设置也会出现对包、发送频率太快导致接收端未接受或溢出缓冲区而丢包。 接收端：处理时间过长导致丢包。 其他：网络等问题。 UDP丢包处理： UDP的缺陷在于丢包和乱序问题，一般视情况进行处理，而发送的时候也需要注意上述导致丢包的问题。 HTTP（HyperText Transfer Protocol）协议 HTTP，超文本传输协议，是互联网上应用最为广泛的一种网络协议。所有的万维网WWW（World Wide Web）文件都必须遵守这个标准。 HTTP基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等） HTTP是一个属于应用层的面向对象的协议 HTTP协议工作于客户端-服务端架构为上 HTTP特点 HTTP是一个客户端和服务器端请求和应答的标准，通常，由HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接。HTTP服务器则在那个端口监听客户端发送过来的请求。一旦收到请求，服务器（向客户端）发回一个状态行。 HTTP协议的网页 HTTP协议的网页 HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。 通过HTTP或者HTTPS协议（HTTP协议+SSL协议）请求的资源由统一资源标示符（Uniform Resource Identifiers）（或者，更准确一些，URLs）来标识。HTTP有以下特点： 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 支持B/S及C/S模式。 HTTP的URL地址 URL（UniformResourceLocator，统一资源定位符）是一种特殊类型的URI，包含了用于查找某个资源的足够的信息，是互联网上用来标识某一处资源的地址。 URL的各部分组成： http://www.heyaguang.com:8080/EarthStudy/index.html?var1=1&var2=2#name 协议部分：一般为HTTP或Https，后接//作为分隔符。 域名部分：www.heyaguang.com为网站域名。 端口号部分：此网址为8080。跟在域名后面的是端口号，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口。 虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。 文件名部分：从域名后的最后一个“/”开始到后面一个“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.html”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名。 参数部分：从“？”开始到“#”为止之间的部分为参数部分。本例中的参数部分为“var1=1&var2=2”。不是必要部分。 锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分。 HTTP请求之request 客户端通过HTTP协议进行请求时遵循一定的格式，请看下面的请求报文格式（由请求行、请求头、空行、请求体组成）： 各部分组成如下所示： HTTP响应之response 在客户端发送请求后服务端进行响应，将信息发送给客户端，以实现功能服务，报文格式如下（包含状态行、响应头、空行、消息体）： HTTP状态码分类： 分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 HTTP状态码列表： 英文名称 中文描述 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-26 21:41:24 "},"network/byzantine.html":{"url":"network/byzantine.html","title":"拜占庭将军问题","keywords":"","body":"拜占庭将军问题 什么是拜占庭将军问题 “拜占庭将军问题”也被称为“拜占庭容错”，是Leslie Lamport（2013年的图灵讲得主）用来为描述分布式系统一致性问题（Distributed Consensus）在论文中抽象出来一个著名的例子： 拜占庭帝国想要进攻一个强大的敌人，为此派出了10支军队去包围这个敌人。这个敌人虽不比拜占庭帝国，但也足以抵御5支常规拜占庭军队的同时袭击。这10支军队在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少6支军队（一半以上）同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵骑马相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们才能保证有多于6支军队在同一时间一起发起进攻，从而赢取战斗？ 注：“ 拜占庭将军问题中并不去考虑通信兵是否会被截获或无法传达信息等问题，即消息传递的信道绝无问题。 通俗分析 先看在没有叛徒情况下，假如一个将军A提一个进攻提议（如：明日下午1点进攻，你愿意加入吗？）由通信兵通信分别告诉其他的将军，如果幸运中的幸运，他收到了其他6位将军以上的同意，发起进攻。如果不幸，其他的将军也在此时发出不同的进攻提议（如：明日下午2点、3点进攻，你愿意加入吗？），由于时间上的差异，不同的将军收到（并认可）的进攻提议可能是不一样的，这是可能出现A提议有3个支持者，B提议有4个支持者，C提议有2个支持者等等。 再加一点复杂性，在有叛徒情况下，一个叛徒会向不同的将军发出不同的进攻提议（通知A明日下午1点进攻， 通知B明日下午2点进攻等等），一个叛徒也会可能同意多个进攻提议（即同意下午1点进攻又同意下午2点进攻）。 叛徒发送前后不一致的进攻提议，被称为“拜占庭错误”，而能够处理拜占庭错误的这种容错性称为「Byzantine fault tolerance」，简称为BFT。 问题抽象 求解拜占庭将军问题，隐含要满足以下两个条件： 每个忠诚的将军必须收到相同的命令值vi（vi是第i个将军的命令）。 如果第i个将军是忠诚的，那么他发送的命令和每个忠诚将军收到的vi相同。 于是，拜占庭将军问题的可以描述为：一个发送命令的将军要发送一个命令给其余n-1个将军，使得： IC1. 所有忠诚的接收命令的将军遵守相同的命令；（一致性） IC2. 如果发送命令的将军是忠诚的，那么所有忠诚的接收命令的将军遵守所接收的命令。（正确性）　 Lamport对拜占庭将军问题的研究表明，当n>3m时，即叛徒的个数m小于将军总数n的1/3时，通过口头同步通信（假设通信是可靠的），可以构造同时满足IC1和IC2的解决方案，即将军们可以达成一致的命令。但如果通信是可认证、防篡改伪造的（如采用PKI认证，消息签名等），则在任意多的叛徒（至少得有两个忠诚将军）的情况下都可以找到解决方案。 而Fischer-Lynch-Paterson定理证明了，异步通信情况下，只要有一个叛徒存在，拜占庭将军问题就无解。翻译成分布式计算语言，在一个多进程异步系统中，只要有一个进程不可靠，那么就不存在一个协议，此协议能保证有限时间内使所有进程达成一致。 拜占庭将军问题在一个分布式系统中，是一个非常有挑战性的问题。因为分布式系统不能依靠同步通信，否则性能和效率将非常低。因此寻找一种实用的解决拜占庭将军问题的算法一直是分布式计算领域中的一个重要问题。 在这里，我们先给出分布式计算中有关拜占庭缺陷和故障的两个定义： 定义1：拜占庭缺陷（Byzantine Fault）：任何观察者从不同角度看，表现出不同症状的缺陷。 定义2：拜占庭故障（Byzantine Failure）：在需要共识的系统中由于拜占庭缺陷导致丧失系统服务。 在分布式系统中，不是所有的缺陷或故障都能称作拜占庭缺陷或故障。像死机、丢消息等缺陷或故障不能算为拜占庭缺陷或故障。拜占庭缺陷或故障是最严重缺陷或故障，拜占庭缺陷有不可预测、任意性的缺陷，例如遭黑客破坏，中木马的服务器就是一个拜占庭服务器。 在一个有拜占庭缺陷存在的分布式系统中，所有的进程都有一个初始值。在这种情况下，共识问题（Consensus Problem），就是要寻找一个算法和协议，使得该协议满足以下三个属性。 一致性（Agreement）：所有的非缺陷进程都必须同意同一个值。 正确性（Validity）：如果所有的非缺陷的进程有相同的初始值，那么所有非缺陷的进程所同意的值必须是同一个初始值。 可结束性（Termination）：每个非缺陷的进程必须最终确定一个值。 根据Fischer-Lynch-Paterson的理论，在异步通信的分布式系统中，只要有一个拜占庭缺陷的进程，就不可能找到一个共识算法，可同时满足上述要求的一致性、正确性和可结束性要求。在实际情况下，根据不同的假设条件，有很多不同的共识算法被设计出来。这些算法各有优势和局限。算法的假设条件有以下几种情况： 故障模型：非拜占庭故障/拜占庭故障。 通信类型：同步/异步。 通信网络连接：节点间直连数。 信息发送者身份：实名/匿名。 通信通道稳定性：通道可靠/不可靠。 消息认证性：认证消息/非认证消息。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-01 18:30:52 "},"network/consensus.html":{"url":"network/consensus.html","title":"共识算法","keywords":"","body":"共识算法 BFT：Byzantine Fault Tolerance，拜占庭容错技术 拜占庭容错技术（Byzantine Fault Tolerance，BFT）是一类分布式计算领域的容错技术。拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或中断以及遭到恶意攻击等原因，计算机和网络可能出现不可预料的行为。拜占庭容错技术被设计用来处理这些异常行为，并满足所要解决的问题的规范要求。 拜占庭容错技术来源于拜占庭将军问题。 在分布式系统中，特别是在区块链网络环境中，也和拜占庭将军的环境类似，有运行正常的服务器（类似忠诚的拜占庭将军），有故障的服务器，还有破坏者的服务器（类似叛变的拜占庭将军）。共识算法的核心是在正常的节点间形成对网络状态的共识。 通常，这些发生故障节点被称为拜占庭节点，而正常的节点即为非拜占庭节点。 拜占庭容错系统是一个拥有n台节点的系统，整个系统对于每一个请求，满足以下条件： 所有非拜占庭节点使用相同的输入信息，产生同样的结果； 如果输入的信息正确，那么所有非拜占庭节点必须接收这个信息，并计算相应的结果。 拜占庭系统普遍采用的假设条件包括： 拜占庭节点的行为可以是任意的，拜占庭节点之间可以共谋； 节点之间的错误是不相关的； 节点之间通过异步网络连接，网络中的消息可能丢失、乱序并延时到达，但大部分协议假设消息在有限的时间里能传达到目的地； 服务器之间传递的信息，第三方可以嗅探到，但是不能篡改、伪造信息的内容和验证信息的完整性。 原始的拜占庭容错系统由于需要展示其理论上的可行性而缺乏实用性。另外，还需要额外的时钟同步机制支持，算法的复杂度也是随节点增加而指数级增加。 PBFT：Practical Byzantine Fault Tolerance，实用拜占庭容错算法 实用拜占庭容错系统（PBFT）降低了拜占庭协议的运行复杂度，从指数级别降低到多项式级别（Polynomial），使拜占庭协议在分布式系统中应用成为可能。 PBFT是一种状态机副本复制算法，即服务作为状态机进行建模，状态机在分布式系统的不同节点进行副本复制。每个状态机的副本都保存了服务的状态，同时也实现了服务的操作。将所有的副本组成的集合使用大写字母R表示，使用0到|R|-1的整数表示每一个副本。为了描述方便，通常假设故障节点数为m个，整个服务节点数为|R| = 3m+1个，这里m是有可能失效的副本的最大个数。尽管可以存在多于3m+1个副本，但是额外的副本除了降低性能之外不能提高可靠性。 PBFT要求共同维护一个状态，所有节点采取的行动一致。为此，需要运行三类基本协议，包括一致性协议、检查点协议和视图更换协议。我们主要关注支持系统日常运行的一致性协议。一致性协议至少包含若干个阶段：请求（request）、序号分配（pre-prepare）和响应（reply）。根据协议设计的不同，可能包含相互交互（prepare），序号确认（commit）等阶段。 PBFT协议通信模式： 上图为PBFT协议通信模式，每一个客户端的请求需要经过5个阶段，通过采用两次两两交互的方式在服务器达成一致之后再执行客户端的请求。由于客户端不能从服务器端获得任何服务器运行状态的信息，PBFT中主节点是否发生错误只能由服务器监测。如果服务器在一段时间内都不能完成客户端的请求，则会触发视图更换协议。其中C为客户端，N0~N3表示服务节点，特别的，N0为主节点，N3为故障节点。整个协议的基本过程如下： 客户端发送请求，激活主节点的服务操作。 当主节点接收请求后，启动三阶段的协议以向各从节点广播请求。 序号分配阶段，主节点给请求赋值一个序列号n，广播序号分配消息和客户端的请求消息m，并将构造PRE-PREPARE消息给各从节点； 交互阶段，从节点接收PRE-PREPARE消息，向其他服务节点广播PREPARE消息； 序号确认阶段，各节点对视图内的请求和次序进行验证后，广播COMMIT消息，执行收到的客户端的请求并给客户端以响应。 客户端等待来自不同节点的响应，若有m+1个响应相同，则该响应即为运算的结果。 PBFT在很多场景都有应用，在区块链场景中，一般适合于对强一致性有要求的私有链和联盟链场景。例如，在IBM主导的区块链超级账本项目中，PBFT是一个可选的共识协议。在Hyperledger的Fabric项目中，共识模块被设计成可插拔的模块，支持像PBFT、Raft等共识算法。 Raft协议 动画版Raft讲解 模拟器 Raft是Paxos的一种实现或变种，是由Stanford提出的一种更易理解的一致性算法，意在取代广为使用的Paxos算法。目前，在各种主流语言中都有了一些开源实现，比如本文中将使用的基于JGroups的Raft协议实现。 Raft最初是一个用于管理复制日志的共识算法，它是一个为真实世界应用建立的协议，主要注重协议的落地性和可理解性。Raft是在非拜占庭故障下达成共识的强一致协议。 在区块链系统中，使用Raft实现记账共识的过程可以描述如下：首先选举一个leader，接着赋予leader完全的权力管理记账。leader从客户端接收记账请求，完成记账操作，生成区块，并复制到其他记账节点。有了leader简化了记账操作的管理。例如，leader能够决定是否接受新的交易记录项而无需考虑其他的记账节点，leader可能失效或与其他节点失去联系，这时，系统就会选出新的leader。 在Raft中，每个节点会处于下面三种状态中的一种： Follower：所有结点都以follower的状态开始。如果没收到leader消息则会变成candidate状态 Candidate：会向其他结点“拉选票”，如果得到大部分的票则成为leader。这个过程就叫做Leader选举(Leader Election) Leader：所有对系统的修改都会先经过leader。每个修改都会写一条日志(Log Entry)。leader收到修改请求后的过程如下，这个过程叫做日志复制(Log Replication)： 复制日志到所有follower结点(replicate entry) 大部分结点响应时才提交日志 通知所有follower结点日志已提交 所有follower也提交日志 现在整个系统处于一致的状态 term逻辑时钟： Term相当于paxos中的proposerID，相当于一个国家的朝代。term是一段任意的时间序号。每一任Leader都有一个与之前不同的term。 当Leader选举成功之后，一个节点成为了Leader，就会产生一个新的term，并且直到Leader故障，整个集群都会一直在这个term下执行操作。 如果leader选举失败了，则会再生成出一个term，再开启一轮leader选举。 Quorum多数派： 多数派，意思是超过一半的机器存活，则这个机器可用，这个Quorums指的就是集群可用的指标。例如：集群中的节点数为2N，如果有N+1的机器存活，则代表集群可用，可接受请求，写入log，应用到状态机中去，执行操作。如果少于N+1个机器存活，则代表集群可用，可接受请求，可写入log，但不应用到状态机中去，不执行操作。 Raft阶段主要分为两个，首先是leader选举过程，然后在选举出来的leader基础上进行正常操作，比如日志复制、记账等。 1. Leader Election 当follower在随机选举超时时间（randomize election timeout）内未收到leader的心跳消息，则转换为candidate状态。为了避免选举冲突，这个超时时间是一个150~300ms之间的随机数。 一般而言，在Raft系统中： 1. 任何一个服务器都可以成为一个候选者candidate，它向其他服务器follower发出要求选举自己的请求。 2. 投票要满足cadidate的term大于follower的term，或者两个term相等但cadidate的index大于follower的index。 3. 投票请求若满足条件则先到先得，后到的请求予以否决。 4. follower服务器同意了，发出OK。注意，如果在这个过程中，有一个follower宕机，没有收到请求选举的要求，此时候选者可以自己选自己，只要达到N/2+1的大多数票，候选人还是可以成为leader的。 5. 这样这个候选者就成为了leader领导人，它可以向选民也就是follower发出指令，比如进行记账。 6. 以后通过**心跳（heartbeat timeout）**进行记账的通知。 7. 一旦这个leader崩溃了，那么follower中会出现新的候选者，并发出邀票选举。follower同意后，其成为leader，继续承担记账等指导工作。 2. Log Replication Raft的记账过程按以下步骤完成： 1. 假设leader领导人已经选出，这时客户端发出增加一个日志的要求。 2. leader要求follower遵从他的**指令（Entry）**，都将这个新的日志内容追加到他们各自日志中。 3. follower服务器将交易记录写入账本后，返回确认追加成功的消息 4. leader接收到多数（**Quorums**）follower的回应后进行**提交（Commit）**处理，并向客户端发出确认成功信息。 5. 在下一个心跳中，leader会通知所有follower更新确认的项目。 对于每个新的交易记录，重复上述过程。 在这一过程中，若发生网络通信故障，使得leader不能访问大多数follower了，那么leader只能正常更新它能访问的那些follower服务器。而大多数的服务器follower因为没有了leader，他们将重新选举一个候选者作为leader，然后这个leader作为代表与外界打交道，如果外界要求其添加新的交易记录，这个新的leader就按上述步骤通知大多数follower。当网络通信恢复，原先的leader就变成follower，在失联阶段，这个老leader的任何更新都不能算确认，必须全部回滚，接收新的leader的新的更新。 安全性 Raft的安全性，体现在如下几个方面： Election safety：在一个term下，最多只有一个Leader。 Leader Append-Only：一个Leader只能追加新的entries，不能重写和删除entries。 Log Matching：集群中各个节点的log都是相同一致的。 Leader Completeness：如果一个log entry被committed了，则这个entry一定会出现在Leader的log里。 State Machine Safety：如果一个节点服务器的state machine执行了一个某个log entry命令，则其他节点服务器，也会执行这个log entry命令，不会再执行其他命令。 POW：Proof of Work，工作量证明 从去中心化账本系统的角度看，每个加入这个系统的节点都要保存一份完整的账本，但每个节点却不能同时记账，因为节点处于不同的环境，接收到不同的信息，如果同时记账的话，必然会导致账本的不一致，造成混乱。因此，需要有共识来达成哪个节点有权记账。比特币区块链通过竞争记账的方式解决去中心化的记账系统的一致性问题，即以每个节点的计算能力即“算力”来竞争记账权的机制。 在比特币（Bitcoin）系统中，大约每10分钟进行一轮算力竞赛，竞赛的胜利者，就获得一次记账的权力，并向其他节点同步新增账本信息。然而，在一个去中心化的系统中，谁有权判定竞争的结果呢？比特币系统是通过一个称为“工作量证明”（Proof of Work，PoW）的机制完成的。 简单地说，PoW就是一份确认工作端做过一定量工作的证明。PoW系统的主要特征是计算的不对称性。工作端需要做一定难度的工作得出一个结果，验证方却很容易通过结果来检查工作端是不是做了相应的工作。 举个例子，给定字符串“blockchain”，我们给出的工作量要求是，可以在这个字符串后面连接一个称为nonce的整数值串，对连接后的字符串进行SHA256哈希运算，如果得到的哈希结果（以十六进制的形式表示）是以若干个0开头的，则验证通过。为了达到这个工作量证明的目标，我们需要不停地递增nonce值，对得到的新字符串进行SHA256哈希运算。按照这个规则，需要经过2688次计算才能找到前3位均为0的哈希值，而要找到前6位均为0的哈希值，则需进行620969次计算。 1 blockchain1 → 4bfb943cba9fb9926df93f33c17d64b378d56714e8a29c6ba8bdc9690cea8e27 2 blockchain2 → 01181212a283e760929f6b1628d903127c65e6fb5a9ad7fe94b790e699269221 …… 3 blockchain515 → 0074448bea8027bebd6333d3aa12fd11641e051911c5bab661a9b849b83958a7…… 4 blockchain2688 → 0009b257eb8cf9eba179ab2be74d446fa1c59f0adfa8814260f52ae0016dd50f…… 5 blockchain48851: 00000b3d96b4db1a976d3a69829aabef8bafa35ab5871e084211a16d3a4f385c…… 6 blockchain6200969: 000000db7fa334aef754b51792cff6c880cd286c5f490d5cf73f658d9576d424 1. 工作量证明函数 及 区块数据计算过程 比特币系统中使用的工作量证明函数是SHA256。 比特币区块结构如下图所示： 比特币的区块由区块头及该区块所包含的交易列表组成。区块头的大小为80字节，由4字节的版本号、32字节的上一个区块的哈希值、32字节的Merkle根哈希值、4字节的时间戳（当前时间）、4字节的当前难度值、4字节的随机数组成。区块包含的交易列表则附加在区块头后面，其中的第一笔交易是coinbase交易，这是一笔为了让矿工获得奖励及手续费的特殊交易。 拥有80字节固定长度的区块头，就是用于比特币工作量证明的输入字符串。因此，为了使区块头能体现区块所包含的所有交易，在区块的构造过程中，需要将该区块要包含的交易列表，通过Merkle树算法生成Merkle根哈希值，并以此作为交易列表的哈希值存到区块头中。其中Merkle树的算法图解如下图所示。 　　 　　 上图展示了一个具有4个交易记录的Merkle树的根哈希值的计算过程。首先以这4个交易作为叶子结点构造一棵完全二叉树，然后通过哈希值的计算，将这棵二叉树转化为Merkle树。 首先对4个交易记录：Txa~Txc，分别计算各自的哈希值HA~HC，然后计算两个中间节点的哈希值HAB = Hash(HA+HB) 和 HCD = Hash(HC+HD)，最后计算出根节点的哈希值HABCD = Hash(HAB+HCD)。 而构造出来的简化的区块链结构如上图所示。We find that: 所有在给定时间范围需要记录的交易信息被构造成一个Merkle树，区块中包含了指向这个Merkle树的哈希指针，关联了与该区块相关的交易数据，同时，区块中也包含了指向前一区块的哈希指针，使得记录了不同交易的单个区块被关联起来，形成区块链。 2. 挖矿难度 挖矿难度值是比特币系统中的节点在生成区块时的重要参考指标，它决定了节点大约需要经过多少次哈希运算才能产生一个合法的区块。比特币的区块大约每10分钟生成一个，如果要在不同的全网算力条件下，新区块的产生都基本保持这个速率，难度值必须根据全网算力的变化进行调整。简单地说，难度值被设定在无论节点计算能力如何，新区块产生速率都保持在每10分钟一个。 难度的调整是在每个完整节点中独立自动发生的。每2016个区块，所有节点都会按统一的公式自动调整难度，这个公式是由最新2016个区块的花费时长与期望时长（期望时长为20160分钟，即两周，是按每10分钟一个区块的产生速率计算出的总时长）比较得出的，根据实际时长与期望时长的比值，进行相应调整（或变难或变易）。也就是说，如果区块产生的速率比10分钟快则增加难度，比10分钟慢则降低难度。　 这个公式可以总结为： 新难度值 = 旧难度值 × ( 过去2016个区块花费时长 / 20160分钟 ) 工作量证明需要有一个目标值。比特币工作量证明的目标值（Target）的计算公式：目标值=最大目标值/难度值 其中最大目标值为一个恒定值：0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF 目标值的大小与难度值成反比。比特币工作量证明的达成就是矿工计算出来的区块哈希值必须小于目标值。 3. PoW过程　 比特币PoW的过程，可以简单理解成就是将不同的nonce值作为输入，尝试进行SHA256哈希运算，找出满足给定数量前导0的哈希值的过程。而要求的前导0的个数越多，代表难度越大。比特币节点求解工作量证明问题的步骤大致归纳如下： 生成铸币交易，并与其他所有准备打包进区块的交易组成交易列表，通过Merkle树算法生成Merkle根哈希； 把Merkle根哈希及其他相关字段组装成区块头，将区块头的80字节数据作为工作量证明的输入； 不停地变更区块头中的随机数，即nonce的数值，并对每次变更后的区块头做双重SHA256运算（即SHA256（SHA256（Block_Header））），将结果值与当前网络的目标值做对比，如果小于目标值，则解题成功，工作量证明完成。 比特币的工作量证明，就是俗称“挖矿”所做的主要工作。 4. PoW能否解决拜占庭将军问题　 关于比特币PoW共识机制能否解决拜占庭将军问题一直在业界有争议。2015年，Juan Garay对比特币的PoW共识算法进行了正式的分析，得出的结论是比特币的PoW共识算法是一种概率性的拜占庭协议（Probabilistic BA）。Garay对比特币共识协议的两个重要属性分析如下。 一致性（Agreement） 在不诚实节点总算力小于50%的情况下，同时每轮同步区块生成的几率很少的情况下，诚实的节点具有相同的区块的概率很高。用数学的严格语言说应该是：当任意两个诚实节点的本地链条截取K个节点，两条剩下的链条的头区块不相同的概率随着K的增加呈指数型递减。 正确性（Validity） 大多数的区块必须由诚实节点提供。严格来说，当不诚实算力非常小的时候，才能使大多数区块由诚实节点提供。 可以看到，当不诚实的算力小于网络总算力的50%时，同时挖矿难度比较高，在大约10分钟出一个区块情况下，比特币网络达到一致性的概念会随确认区块的数目增多而呈指数型增加。但当不诚实算力具一定规模，甚至不用接近50%的时候，比特币的共识算法并不能保证正确性，也就是，不能保证大多数的区块由诚实节点来提供。 因此，比特币的共识算法不适合于私有链和联盟链。其原因首先是它是一个最终一致性共识算法，不是一个强一致性共识算法。第二个原因是其共识效率低。提供共识效率又会牺牲共识协议的安全性。另外，比特币通过巧妙的矿工奖励机制来提升网络的安全性。矿工挖矿获得比特币奖励以及记账所得的交易费用使得矿工更希望维护网络的正常运行，而任何破坏网络的非诚信行为都会损害矿工自身的利益。因此，即使有些比特币矿池具备强大的算力，它们都没有作恶的动机，反而有动力维护比特币的正常运行，因为这和它们的切实利益相关。 PoW机制存在明显的弊端。一方面，PoW的前提是，节点和算力是均匀分布的，因为通过CPU的计算能力来进行投票，拥有钱包（节点）数和算力值应该是大致匹配的，然而随着人们将CPU挖矿逐渐升级到GPU、FPGA，直至ASIC矿机挖矿，节点数和算力值也渐渐失配。另一方面，PoW太浪费了。比特币网络每秒可完成数百万亿次SHA256计算，但这些计算除了使恶意攻击者不能轻易地伪装成几百万个节点和打垮比特币网络，并没有更多实际或科学价值。当然，相对于允许世界上任何一个人在瞬间就能通过去中心化和半匿名的全球货币网络，给其他人几乎没有手续费地转账所带来的巨大好处，它的浪费也许只算是很小的代价有鉴于此，人们提出了权益证明（Proof of Stake，PoS）。 POS：Proof of Stake，股权证明 PoS类似于财产储存在银行，这种模式会根据你持有数字货币的量和时间，分配给你相应的利息。 简单来说，就是一个根据你持有货币的量和时间，给你发利息的一个制度，在股权证明PoS模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个PoS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(假定利息可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币，这下就很有意思了，持币有利息。 点点币（Peercoin）是首先采用权益证明的货币，点点币在SHA256的哈希运算的难度方面引入了币龄的概念，使得难度与交易输入的币龄成反比。在点点币中，币龄被定义为币的数量与币所拥有的天数的乘积，这使得币龄能够反映交易时刻用户所拥有的货币数量。实际上，点点币的权益证明机制结合了随机化与币龄的概念，未使用至少30天的币可以参与竞争下一区块，越久和越大的币集有更大的可能去签名下一区块。 然而，一旦币的权益被用于签名一个区块，则币龄将清为零，这样必须等待至少30日才能签署另一区块。同时，为防止非常老或非常大的权益控制区块链，寻找下一区块的最大概率在90天后达到最大值，这一过程保护了网络，并随着时间逐渐生成新的币而无需消耗大量的计算能力。点点币的开发者声称这将使得恶意攻击变得困难，因为没有中心化的挖矿池需求，而且购买半数以上的币的开销似乎超过获得51%的工作量证明的哈希计算能力。 权益证明必须采用某种方法定义任意区块链中的下一合法区块，依据账户结余来选择将导致中心化，例如单个首富成员可能会拥有长久的优势。为此，人们还设计了其他不同的方法来选择下一合法区块。 PoS机制虽然考虑到了PoW的不足，但依据权益结余来选择，会导致首富账户的权力更大，有可能支配记账权。股份授权证明机制（Delegated Proof of Stake，DPoS）的出现正是基于解决PoW机制和PoS机制的这类不足。 DPOS：Delegated Proof of Stake，委任权益证明 比特股（Bitshare）是一类采用DPoS机制的密码货币，它期望通过引入一个技术民主层来减少中心化的负面影响。 比特股的DPoS机制，中文名叫做股份授权证明机制（又称受托人机制），它的原理是让每一个持有比特股的人进行投票，由此产生101位代表 , 我们可以将其理解为101个超级节点或者矿池，而这101个超级节点彼此的权利是完全相等的。从某种角度来看，DPOS有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责（当轮到他们时，没能生成区块），他们会被除名，网络会选出新的超级节点来取代他们。DPOS的出现最主要还是因为矿机的产生，大量的算力在不了解也不关心比特币的人身上，类似演唱会的黄牛，大量囤票而丝毫不关心演唱会的内容。 比特股引入了见证人这个概念，见证人可以生成区块，每一个持有比特股的人都可以投票选举见证人。得到总同意票数中的前N个（N通常定义为101）候选者可以当选为见证人，当选见证人的个数（N）需满足：至少一半的参与投票者相信N已经充分地去中心化。 见证人的候选名单每个维护周期（1天）更新一次。见证人然后随机排列，每个见证人按序有2秒的权限时间生成区块，若见证人在给定的时间片不能生成区块，区块生成权限交给下一个时间片对应的见证人。DPoS的这种设计使得区块的生成更为快速，也更加节能。 DPoS充分利用了持股人的投票，以公平民主的方式达成共识，他们投票选出的N个见证人，可以视为N个矿池，而这N个矿池彼此的权利是完全相等的。持股人可以随时通过投票更换这些见证人（矿池），只要他们提供的算力不稳定，计算机宕机，或者试图利用手中的权力作恶。 比特股还设计了另外一类竞选，代表竞选。选出的代表拥有提出改变网络参数的特权，包括交易费用、区块大小、见证人费用和区块区间。若大多数代表同意所提出的改变，持股人有两周的审查期，这期间可以罢免代表并废止所提出的改变。这一设计确保代表技术上没有直接修改参数的权利以及所有的网络参数的改变最终需得到持股人的同意。 POA：Proof of Authority，权威证明 权威证明（Proof-of-Authority）或者PoA是一种算法。通过基于身份权益（identity as a stake）的共识机制，它可以提供更快的交易速率（与PoW相比）。这个术语是由以太坊（Ethereum）和Parity Technologies公司的联合创始人Gavin Wood创建的，并且目前用于Kovan——以太坊的测试网络（testnet networks）之一。 交易和块通过被批准的帐户（称为验证器）来验证。该过程是自动化的，并且激励被批准和被信任的验证者保持网络的安全性和一致性。 建立权威，必须满足三个主要条件： 必须在链上验证身份。 为了使验证过程有价值并提供足够的激励，应使资格很难获得。 建立权威时，在其检查和程序上必须具有完全的一致性。 使用案例 一个流行的利用PoA机制的区块链项目是 Oracle Network。作为一个基于以太坊的公共网络，它允许更快地执行智能合同（Smart Contract），并使用受尊敬的个人共识，使区块链对于从小商家到大企业的每个人来说,都是负担得起的而且是可访问的。 此外，还有一个正在使用PoA机制进行新代币开发和交易速度提升的新项目。Lindax是一个去中心化平台，用于交易与创造定制化的数字资产，是Go & CPP 以太坊的一个分支。当公司在LindaX网络上创建代币时，它们还将帮助确认交易的有效性，从而减少在区块链上的不当行为，同时消除消耗性成本。 RPCA：Ripple Protocol consensus algorithm，瑞波协议共识算法 Ripple（瑞波）是一种基于互联网的开源支付协议，可以实现去中心化的货币兑换、支付与清算功能。 基本概念 服务节点（Rippled）：可以接收交易的区块链节点，包括追踪节点和验证节点。客户端应用提交交易请求给服务节点（Rippled），服务节点以最近验证过的帐本为依据进行交易检查，检查通过的交易进入候选交易集合。 追踪节点（tracking node）：主要功能是分发交易信息以及响应客户端的账本请求。 验证节点（validating node）：被其它节点接入到信任列表中的节点，除包含追踪节点的所有功能外，还参与共识过程。 区块用于记录交易，在RPCA中有两种区块比较关键： 最新关闭区块（Last Closed Ledger）：也就是最新被共识过的区块 开放区块：也就是当前正在被共识的区块，当开放区块被共识过，也就成了最新关闭区块 信任节点列表UNL（unique node list）：每个服务节点都会维护一个信任节点列表，这里信任并不是指信任每一个节点， 而是指信任这个列表中的节点不会联合起来作弊。在共识过程中，我们只接受来自信任节点列表中的节点投票。在Ripple中，使用配置文件中加入其它验证节点的公钥的方式来制定UNL。 RPCA共识过程 Ripple网络每隔几秒就会产生一个新的区块，这个区块的产生过程就是所有网络节点RPCA共识的过程。假设共识过程是成功的，并且网络中没有分叉产生，那么新生成的区块就是全网唯一的 整个RPCA共识过程分为如下两个阶段： 交易共识，形成交易集 区块打包，再共识 1. 交易共识，形成交易集 每个验证节点会不断收到从网络发送过来的交易，通过与本地账本数据验证后，不合法的交易直接丢弃，合法的交易将汇总成交易候选集（candidate set）。交易候选集里面还包括之前共识过程无法确认而遗留下来的交易。 每个验证节点把自己的交易候选集作为提案发送给其他验证节点。 验证节点在收到其他节点发来的提案后，如果不是来自UNL上的节点，则忽略该提案；如果是来自UNL上的节点，就会对比提案中的交易和本地的交易候选集，如果有相同的交易，该交易就获得一票。在一定时间内，当交易获得超过50%的票数时，则该交易进入下一轮。没有超过50%的交易，将留待下一次共识过程去确认。 验证节点把超过50%票数的交易作为提案发给其他节点，同时提高所需票数的阈值到60%，重复步骤3、步骤4，直到阈值达到80%。 验证节点把经过80%UNL节点确认的交易正式写入本地的账本数据中，称为最后关闭账本。 2. 区块打包，再共识 形成交易集后，每个节点开始打包新的区块，打包区块的过程如下： 把当前区块号、共识交易集的Merkle树根Hash、父区块Hash、当前时间戳等内容放到一起，计算一个区块哈希。 每个节点广播自己得出的区块哈希到它可见的节点，这里的可见节点不仅仅指可信列表中的节点，而是通过节点发现过程能发现的节点。 节点收集到它所有可信列表中节点广播过来的区块哈希后，结合自己生成的区块哈希，对每个区块哈希计算一个比例，如果某一哈希的比例超过一个阈值（一般是80%），则认为这个哈希是共识通过的区块哈希。如果自己的哈希与之相同，则说明自己打包的区块得到了确认，是新的被共识过的区块，直接存到本地，并且更新状态。如果自己的哈希与共识通过的哈希不同，那就需要去某个区块哈希正确的节点索要新的区块信息，要到之后存储到本地并且更新当前状态。 如果上面没有对某一区块哈希超过设定的阈值，那么重新开始共识过程，直到满足条件。 验证 正确性 RPCA中正确性的验证方式很简单，因为共识需要80%的阈值，那么只要UNL中有80%的诚实节点，就能达成共识，另外即使有超过20%的欺诈节点，也不能破坏正确性，因为欺诈节点也必须达到80%以上才能达成共识。无论欺诈节点还是诚实节点，达不到80%，都无法通过共识。 一致性 RPCA中一致性是通过子网络与其它子网络的连通性来保证的，要保证区块链不分叉，必须确保每个子网络必须至少与整个网络节点中的20%保持连通性。达到20%连通性的前提下，如果一个子网络中得出的共识区块哈希与整个网络得出的不一致，也就无法达成80%的共识要求，也就无法产生分叉。 可用性 在每一轮投票过程中，节点会搜集它UNL中每个节点的响应时间，一直响应时间慢的节点将会被剔除出去，这样UNL就能保持一个较高的沟通效率。在高效沟通的前提下，RPCA算法能保证每3秒左右就能产生一个区块，Ripple官方给出的tps数据是1500。这样的性能基本能满足一般的生产需求。 在Ripple的共识算法中，参与投票节点的身份是事先知道的，因此，算法的效率比PoW等匿名共识算法要高效，交易的确认时间只需几秒钟。当然，这点也决定了该共识算法只适合于权限链（Permissioned chain）的场景。Ripple共识算法的拜占庭容错（BFT）能力为( n-1 ) / 5，即可以容忍整个网络中20%的节点出现拜占庭错误而不影响正确的共识。 总结 “ 在区块链网络中，由于应用场景的不同，所设计的目标各异，不同的区块链系统采用了不同的共识算法。一般来说，在私有链和联盟链情况下，对一致性、正确性有很强的要求。一般来说要采用强一致性的共识算法。而在公有链情况下，对一致性和正确性通常没法做到百分之百，通常采用最终一致性（Eventual Consistency）的共识算法。” 通俗点就是：共识算法的选择与应用场景高度相关，可信环境使用paxos或者raft，带许可的联盟可使用pbft ，非许可链可以是pow，pos，ripple共识等，根据对手方信任度分级，自由选择共识机制。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-11 22:43:53 "},"database/":{"url":"database/","title":"数据库","keywords":"","body":"数据库 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"database/leveldb.html":{"url":"database/leveldb.html","title":"LevelDB","keywords":"","body":"LevelDB Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"database/couchdb.html":{"url":"database/couchdb.html","title":"CouchDB","keywords":"","body":"CouchDB Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"database/mysql.html":{"url":"database/mysql.html","title":"Mysql","keywords":"","body":"Mysql Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"markdown/":{"url":"markdown/","title":"Markdown","keywords":"","body":"Markdown Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 12:29:09 "},"markdown/markdown.html":{"url":"markdown/markdown.html","title":"markdown语法","keywords":"","body":"Markdown基本语法 一、标题 在想要设置为标题的文字前面加#来表示 一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 示例： # 这是一级标题 ## 这是二级标题 ### 这是三级标题 #### 这是四级标题 ##### 这是五级标题 ###### 这是六级标题 效果如下： 这是一级标题 这是二级标题 这是三级标题 这是四级标题 这是五级标题 这是六级标题 二、字体 加粗 要加粗的文字左右分别用两个*号包起来 斜体 要倾斜的文字左右分别用一个*号包起来 斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来 删除线 要加删除线的文字左右分别用两个~~号包起来 示例： **这是加粗的文字** *这是倾斜的文字*` ***这是斜体加粗的文字*** ~~这是加删除线的文字~~ 效果如下： 这是加粗的文字 这是倾斜的文字 这是斜体加粗的文字 这是加删除线的文字 三、引用 在引用的文字前加>即可。引用也可以嵌套，如加两个>>三个>>> 示例： >这是引用的内容 >>这是引用的内容 >>>>>>>>>>这是引用的内容 效果如下： 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线 三个或者三个以上的 - 或者 * 都可以。 示例： --- ---- *** ***** 效果如下： 可以看到，显示效果是一样的。 --- 五、图片 语法： ![图片alt](图片地址 \"图片title\") 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： ![blockchain](6860761-fd2f51090a890873.webp \"区块链\") 效果如下： 六、超链接 语法： [超链接名](超链接地址 \"超链接title\") title可加可不加 示例： [百度](http://baidu.com) 效果如下： 百度 注：Markdown本身语法不支持链接在新页面中打开，如果想要在新页面中打开的话可以用html语言的a标签代替。 超链接名 示例 百度 七、列表 无序列表 语法： 无序列表用 - + * 任何一种都可以 - 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格 效果如下： 列表内容 列表内容 列表内容 有序列表 语法： 数字加点 1. 列表内容 2. 列表内容 3. 列表内容 注意：序号跟内容之间要有空格 效果如下： 列表内容 列表内容 列表内容 列表嵌套 上一级和下一级之间敲三个空格即可 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 八、表格 语法： 表头|表头|表头 ---|:--:|---: 内容|内容|内容 内容|内容|内容 第二行分割表头和内容。 - 有一个就行，为了对齐，多加了几个 文字默认居左 -两边加：表示文字居中 -右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 示例： 姓名|技能|排行 --|:--:|--: 刘备|哭|大哥 关羽|打|二哥 张飞|骂|三弟 效果如下： 姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 九、代码 语法： 单行代码：代码之间分别用一个反引号包起来 `代码内容` 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 (```) 代码... 代码... 代码... (```) 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。 示例： 单行代码 `create database hero;` 代码块 (```) function fun(){ echo \"这是一句非常牛逼的代码\"; } fun(); (```) 效果如下： 单行代码 create database hero; 代码块 function fun(){ echo \"这是一句非常牛逼的代码\"; } fun(); Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-23 15:49:25 "},"markdown/gitbook.html":{"url":"markdown/gitbook.html","title":"GitBook","keywords":"","body":"GitBook GitBook 是一个使用 Git 和 Markdown 来构建书籍的工具。它可以将你的书输出很多格式：PDF，ePub，mobi，或者输出为静态网页。 Git 方式： 作为一枚程序员，Git 当然是日常生活中的必备工具。使用 Git 的方式去管理文档，除了其自身的优越性外，还大大降低了额外的学习成本，非常便捷。 Markdown：Markdown 的优秀之处可以浓缩为一句：“简单通用，让你只需专注于内容创作”。 多种格式输出：可以一键生成静态文件，非常便于静态站点的搭建。 其他：有丰富的插件、支持多语言、组织结构极为清晰等等。 安装 环境：NodeJS(v4.0.0 及以上) 通过 npm 快速安装。gitbook-cli 一个用于在同一系统上安装和使用多个版本的 GitBook 的管理程序。它将自动安装所需版本的 GitBook 来构建一本书。 $ npm install gitbook-cli -g 安装指定版本： $ gitbook fetch 3.2.3 查看当前安装版本： $ gitbook -V 查看已安装版本： $ gitbook -ls 管理 gitbook-cli 和 gitbook 是两个软件 , 通过 gitbook-cli 来管理 gitbook。 列出 gitbook 帮助信息： $ gitbook help 列出 gitbook-cli 帮助信息： $ gitbook --help 初始化文档结构 (根据 SUMMARY.md 文件生成目录结构)： $ gitbook init 生成 HTML 文件： $ gitbook build 本地预览 (会默认在本地运行 HTTP Server 监听 4000 端口，并生成 HTML 文件至 _book/ ）： $ gitbook serve 使用 目录结构： . ├── book.json ##存放站点配置信息，例如:标题、作者、描述、插件、语言、版本、导航等├── README.md ##书籍的简单介绍├── SUMMARY.md ##定义目录结构的文件，文档左侧的目录就是根据这个文件来生成的，是用Markdown语法来定义目录树的父子关系的。├── Glossary.md ##词汇表文件，用于常用存储词汇信息。├── chapter-1/ | └── something.md └── chapter-2/ └── something.md 案例：Summary.md 文件 # Summary ## 介绍 * [Introduction](README.md)## 文档使用手册 * [简单使用三步走](simple_three_step.md) * [Markdown常用语法](markdown_use.md) * [Gitbook详解](gitbook.md) * [安装](gitbook/install.md) * [命令](gitbook/command.md) * [目录结构](gitbook/structure.md) * [常用插件](gitbook/plugin.md) * [book.json样例](gitbook/book_json.md) * [文档设计](design.md) * [架构逻辑](design/framework.md) * [监控及维护](design/monitor_operation.md) 生成的文件目录结构： ├── book.json ├── design │ ├── framework.md │ └── monitor_operation.md ├── design.md ├── gitbook │ ├── book_json.md │ ├── command.md │ ├── install.md │ ├── plugin.md │ └── structure.md ├── gitbook.md ├── GLOSSARY.md ├── markdown_use.md ├── README.md ├── simple_three_step.md └── SUMMARY.md book.json 样例简介： { \"title\": \"Common\", ##标题 \"description\": \"公共文档\", ##简述 \"author\": \"Common\", ##作者 \"language\": \"zh-hans\", ##语言 \"gitbook\": \"3.2.3\", ##版本 \"root\": \".\", \"structure\": { \"readme\": \"README.md\" }, \"links\": { ##左侧导航栏信息\"sidebar\": { \"Home\": \"xxx\" } }, \"plugins\": [ ##-：表示关闭此插件\"-lunr\", \"-search\", \"highlight\", ##语法高亮\"-livereload\", \"-sharing\", \"search-plus\", ##支持中文搜索 \"simple-page-toc\", ##自动生成本页目录结构 \"advanced-emoji\", ##支持emoji表情 \"anchors\", ##Github 风格的锚点样式 \"include-codeblock\", ##插入代码块 \"ace\", ##支持ace \"emphasize\", ##文字加底色 \"katex\", ##数学公式插件 \"splitter\", ##侧边栏宽度可自由调节 \"tbfed-pagefooter\", ##添加脚页 \"expandable-chapters-small\", ##目录可折叠 \"sectionx\", ##页面分块显示 \"local-video\", ##视频插件(Video.js播放) \"anchor-navigation-ex\", ##悬浮导航 \"todo\", ##ToDo显示功能 \"git-author\", ##显示创建、修改记录 \"alerts\", ##不同alerts样式(info, warning, danger,success) \"include-csv\" ##支持展示csv文件 ], \"pluginsConfig\": { \"theme-default\": { \"showLevel\": true}, \"prism\": { \"css\": [ \"prism-themes/themes/prism-base16-ateliersulphurpool.light.css\" ] }, \"include-codeblock\": { \"template\": \"ace\", \"unindent\": true, \"edit\": true}, \"tbfed-pagefooter\": { \"copyright\": \"Copyright © xiaomi.com 2017\", \"modify_label\": \"文档修订时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" }, \"simple-page-toc\": { \"maxDepth\": 3, \"skipFirstH1\": true}, \"anchor-navigation-ex\": { \"showLevel\": false, \"multipleH1\":true, \"multipleH2\":true, \"multipleH3\":true, \"mode\": \"float\", \"float\": { \"showLevelIcon\": true, \"level1Icon\": \"fa fa-hand-o-right\", \"level2Icon\": \"fa fa-hand-o-right\", \"level3Icon\": \"fa fa-hand-o-right\" }, \"pageTop\": { \"showLevelIcon\": true, \"level1Icon\": \"fa fa-hand-o-right\", \"level2Icon\": \"fa fa-hand-o-right\", \"level3Icon\": \"fa fa-hand-o-right\" } }, \"sectionx\": { \"tag\": \"b\" }, \"favicon\": { \"shortcut\": \"favicon.ico\", \"bookmark\": \"favicon.ico\" }, \"git-author\":{ \"position\": \"bottom\", \"createTpl\": \"Created by {user}：{timeStamp}\", \"modifyTpl\": \"Modified by {user}：{timeStamp}\", \"timeStampFormat\": \"YYYY-MM-DD\" }, \"styles\": { \"website\": \"./styles/website.css\" }, \"pluginsConfig\": { \"include-codeblock\": { \"template\": \"ace\", \"unindent\": \"true\", \"theme\": \"monokai\" } } } } 可以在本地运行如下命令来分别生成 pdf, epub, mobi 格式文件 gitbook pdf gitbook epub gitbook mobi GitHub Pages GitHub Pages提供静态网站托管服务。 GitHub 上的每个仓库都可以拥有一个 GitHub Pages，对应的 URL 如下： https://.github.io// GitHub Pages 的静态资源支持下面 3 个来源： master 分支 master 分支的 /docs 目录 gh-pages 分支 执行下面命令，将 _book 目录推送到 GitHub 仓库的 gh-pages 分支。 $ git subtree push --prefix=_book origin gh-pages 或者在生成静态网页时，将保存的目录指定为 ./docs $ gitbook build ./ ./docs 然后直接推送到 GitHub 仓库的。 $ git push origin master Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 18:36:19 "}}