{"./":{"url":"./","title":"首页","keywords":"","body":"EarthStudy 生而为人，学无止境。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 11:14:26 "},"golang/":{"url":"golang/","title":"GO语言","keywords":"","body":"GO语言 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"golang/base.html":{"url":"golang/base.html","title":"语法基础","keywords":"","body":"语法基础 Go语言只有值传递，地址（&）是指针（*）的值，指针是地址的变量 Go语言没有隐式类型转化 Go语言变量类型写在变量名后面 Go语言支持封装，不支持继承、多态；只有struct没有class var 包内、函数内 var aa int = 3 var ( aa int = 3 ss = ”kkk” bb = true ) var aa, ss, bb = 3, “kkk”, true 函数内 aa, ss, bb := 3, “kkk”, true 内建类型 bool, string (u)int, (u)int8, (u)int16, (u)int32, (u)int64, uintptr（指针）//(u)int根据操作系统32 64决定位数 byte（8位）, rune（32位） float32, float63, complex64, complex128 const const aa int = 3 const aa, ss, bb = 3, “kkk”, true const( cpp = iota //iota是自增值 _ python java javascript ) iota在const关键字出现时将被重置为0 const中每新增一行常量声明将使iota计数+1（注意在同一行计数不+1） 控制语句 if、for、switch、select 没有while，for即是while 遍历可使用 for i, v := range xxx { } 函数 func function_name( [parameter list] ) [return_types / return parameter list] { defer xxxx return x //若有返回参数名则无需return，直接给返回参数赋值 } Array 数组是值类型，，长度不同类型不同，赋值即拷贝，一般不直接使用数组 var variable_name [SIZE] variable_type variable_name = [SIZE] variable_type{v1, v2, v3} //SIZE为...时根据初始化元素的个数设置大小 Slice 声明： var s []Type //nil 空切片 初始化： m := []Type{ , , , , } m := make([]Type, len, cap) //len长度，cap可达最大长度 m := a[ s:e] //a可以是已有的slice或数组，前闭后开 //其中e不能大于数组的长度或slice的cap slice的len根据可读元素决定，cap根据开辟的内存决定 读取元素： m[n] //其中n不能超过len-1 遍历： for i, v := range s { } 操作： append( s1, v1, v2 ) //若cap不够会重新开辟一个内存，并赋值原值过去 append( s1, s2... ) //...将s2分解为一个个元素 copy(s1, s2) //只将覆盖s1 len范围内的值 len(s) //返回长度 cap(s) //返回可达最大长度 Map 声明： var m map[K]V //nil 初始化： m := map[K]V { k1 : v1 } m := make(map[K]V) //EmptyMap 读取： Map[K]=v value , ok := map[K] //若找不到键值 ok为false 遍历： for k, v := range m{ } 操作： delete(map , K) //删除对应键值 len(m) //获取元素数量 String、Rune len(string) 返回的是字节长度，可使用utf8.RuneCountString获得字符数量 range遍历string得到的是pos是字节坐标，不适合处理非unicode编码的字符，可先使用[]rune(string)转换后再遍历 结构体 声明： type StructName struct{ var1 int var2 *T } 初始化： var t StructName t = StructName { 1, nil } 使用new函数初始化： t = new(StructName) t.var1 = 1 t.var2 = nil 使用工厂创建函数初始化： func createStruct(var1 int) *StructName { return &StructName { var1, nil } //局部变量的地址也可以返回给别人用，内存分配在堆还是栈由编译器决定 } 为结构定义方法： // 指针接收者（要改变内容、结构过大、建议有指针接收者则保持一致性也使用指针接收者） func (StructName *t) funcname { } // 值接收者 func (StructName t) funcname { } 指针能直接调用方法，当做值来用 nil指针也可以调用方法 包 一个目录下文件只能有同一个包名 main包有一个可执行入口 结构体的方法必须放在同一个包内，但可在不同文件里 扩展系统类型或别人类型的方法： 定义别名，给要扩展的类型创建一个其他名字，再加方法 使用组合，将要扩展的类型放进自己的类型中 Duck Typing 描述事物的外部行为而非内部结构 -- 像鸭子走路，像鸭子叫，像鸭子就是鸭子 Go严格来说属于结构化类型系统，是类似duck typing（duck typing要动态绑定，Go没有） Python 运行时检查，需要注释来说明接口 C++ 使用模板实现，编译时检查，需要注释来说明接口 Java 没有duck typing，必须实现接口方法，无需注释 接口 接口由使用者定义+组合，实现者无需了解如何组合 接口变量： 接口变量包含 {指向的实现者的类型或类型指针，指向的实现者的值或指针} 接口变量可指向实现者的值，也可指向实现者的指针 接口变量蕴含一个指针，故几乎不需要使用接口的指针 若实现的方法是指针接收者，则接口变量必须指向实现者的指针 Type Assertion：将接口变量转换为指定实现者类型 v, ok := i.(int) //接口变量.(实现者类型/类型指针) Type Switch： 判断实现者类型/类型指针 switch v := i.(type) { case T1: // TODO case T2: // TODO } 表示任何类型： v := interface{} 常用接口： Stringer接口：相当于tostring Reader/Writer接口：文件的抽象 嵌入类型 当我们嵌入一个类型，这个类型的方法就变成了外部类型的方法，但是当它被调用时，方法的接受者是内部类型(嵌入类型)，而非外部类型。 函数式编程 函数体 = {局部变量，自由变量} 闭包 = 函数体 + 所有相关自由变量指向的值（递归） 斐波那契数列 为函数实现接口 defer 确保调用在函数结束（return或panic）时发生 参数在defer语句时计算结果 多个defer时，遵循后进先出 常用场景： Open/Close Lock/Unlock PrintHeader/PrintFooter error error接口用于实现自定义错误 type error interface{ Error() string } 判断错误类型，MyError为自定义错误类型 if dError, ok = err.(*MyError); !ok{ painc(\"unknown err\") } else{ //TODO } panic 尽量不要用 recover 在defer中使用recover()，来保护panic defer func(){ r := recover() // TODO }() 表格驱动测试 分离测试数据和测试逻辑 更详细的自定义出错信息 可部分失败 Go语言语法更易实现表格驱动测试 单元测试testing.T func TestTriangle(t *testing.T) { tests := []struct{ a, b, c int }{ {3, 4, 5}, {5, 12, 13}, {8, 15, 17}, {12, 35, 37}, {30000, 40000, 50000}, } for _, tt := range tests { if actual := calcTriangle(tt.a, tt.b); actual != tt.c { t.Errorf(\"calcTriangle(%d, %d); got %d; expected %d\", tt.a, tt.b, actual, tt.c) } } } 命令行运行： go test . 代码覆盖率： go test -coverprofile=c.out go tool cover go tool cover -html=c.out 性能测试testing.B func BenchmarkSubstr(b *testing.B) { s := \"黑化肥挥发发灰会花飞灰化肥挥发发黑会飞花\" for i := 0; i 命令行运行 go test -bench . 性能分析： go test -bench . -cpuprofile cpu.out go tool pprof cpu.out help web quit http测试： 1. 通过使用假的Request/Response response := httptest.NewRecorder() request := httptest.NewRequest( http.MethodGet, \"http://xxxxxxxxxx\", nil) 2. 通过起服务器 server := httptest.NewServer( http.HandlerFunc(f)) resp, _ := http.Get(server.URL) 文档 命令行运行 go doc 命令行指令帮助 go help doc 启动帮助文档服务器 godoc -http :6060 Example Example是另一种测试，也可运行 在给文档提供示例 func ExampleTypename_Funcname() { // 函数调用，期望的函数返回结果 } goroutine 协程Coroutine： 轻量级“线程” 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟机层面的多任务，GO语言有自己的调度器 多个协程可能在一个或多个线程上运行 子程序是协程的一个特例 C++：Boost.Coroutine Java：不支持 Python：使用yield关键字、async def Go语言：goroutine go func() { // TODO runtime.Gosched(); //让出控制权 }() 任何加上go就能送给调度器运行 不需要在定义时区分是否是异步函数 调度器会在合适的点进行切换 切换点： I/O，select channel 等待锁 函数调用（有时） Runtime.Gosched() 以上只是参考，不能保证切换，不能保证在其他地方不切换 使用-race来检测数据访问冲突 go run -race xxxx.go channel 类似Python的yield 当一个channel的数据未传输成功时（未发、未收、无缓冲区），当前协程会阻塞等待 声明： var c chan int //可发可收 var c chan 初始化： c := make(chan int) c := make(chan int, 3) //创建一个缓冲区大小为3的channel 操作： c Go语言channel基于CSP模型 “不要通过共享内存来通信；通过通信来共享内存”，可创建两个channel来完成双向发送数据 WaitGroup 利用WaitGroup判断协程工作是否完毕 var wg = sync.WaitGroup wg.add(1) //添加任务数 wg.done() //完成一个任务 wg.wait() //挂起等待所有任务完成 select 利用select来进行调度，实现非阻塞式获取channel数据，select中若case不可运行且没有default则阻塞直到有case可运行 select { case n:= 注：在select中使用Nil Channel时会直接跳过而非阻塞 时间channel： time.After(10 * time.Second) //倒计时 time.Tick(time.Second) //周期定时触发 传统同步机制 非CPS模型，在GO中尽量少使用 WaitGroup MuteX Cond http标准库 http.Get(“https://xxxxxxxxxxxxxx.com”) request, err := http.NewRequest(http.MethodGet, \"https://xxxxxxxxxxxxxxx.com\", nil) request.Header.Add(\"\",\"\") client := http.DefaultClient() client := http.Client{ xxx : xxx CheckRedirect : func(){ }, } client.Do(request) httputil.DumpResponse(resp, true) http调试： 浏览器访问 http服务地址/debug/pprof 命令行go tool pprof 服务地址/debug/pprof/profile获得30秒服务的CPU使用情况 结束后对话输入web 命令行go tool pprof 服务地址/debug/pprof/heap 获得服务的内存使用情况 结束后对话输入web 其他标准库 bufio log encoding/json regexp time string/math/rand 使用 godoc -http:6060 启动帮助文档服务器 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 18:52:24 "},"cryptography/":{"url":"cryptography/","title":"密码学","keywords":"","body":"密码学 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"cryptography/hash.html":{"url":"cryptography/hash.html","title":"哈希","keywords":"","body":"哈希 哈希函数 任意输入，固定输出，有效计算O(n) SHA-0： SHA-1：HASH160 SHA-2：HASH256、HASH512、HASH244、HASH384 SHA-3：Keccak RIPEMD：RIPEMD-128、RIPEMD-160、RIPEMD-256、RIPEMD-320 加密安全的哈希函数： 碰撞阻力（collision-resistance） 隐秘性（hiding） 谜题友好（puzzle-friendliness） 应用： 信息摘要（message diget） 承诺（commitment） com := commit(msg , nonce) verify(com , msg , nonce) 搜索谜题 安全哈希算法（Secure Hash Algorithm 256，SHA-256） 压缩函数（compression function）：接受固定长度，具有碰撞阻力的哈希函数 MD（Merkle-Damgard）变换：将接受固定长度的哈希函数变换为可接受任意长度 SHA256 算法输入报文的最大长度不超过2^64 bit，输入按512-bit 分组进行处理，产生的输出是一个256-bit 的报文摘要 将报文进行512位分组 + 488位补位 + 64位长度信息 = 512整数倍位数 初始化8个共256位常量缓存 A=0x6A09E667，B=0xBB67AE85，C=0x3C6EF372，D=0xA54FF53A， E=0x510E527F，F=0x9B05688C，G=0x1F83D9AB，H=0x5BE0CD19 处理512-bit（16 个字）报文分组序列。该算法使用了六种基本逻辑函数，由64步迭代运算组成。每步都以256-bit缓存值ABCDEFGH为输入，然后更新缓存内容，每步使用一个32-bit 常数值Kt和一个32-bit Wt 上图参与运算的都是32 bit的数，Wt是分组之后的报文，512 bit=32bit*16. Wt t=1,2..16 由每一组512位报文再分16组产生 Wt t=17,18,..,64 由前面的Wt按递推公式计算出来。Wt递推公式为： Kt t=1,2..64是已知的常数。 所有512-bit分组处理完毕后，对于SHA-256算法最后一个分组产生的输出便是256-bit的报文摘要 哈希指针（hash pointer）：一个指向数据存储位置及其位置数据的哈希值的指针 可应用于任何基于指针且不包含闭环的数据结构 区块链（block chain）：通过哈希指针建立的链表 防篡改日志 梅克尔树（Merkle trees）：通过哈希指针建立的二叉树 隶属证明，验证时间与空间与log(n)同级 排序梅克尔树 非隶属证明 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 16:37:07 "},"cryptography/signature.html":{"url":"cryptography/signature.html","title":"数字签名","keywords":"","body":"数字签名 (sk , pk) := generateKeys(Keysize) sig := sign(sk , message) isValid := verify(pk , message , sig) 可验证，不可伪造，签名算法随机性的良好来源，信息大小处理（签署哈希值） 椭圆曲线数字签名算法（ECDSA） 比特币使用ECDSA而非标准椭圆曲线“secp256k1” 需要使用良好随机来源（就算密钥完美无缺只在签名时使用了不良随机，也可能导致密钥泄露） 是单向加密函数，输入私钥获得公钥 ​ 个人密钥：256位 ​ 公钥（未压缩）：512位 ​ 公钥（压缩）：257位 ​ 待签名信息：256位 ​ 签名：512位 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 12:26:26 "},"bitcoin/":{"url":"bitcoin/","title":"比特币","keywords":"","body":"比特币 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"bitcoin/decentration.html":{"url":"bitcoin/decentration.html","title":"去中心化","keywords":"","body":"去中心化 比特币如何做到去中心化 去中心化 去中心化（Decentralization）：在一个分布有众多节点的系统中，每个节点都具有高度自治的特征。节点之间可以自有链接，形成新的连接单元。任何一个节点都可能成为阶段性的中心，但不具备强制性的中心控制模式。节点与节点之间的影响，会通过网络而形成非线性因果关系。这种开放式、扁平化、平等性的系统现象或结构，被称为去中心化。 没有一个系统是完全中心化（Centralization）或完全去中心化的，去中心化不是不要中心，而是由节点来自由选择中心、自由决定中心。简单地说，中心化的意思，是中心决定节点。节点必须依赖中心，节点离开了中心就无法生存。在去中心化系统中，任何人都是一个节点，任何人也都可以成为一个中心。任何中心都不是永久的，而是阶段性的，任何中心对节点都不具有强制性。 分布式共识 共识（consensus） 分布式共识协议（distributed consensus protocol） 在一个有n个节点的系统中，每一个节点都有一个输入值，其中一些节点具有故障，甚至是恶意的。一个分布式共识协议有以下两个属性： 输入值的中止必须经由所有诚实节点来确定 这个输入值必须由诚实节点来生成 比特币是一个点对点系统 比特币协议达成共识时直面两大障碍： 不完美的网络，例如信息延迟和节点死机 某些故意搞破坏的节点 拜占庭将军问题（Byzantine Generals Problem） 如果叛徒数量超过1/3，则无法达成统一的作战计划 不可能结果（Fischer-Lynch-Paterson） 在一定条件下（包括节点行为具有确定特征），甚至在只有一个缺陷的过程中，达成共识都是不可能的 Paxos算法协议 一方面做到不产生不一致结果；另一方面做出妥协：在一定条件下，协议会死机卡住，无法继续运行 以上三个问题都是针对分布式数据库的研究，而比特币打破了很多原来分布式数据库所做的假设。 比特币打破的假设： 引进了奖励的理念 包含随机性概念 使用区块链达成没有身份的共识 化名制（pseudonyity），缺少真实身份 隐性共识（inplicit consensus），共识协议有多个回合，每个回合随机选取一个节点提议下一个区块，其他节点通过隐性接受或拒绝，如果接受则在该区块之后接龙下去，如果拒绝则忽略该区块而选择曾经接受的区块然后接龙下去 新的交易被广播到所有节点之上 每个节点都将新的交易放进一个区块 在每个回合，一个随机的节点可以广播它的区块 其他节点可以选择接受这个区块，前提是如果区块里的交易都是正当的（有真的签名） 节点们可以把以上区块的哈希值放进自己的区块里，以此来表示他们对那个新区块的认可 可避免的攻击：窃取比特币、拒绝服务攻击、双重支付攻击（商家需通过多次确认交易来避免双重支付攻击，一般是6个确认） 孤块（orphan block）：被网络完全遗忘的链块 零验证交易（zero confirmation transaction）：在没有区块被创建之前就完成交易 诚实节点一般会延长最长有效分支 奖励机制与工作量证明 奖励机制 ：比特币创造的唯一途径 奖励一：区块奖励，每创建一个区块，可在该区块中加入一笔奖励交易，地址由区块创建者指定。最初奖励为50个比特币，每生成210000个区块，奖励减半，最终限制比特币上限为2100万个 奖励二：交易费，交易的制造者可以让交易输出值比输入值小，而第一个节点的区块创建者能将这个差额付到指定的地址中 工作量证明（proof of work） 核心理念是把随机选取节点改为根据节点占有某种资源的比例来选取节点，该资源是无法垄断的，比如计算能力 权益证明（proof of stake） 某种币的拥有量 工作量证明函数三个特性： 难于计算，挖矿成本高 可参数化成本，每产生2016个区块之后，所有节点会自动重新计算目标区域的比例大小，使得后续区块产生的时间间隔约为10分钟 易于证实，其他节点很容易就能验证随机数的正确性 比特币挖矿：解哈希谜题 H( nonce || prev_hash || tx || tx || … || tx ) 挖矿能力：哈希速度（哈希/秒） 比特币最小单位：1中本聪 = 0.00000001 BTC（1E-8） 总结 比特币的共识： 账本情况、拥有的比特币、系统规则都是通过共识表达的 区块链安全性 – 挖矿生态系统的健康程度 – 货币的价值 三者相互作用的自举过程（bootstrapping） 51%攻击： 成本极高，且开发者可升级比特币来应对，但51%攻击的存在本身就是大家对比特币信息的巨大威胁 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:17:48 "},"bitcoin/operation.html":{"url":"bitcoin/operation.html","title":"运行机制","keywords":"","body":"运行机制 比特币的运行机制 比特币的交易 一个交易包含： 比特币的来源 输出地址 输出地址可以是任意地址，可多个，可用于找零 地址转换：将比特币转入同一人的不同地址 有效验证：不需要从账本建立之初的交易开始核查，只需从引用的输出核查到账本最新记录 资金合并：同一人的两笔比特币收入同时作为输入，输出到他的一个地址中 共同支付：不同人的比特币作为输入同时作为输入，输出到收款人的地址中，需要多个签名 交易语法： 元数据 { “hash”:”0xxxxxx” “ver”:1, “vin_sz”:2 “vout_sz”:1, “lock_time”:0, “size”:404, 输入 “in”:[ { “prev_out”:{ “hash”:”1xxxxxx”, “n”:0 }, “scriptsig”:”...” } { “prev_out”:{ “hash”:”2xxxxxx”, “n”:0 }, “scriptsig”:”...” }, ] 输出 “out”:[ { “value”:”xxx”, “scriptPubKey”:”OP_DUP OP_HASH160 3xxxxxx OP_EQUALVERIFY OP_CHECKSIG” } ] } 输入总金额 – 输出总金额 = 记账交易费 根据目标地址区分的交易类型： 支付到公钥Hash，Pay-To-PubkeyHash Tx .（P2PKH Tx） 支付到脚本Hash，Pay-To-ScriptHash Tx .（P2SH Tx） 挖矿交易（coinbase） 比特币的脚本 可以为比特币支付设定条件 堆栈式编程语言（stack-based programming language），非图灵完备（避免无限循环） 和Forth语言有很多相似的地方 将输入脚本和输入比特币的前一笔交易的输出脚本链接起来，然后执行 一共只有256个指令，每个指令一个字节（目前15个不可用，75个保留） 包含其他语言里常见的基本指令（基本算数、逻辑语句、抛出错误、过早返回） 包含一个重要的特殊指令（CHECKISIG）可查证多个签名，该指令有一个缺陷即会返回一个没用的值，它要求堆栈的一个变量去储存然后忽略，这个缺陷也是比特币的一个特性 脚本在交易的时候执行 脚本分两类： 数据指令（<>），作用是把数据推到堆栈的最上面 工作码指令，用堆栈顶部的数据作为输入值，用来计算一个函数 比特币脚本的应用 销毁证明（proof of burn）：用于销毁比特币（防止资金被赎回） 使用OP_RETURN直接抛错 P2SH：对堆栈顶部数据进行哈希运算，核验哈希结果与另一个给定的哈希值一致，通过后将最顶层的数据重新解读为一系列指令，然后运行一次这些指令，此时堆栈中的其他数据作为脚本的输入值 P2SH简化了支付工作，收款方只需告诉付款方一个哈希值，无需付款方写入复杂的脚本；还提升了挖矿效率 第三方支付交易（escrow transation） 使用多重签名（MULTISIG）实现，加入第三方仲裁员，三人中有两人签名后资金才能被支取 场景：货到付款&见款发货&退款 绿色地址（green address） 即第三方银行（可以是交易所或者其他金融媒介）控制的账户，第三方银行保证不会双重支付，故收款人无需等待区块链的6次确认 绿色地址使用的越来越少，人们认为，对“银行”过分信任是有风险的 高效小额支付（efficient micro-payments） 使用多重签名（MULTISIG）实现，需要收款人和付款人两个签名才能完成交易，如此可允许短时间重复支付，收款人在所有支付结束后再签名完成交易，可减少交易次数（交易费），而重复支付没有签名的那些交易会被丢弃掉 步骤： 付款人创建一个交易到MULTISIG，金额为可能花费的最大金额，MULTISIG需要收付款两方的签名才能使用 在付款人发布步骤1的交易之前，要求收款人先发布一个从MULTISIG退款给付款人的交易，该交易的lock_time=t，t>0，即t时间后才计入区块链 在有退款交易的保证下，付款人发布步骤1的交易 付款人在每次需要小额支付的时候签名一个从MULTISIG到收款人的交易，金额为所有累计的费用，剩余金额转给付款人自己 消费结束时付款人签名最后一个交易，同时收款人在最后一个交易上签名 场景：手机流量提供商根据每分钟使用的流量计费 锁定时间 利用lock_time防止小额支付中的收款人一直不签名，而扣押了付款人的剩余比特币 lock_time是一个非零数值t，告诉矿工记账时候，要等到t时间之后才将交易记入区块链 智能合约 即无需通过法律或者仲裁机构来保护执行的普通合约， 比特币的特性能用脚本、矿工和交易验证来实现第三方托管协议或是小额支付 但比特币脚本语言的设计也有很多缺陷，有很多现实需求无法实现，因此需要像以太坊等实现了图灵完备的智能合约 比特币的区块 区块的哈希链，每个区块都有一个区块头部，里面有 一个哈希指针指向上一个区块（prev） 一个矿工可修改的“临时随机数”（nonce） 一个时间戳 一个点数（表示找到区块的难度） 梅克尔树（树状数据结构），把区块内所有交易的哈希值进行排列存储 梅克尔树中都有一个币基交易 币基交易（coinbase） 永远只有一个单一的输入与单一的输出 交易不消费之前交易输出的比特币，因此没有指针指向“上一交易” 输出的值 = 区块奖励 + 区块中所有交易费 币基交易的参数可以是任何数据，矿工可以放任何值进去 比特币的网络 泛洪算法（flooding algorithm）/八卦协议（gossip） 发起交易 传播给其他相连节点 节点接收到交易后进行核验 节点判断若交易池中没有该交易则放入交易池并继续传播给其他相连节点，否则中止传播 泛洪算法的效率偏低（比较大的区块需要30秒左右才能传播到大部分节点） 节点核验交易的四个关卡 交易验证，找到所有输入的前序交易的输出脚本来核验，确保所有结果都为真 检查是否有双重支付 检查是否已经被本节点接收过 只接收和传递在白名单上的标准脚本 上述检查都是非强制的 竞态条件（race condition）/紊乱情况：众多节点对哪些交易应该被纳入区块链产生分歧 该情况会被打包下一个节点的矿工打破 比特币网络大小：很难测量，因为随时都在变化。 往低说5000-10000节点永远在线并处理交易，往高说有100万个IP成为节点 存储空间需求：需要将整个完整的共识区块链存储下来，并将所有未被消费的比特币的完整列表放在内存中以便快速验证 轻量节点（lightweight nodes）/轻客户端/简单付款验证（Simple Payment Verification, SPV）: 不存储整个比特币区块链，而只存储它们关心的、需要核验的部分交易 依赖全节点去验证全部交易，但在矿工挖出来之前会做一些核验来确保这个区块不会被拒绝 限制与优化 更新协议：硬分叉、软分叉 硬分叉：新的特性会使前一版本的协议失效，网络上的节点根据其所运行的协议版本去扩展不同的区块链，分叉不会合并，该情况是比特币社区不能接受的 软分叉：新的特性让现有核验规则更加严格，这样老节点会接受所有区块，新的节点会拒绝一些，能避免永久分裂；可以说更新后的新交易和新区块在旧协议下是有效的，新协议是原协议的一个子集 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 18:53:42 "},"bitcoin/coin_storage.html":{"url":"bitcoin/coin_storage.html","title":"货币存储","keywords":"","body":"货币存储 如何储存和使用比特币 储存比特币就是储存与管理比特币私钥 三个目标：获取性、安全性、便利性 简单的本地设备储存 获取性、安全性差 一般会使用比特币钱包软件 地址使用Base58对二进制字符进行编码 交换地址一般使用字符串或QR二维码 虚荣地址（vanity address）：使用工具不停生成私钥，以达到含有个性化字符的地址（平均生成58的k次方次地址，k为个性化字符的个数） 特储存与冷储存 热储存：连入互联网，随时可以给冷储存转账 冷储存：不连入互联网，生成地址发送给热储存 第一种方法 分层确定性钱包（hierarchical deterministic wallet）：可让冷储存制造无限制的地址数量，一次性让热储存知晓所有地址 生成“密钥生成信息”和“地址生成信息”来代替“密钥”和“地址” 比特币使用的ECDSA支持分层密钥 生成分层确定性密钥需要两个随机数k、y 私钥生成信息：k、y 第i个私钥：xi = H( k || i ) +y 地址生成信息：k、gy 第i个公钥：gxi= g H( k || i ) · gy 第i个地址：H(gxi) 第二种方法 大脑钱包（brain wallet）：用一个可预测的算法把一个口令变成一对公钥/私钥，还可结合分层确定性钱包技术生成一整套地址和私钥 第三种方法 纸钱包：将密钥印在纸上，二维码或base58编码 第四种方法 防损硬件（tamper-resistant device） 密钥分存和密钥共享 密钥分存：将密钥转换成N个子密钥，只要获取K（K 若K=N，可以先生成N-1个随机数，然后最后一个子密钥就是原密钥与所有其他N-1个子密钥的异或 若K 门限密码（threshold cryptography） 门限签名（threshold signature） 可实现双重安全机制或多重安全机制 多重签名（multisignature） 可实现多人对共同财产实现共同控制 通过比特币脚本把一个比特币的控制权交给多个密钥 在线钱包和交易所 在线钱包：将密钥储存在云端（Coinbase、blockchain.info） 比特币交易所 和银行一样主要面临三大类风险： 挤兑 庞氏骗局 黑客入侵 银行有政府的监管： 最低准备金要求 投资类型、资金管理监管 提供必要保护 交易所的措施： 准备金证明（proof of reserve），证明其“至少”有多少准备金，交易所发起一笔收款人是自身的交易，之后用同一私钥为一条查询指令签名，这个查询指令是公正第三方随意发出的字符串 负债证明（proof of liabilities），证明其“至多”有多少存款，交易所构建一个梅克尔树（叶子节点为所有储户信息，每个节点增加一个金额字段，该字段显示最近两个子节点的金额之和），然后将根节点加密签名后广播 “准备金”（provision）协议，可提供偿付能力证明，无需披露总负债和总的存款准备金规模 准备金证明和负债证明会泄露很多私密信息，实际应用中用的很少 支付服务 支付服务一般流程： 客户购买 – 支付服务商提供比特币支付按钮 – 客户付款给支付服务商 – 支付服务商给商户发送支付凭证 – 客户购买成功 – 支付服务商定时结算指定货币给商户 该流程支付服务商几乎承担了所有风险 2015年初无需交易费默认条件： 交易小于1000个字节 所有输出为0.01BTC或更大 优先权足够高 优先权 = 所有（账龄x输入金额）的总和 / 交易规模 账龄 = 输入对应的上一笔交易到现在所经过的时间 2015年初交易费默认标准：每1000个字节需要支付0.0001BTC 货币兑换市场 简单的市场行为模型： P = TD/S P为比特币价格 T为比特币价格对应货币的交易量（每秒） D为比特币处于交易状态的时间间隔（暂时退出流通体系） S为比特币总量 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:00:23 "},"bitcoin/mine.html":{"url":"bitcoin/mine.html","title":"挖矿","keywords":"","body":"挖矿 矿工的任务 （一类是验证交易和区块，一类是和其他矿工竞争） 一类是和其他矿工竞争 监听交易广播 维护区块链网络和监听新的区块 组装一个备选区块 找到新区块对应的有效的随机数 先尝试头部的临时随机数，若试过所有32位可能的取值后仍然不能产生一个有效的哈希值，还可以改动币基里的随机数，但后者改动涉及到梅克尔树的更新，代价更大 2015年目标区域值为： 小于 0000000000000000172EC0000000000000000000000000000000000000000000 新区块被全网接受 获得利润 决定难度：每挖出2016个区块（约两周时间）则所有矿工自己重新计算一次难度 下一个难度 = 上一个难度 x 2016 x 10 / 产生上2016个区块所花费的分钟 挖矿所需硬件 挖矿设备： CPU挖矿非常困难 GPU的高吞吐量和高并行处理能力更适合用于挖矿，且大多数显卡支持超频，能家加快运算速度；OpenCL是一个可以使GPU进行非图像处理类工作的通用语言；但是GPU内置了很多与挖矿无关的硬件，同时还有耗电多、散热难等问题；GPU挖矿的运算速度仍然 现场可编程门阵列挖矿（Field-Programmable Gate Array,FPGA）+Verilog（硬件设计语言），优点是比GPU性能好、容易冷却，缺点是性能提升不大、一直超频导致报错和故障、算法优化难、采购搭建难，故短暂存在后便退出舞台 专用集成电路技术挖矿（ASIC），主导当今挖矿市场 大型专业挖矿中心，建立的三个重要因素：气候、电费、网络接入速度 新的另类币总会经历一个ASIC蜜月期（还没有ASIC的时期，个人参与挖矿的利润比较高） 能源消耗和生态环保 蓝道尔原理（Landauer’s principle）：任何一个不可逆转的计算都会消耗一定的能源 任何位移运算都会消耗一定量（kTln2）的焦耳 比特币的能源消耗： 内涵能源：设备的制造和运输消耗的能源，会越来越小 电能：根据蓝道尔原理，是不可避免的 冷却：一般也是利用电力，寒冷环境可以减少消耗 比特币的能耗预估： 自上而下：将所有区块奖励的收入都用于电费来计算 自下而上：利用算力除以矿机功效来计算 得到比特币挖矿大搞所耗电力为几百万瓦特（MW）的数量级 矿池 总的发现区块的期望值可以是泊松概率分布 矿池：一组矿工形成一个矿池共同进行挖矿，并指定同一个币基接受人，最终无论谁发现了有效区块，币基接受人都根据每个参与者所贡献的工作量按比例分配奖励 挖矿工分（mining shares）：那些接近目标值的区块 工分分红：矿工发送工分后，管理员马上对其支付奖励；对矿工最有利，管理员需要承担风险但也会收取更高的管理费用；矿工没有动力追求有效区块 按实际比例分红：当找到一个有效区块时，将奖励按矿工的实际工作量比例分配；降低了管理员的风险但要求管理员校验、计算和分配奖励；矿工有动力追求有效区块；矿池足够大时，发现有效区块的概率波动会相当低 获取有效区块模板（getblocktemplate，GBT）作为一种标准化的矿池协议放进了比特币改进方案（Bitcoin Improvement Proposal，BIP）中。一种被称为层（stratum）在实际中运用广泛 矿池跳换（pool hopping）：矿工通过切换矿池的方式提高自己的收益。例如在挖矿周期的早期（上一个区块刚刚被发现），在按实际比例分红的矿池中挖矿，只在周期的后期切换到一个工分分红模式的矿池 洗算力（laundering hashes）：大的挖矿机构通过同时参与多个不同的矿池来掩盖他们的真实规模 挖矿的激励和策略 挖矿策略： 需要包括哪些交易？默认选择交易费比较高的交易 在哪一个区块上进行挖矿？默认是在最长的那条区块链上继续挖下去 若两个不同的区块在同一时间被宣布发现，该如何做选择？默认选择最先被监听到的那个区块 什么时候宣布新的区块？默认立刻宣布 大部分矿工都选择了默认策略（default strategy）来挖矿 挖矿攻击 分叉攻击（forking attack）：利用分叉制造双重支付 设一个攻击者矿工掌握的比特币网络挖掘市场份额为ａ，如果ａ>0.5，很可能实现一个分叉攻击，拥有近乎50%算力的攻击者可能需要花很长时间，但算力超过50%越多，攻击就会越容易且越有效 可操作的对策：大家可以觉察到攻击，社区可以对此做出决定，即使分叉链更长也可以拒绝接受 这种攻击能摧毁比特币信心，使其没有价值，可被称为金手指攻击（Goldfinger attack）；攻击者可以做比特币空头交易或拥有大量竞争货币而获益 通过贿赂进行分叉攻击：系统外的贿赂、高奖励矿池、高额交易费 临时保留区块攻击（temporary block-whihholding attacks）：找到有效区块后不立刻宣布而是在新区快上继续挖矿，期望可以在其他矿工找到下一个区块之前连续找到两个有效区块，该行为称为自私挖矿（selfish mining） 惩罚分叉攻击（punitive forking）：宣布拒绝在包含来自该地址的交易的区块链上工作，若宣布者市场运算能力大，则其他矿工会为了避免自己的区块链被分叉而不将该交易放入区块链中 羽量级分叉攻击（feather forking）：当算力不足0.5时，通过宣布将会尝试分叉来封杀某个地址，若其他矿工相信你，也可能会为了避免自己的区块链被分叉而决定加入你的封杀行动 好的挖矿算法 挖矿解谜更精确的说法是“不完全哈希函数原像解谜”（partial hash-preimage puzzle） 一个好的解谜方案： 能够被及时验证 解谜难度可调整 给每个矿工按哈希算力的比例来获得谜底，即解谜是“无关过程”（progress free）的 上面也是比特币挖矿解谜的三大核心特征 永不枯竭的解谜库 谜题通过算法自动生成 反ASIC解谜 反ASIC解谜（ASIC-resistance puzzles）：抑制ASIC设备优势的解谜程序 刚性内存解谜（memory-hard puzzles）：一种需要大量的内存来计算的反ASIC解谜 Scrypt是一个刚性内存的哈希函数，先用随机数填充随机存取存储器（Random Access Memory，RAM）里的缓存空间，然后从这块内存区域里虚拟随机地读取（或更新）数据，同时要求整个缓存都存储在RAM里面，伪代码： def scrypt( N , seed ): V = [0]*N //初始化N长度的缓存区域 //往缓存区域里充满虚拟随机数 V[0] = seed For i = 1 to N: V[i] = SHA-256(V[i-1]) //然后从这个区域里虚拟随意地读取 X = SHA-256(V[N-1]) For i = 1 to N: j = X % N //根据X，选择一个随机的索引 X = SHA-256(X ^ V[j]) //根据X的索引来更新这个X return X 若不使用缓存V，时间复杂度为O(N2) 若使用缓存V，时间复杂度为O(N) 故只要N值足够大，就能确保使用内存是更快的选择 另外还可以只缓存一部分来平衡时间与内存：假设储存缓存区域V里的每个k排数据，则大致内存为N/k，SHA-256迭代计算次数为( k + 3 )N/2 Scrypt的一个局限性是需要用同样大小的内存来校验，增加了分叉攻击的风险 Scrypt在莱特币的实际应用由于N值较低中最终无法反ASIC 布谷鸟周期算法：于2014年提出，需要建立一个很大的哈希表来计算周期，但结果却可以通过发现一个相对小的周期来验证 X11：将11个不同的哈希函数结合在一起的反ASIC解谜方案，被应用在黑暗币（DASH）中，其反ASIC的方式并不科学 有效工作量证明 有效工作量证明：让比特币挖矿的工作量证明所消耗的能量对社会做出贡献 质数币（Primecoin）：被证明具有有效工作的系统，其工作量证明是为质数找到一个“坎宁安链” 坎宁安链（Cunningham chain）：k个质数的序列P1,P2,…,Pk，使得Pk = 2 Pi-1 + 1 质数币解谜算法： 三个关键参数m，n，k 对于解谜挑战x（上一个区块的哈希函数值），要找到一个长度为k的坎宁安链，其中第一个质数的位数是n，且它的前 m位数与x的前m位数相同（n>=m）；增加n的值可使问题难度指数型增长，增加k的值可使问题难度线性增长，m足够大使得知道前一个区块的值之前的预先计算没有意义 局限性是坎宁安链还没有实际的应用和解谜结果验证时间长 存储量证明（proof of storage）/可恢复性证明（proof of retrievabitlity）：一个需要本地存储大量数据用来运算的解谜算法 永久币（Permacoin）：用于共识机制的存储量证明方案 首先系统选择一个不变的有意义的大文件F，并用一个大型梅克尔树代表F，挖矿步骤如下： 矿工生成一个用于接受资金的公钥KM 矿工使用KM进行哈希运算生成的一个随机索引集，对应梅克尔树的区块集FM ⊆ F，区块数为k1 矿工存储FM到本地以实现挖矿（也可存储一部分，用运算时间换取存储空间） 矿工获得区块链前一个区块的哈希值s时，创建一个临时随机数n 矿工使用s、KM、n行哈希运算生成的一个随机索引集，对应k1个区块FM中的k2个区块FM, n（k2 最后矿工对n、FM, n进行SHA-256的哈希函数H( FM, n || n )运行，如果计算结果低于目标难度，则挖矿成功（与比特币相同） 校验结果步骤如下： 校验FM, n是由矿工的公钥KM和临时随机数n共同产生 通过梅克尔树检验FM, n中的每一个区块时正确的 校验H( FM, n || n )的值比目标难度要小（为何不把s放进哈希函数？） 若k2足够大，降低存储量带来的计算负担是指数型增长的，故矿工没法通过降低存储量来权衡成本；但太大的k2会增加校验结果的成本 若k1更小以为这挖矿更加民主化；但有能力存储更多的矿工没有动力存储多于k1的区块 反矿池解谜：不能外包的解谜算法 矿池依赖于比特币的两大技术特征： 矿工很容易通过工分来证明工作量（由于谜题本身就需要包含难度可调整的特征，故很难通过改变此特征来反矿池） 矿池成员可以容易地保证遵守规则并通过实际运算来寻找有效区块，最后让整个矿池受益 反矿池的方案有： “区块丢弃”攻击（block-discarding attack）：矿池成员在找到有效区块时不提交给管理员，而是直接丢弃 设计一个挖矿解谜算法使得“区块丢弃”攻击有利可图，从而抵抗矿池存在 奖励破坏：让分配奖励的过程无法可靠进行 设计一个挖矿解谜算法将私钥加入到运算中，如先用私钥对区块进行数字签名。在这种解谜算法下，解谜者即新铸币的控制者，管理员无法保证分配奖励的正常进行 争议：反矿池的解谜算法也许并不能抑制中心化，因为没有了矿池会让小矿工们不敢参与挖矿，只剩下大型挖矿团队 最理想的方案是小额度奖励每个找到低等难度解谜答案的矿工，让小矿工们在不需要组成矿池的前提下也能参与挖矿获利 权益证明和虚拟挖矿 虚拟挖矿（virtual mining）：直接将挖矿“算力”按比例分配给有权益证明的矿工，从而节省挖矿设备和能耗；理由是利益相关者会有强烈意愿成为系统的维护者 虚拟挖矿可以节省能源，同时也不会有ASIC 点点币（Peecoin）：于2012年启动，是第一个使用权益证明的另类币，它结合了工作量证明（PoW）与权益证明（PoS），“拥有量”以“币龄”为计价单位 币龄（Coin age）：币量x未被交易的时间 点点币区块中包含一种即能用于消耗币龄又能获得利息的交易，称为利息币（coinstake），利息币总和越大挖矿目标则越大，挖矿也越容易 权益的其他形式有： 权益证明：不考虑币龄，会让最有钱的参与者总是最容易挖矿 储量证明：用于铸造区块的货币会被冻结一定时间（与币龄的方案正好成镜像，矿工的收入都是来自不能使用货币去做其他事情的机会成本） 虚拟挖矿的缺点： “无利害关系问题”（nothing-at-stake problem）或“股权粉碎攻击”（stake-grinding attacks）：不像真实的算力，虚拟挖矿中的筹码可以同时用于两个挖矿，这就降低了矿工尝试分叉的成本 中心化的检查点、以太坊（Ethereum）的Slasher都是尝试解决上述问题的方案 检查点：用于给节点更新主链，更新由指定私钥签发 Slasher：在使用筹码挖矿时需要私钥签名这一前提下，若矿工使用相同的筹码去签署两个不连续的区块链，其他矿工可以在区块链上输入这两个签名，并拿走一部分筹码作为奖励 蓄力：虚拟挖矿可积蓄大量筹码进行一次剧烈的攻击 垄断：如果有一个拥有51%筹码的矿工持续挖矿，则会永远保持优势直到筹码慢慢接近100% Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 13:44:08 "},"bitcoin/apply.html":{"url":"bitcoin/apply.html","title":"应用","keywords":"","body":"应用 应用一：比特币作为一个只能被添加的记录 安全时间戳（secure timestamp）：在不披露具体内容的前提下，证明该内容于某时间点存在，并且这个证据具备永久性 实例： 专利、创意的优先权 工作完成的时间点 完全公钥签名方案，盖伊福克斯签名方案（Guy Fawkes signature scheme） 等… 方案： 将内容的哈希函数值作为输出地址，创建一笔微小交易 缺点是会产生永不能使用的比特币 承诺币（CommitCoin）：将内容的哈希函数值作为私钥，创建一个微小交易，随后再将交易分两次交易回来，两次交易的随机源相同（利用了ECDSA的不良随机源漏洞） 如此不会产生永不能使用的比特币 OP_RETURN交易 OP_RETURN，允许输出80字节 恶意用途：记录非法内容 附着币（overlay currencies）：利用比特币的共识机制，开发一种新币，将开发新币需要的所有数据写进比特币的区块链中；附着币的检查更依赖用户，故没有一个轻量级的SPV客户端 合约币（Counterparty）：一种比较优秀的附着币，功能更丰富比如智能合约、用户自定义货币等，API更丰富；但是，合约币有效率低和交易费规则受制于比特币的缺点 应用二：比特币作为一个“智能资产” 利用比特币具有可追溯性 染色币（Colored Coins）：在一个被称为“发行”的交易里，嵌入一些额外的元数据来宣布某些比特币具备了特定的“颜色”，这些比特币就成为了染色币；染色币交易后仍能追溯到发布 实例： 公司股票 有形资产交易 域名交易（有一种另类币叫域名币Namecoin是专门用于域名交易的） 等… 方案： 开放资产（OpenAsset）：利用P2SH发行，执行带有染色币的交易时必须嵌入一个有特殊标记的支出 应用三：比特币作为一个多方参与的安全博彩系统 可扩展为一个强大的系统模式：各自都有敏感数据的互不信任的一群参与者，共同来执行一个程序，不仅仅是为了控制数据，还可以控制与之关联的资金 假设三个参与者A/B/C，想以相同的概率选择一个号码1/2/3，最终与结果相同者获胜，则方案步骤为： 首先每个人选择一个大的随机数（x/y/z） 为了杜绝某人在知晓其他人的随机值后改变自己的数字，大家只发布随机数对应的哈希值（H(x)/ H(y)/ H(z)） 为了避免某人在知晓其他人的随机值后不公布自己的数字，所有参与者两两交换保证金： 例如A支付给特定脚本一笔交易作为A给B的保证金，输出脚本如下： scriptPubKey: OP_IF OP_CHECKSIGVERIFY OP_CHECKSIG OP_ELSE OP_CHECKSIGVERIFY OP_HASH OP_EQUAL OP_ENDIF 然后A和B同时签名将保证金支付给B，但交易的nLock_Time=t，t>0（所有人需要在t时间内公布自己选择的随机数） scriptSig: 1 A在公布x时，将保证金收回 scriptSig: x 0 同样方法B给A保证金 x/y/z都公布后，最终结果为(x+y+z)%3 应用四：比特币作为一个公共的随机源 密码学“信号塔”（cryptograph beacons）：提供公共随机源的服务，它源源不断在固定频率产生随机数，没人可以预测 方案： 在区块头部设置一个“随机数抽取器”（哈希函数），把所有的输入随机熵均匀压缩成一个随机字符串作为随机信号输出 缺点是不能精确定时，操纵信号所需的代价可能太低 实例： 抽奖：在比特币脚本中加入一个特殊的操作码来读取某一个（例如上一个区块或特定高度的区块）比特币信号塔的随机数，加上多回合的数据协议安全或有时效的函数，最后利用随机数将一个交易的输出分派到n个密钥中的一个，来达到抽奖的目的 应用五：比特币作为一个去中心化的预测市场和真实世界的数据源 预测市场方案： 未来币（Futurecoin） CreateMarket( event_id, arbitrator_key, num_outcomes ) BuyPortfolio( event_id ) TradeShares( … ) SellPortfolio( event_id ) CloseMarket( event_id, outcome_id ) 仲裁方案： 中心化仲裁员 多个仲裁员 用户投票 矿工投票 实时数据供给（真实数据的数据源） 现实密钥（reality keys）： 仲裁者制造出一组密钥，其中每个密钥签名一个事件的结果起到代表作用 仲裁者公布所有密钥的公钥 预测者们将各自的保证金发送到一个比特币输出 仲裁者公布正确结果对应的密钥的私钥 仲裁会面临复杂的难预料的实际情况 交易委托方案： 让矿工撮合两个交易，自己讲两者的差额留下作为交易费 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 14:01:51 "},"bitcoin/develop.html":{"url":"bitcoin/develop.html","title":"开发","keywords":"","body":"开发 区块链结构 魔法数 Magic no 区块大小 Blocksize ​ 区块头 Blockheader： ​ 版本号 Version ​ 前区块Hash值 hashPrevBlock ​ Merkle根节点Hash值 hashMerkleRoot ​ 时间戳 Time ​ 当前目标Hash值 Bits ​ 随机数 Nonce 交易数量 Transaction counter 交易 Transactions ​ 版本号 ​ 输入数量 ​ 输入列表 ​ 输出数量 ​ 输出列表 ​ 锁定时间lock_time bitcoin core：比特币核心（前身是bitcoin-QT，比特币钱包），带有图形界面 bitcoind：比特币核心简洁版、命令行版 调用比特币API的方式 通过bitcoin core 通过bitcoind-cli 通过curl 通过语言库调用 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-18 14:14:40 "},"ethereum/":{"url":"ethereum/","title":"以太坊","keywords":"","body":"以太坊 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"ethereum/operation.html":{"url":"ethereum/operation.html","title":"运行机制","keywords":"","body":"运行机制 DApp：去中心化应用 免权限DApp，有内部货币 授权DApp，无内部货币 DAO，Decentralized Autonomous Organization：去中心化自治组织 DAC：去中心化公司 账户 外有（外部）账户（EOA） 以太币余额 可以发送交易（以太币交易或引发合约代码） 由私钥控制 没有相关代码 合约账户 以太币余额 有相关代码 代码执行由从其他合约接受的交易或信息（调用）触发 执行的时候-执行任意复杂的操作-将会操作它自己的永久区存储 交易 签署的数据包 ​ 信息接收人 ​ 一个签字，确认发送人身份 ​ VALUE域，从发送方面向接收方转移的wei的数量 可选数据域，包括发送到合约的信息 STARTGAS，代表交易执行允许采取的运算步骤的最大数量 GASPRICE，代表发送人愿意支付的gas的价格 消息 合约向其他合约发送消息，像功能调用，与交易类似 ​ 消息发送方 ​ 消息接收方 ​ VALUE域，它和发送到合约地址的消息一起转移的wei的数量 可选数据域，即发送到合约的实际数据 STARTGAS，限制了消息可以触发的代码执行的gas最大值 gas 交易发送方为每个以太坊区块链上发生的操作所支付的执行花费 总成本= gasUsed * gasPrice gasUsed 可以用estimate Gas API 估算 gasPrice 由用户在签署交易时指定，以太坊客户端会默认0.05e12wei 合约 合约一般服务于四个目的： 保持数据库代表着其他合约或外部世界有用的东西 “前向合约”，即作为某种具有更复杂访问政策的外有账户 在多个用户之间管理一个正在进行的合约货关系 软件库 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 15:07:47 "},"ethereum/ethwallet.html":{"url":"ethereum/ethwallet.html","title":"以太坊钱包","keywords":"","body":"以太坊钱包 MetaMask MetaMask是一款在浏览器上使用的插件类型的以太坊钱包，该钱包不需要下载，只需要在谷歌浏览器添加对应的扩展程序即可，非常轻量级，使用起来也非常方便。 Ropsten测试网络水龙头 https://faucet.metamask.io/ Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-15 12:27:10 "},"ethereum/solidity.html":{"url":"ethereum/solidity.html","title":"Solidity","keywords":"","body":"Solidity 中文文档：Solidity 语言依赖 NodeJS是对Google V8引擎进行封装的JS解释器，一种服务器端的JS运行环境 npm是NodeJS的包管理器 nodist是Windows下NodeJS版本管理器 remix是基于浏览器的在线Solidity编译器 Windows本地安装remix时需要安装依赖 npm install --global --production windows-build-tools 合约文件 版本 Import 合约结构 ​ 状态变量 ​ 函数 ​ 结构类型 ​ 枚举类型 ​ 事件 ​ 函数修改器 代码注释 值类型 Solidity语言是静态类型，必须声明时指定类型（除赋值时的类型推断外） 值类型的变量将始终进行值拷贝来传递 布尔类型 ​ bool a = true; 整型 ​ int/uint（从8-256以8步进，如int8，默认256） ​ 负数右移向0取整 定长浮点型 ​ fixed/ufixed fixMxN（默认128x19） 定长字节数组 ​ byte（从1-32以1步进，如byte8，默认1） ​ .length ​ byte[x]，浪费存储空间，尽量使用变长字节数组 有理数和整型字面常数 ​ 没有八进制 ​ 支持任意精度，即在常数表达式中不会溢出也不会被截断 ​ 每个有理数有自己的字面常数类型 字符串字面常数 ​ 没有结尾符 ​ 可隐式转成byte bytes string等 十六进制字面常数 ​ hex开头，如hex“001122ff” ​ byte1 a = hex“aa”; //两位十六进制字符可以表示一字节 枚举 ​ enum Enumexample {A, B, C} ​ 枚举类型不属于 |ABI| 的一部分 函数类型 function () = {internal | external | public | private} [pure | constant | view | payable] [modifierfunc()] [returns ()] 地址类型 ​ 20字节值 ​ 成员变量：balance、transfer()、send()（有风险，尽量使用transfer）、 地址字面常数 ​ 通过了地址校验和测试的十六进制字面常数 引用类型（复杂类型） 数据的位置 复杂类型（数组、结构体）才有数据位置 Memory（内存）：内存中 函数参数（包括返回的参数）值默认memory Storage（存储）：永久存储在区块链中 局部变量值默认storage，状态变量值强制storage calldata：跟memory差不多 外部函数的参数（非返回参数）强制calldata 值传递方式 状态变量 = 函数参数 //拷贝 状态变量 = 状态变量 //拷贝 状态变量 = 内存局部变量 //拷贝 内存局部变量 = 函数参数 //拷贝 内存局部变量 = 状态变量 //拷贝 内存局部变量 = 内存局部变量 //拷贝 存储局部变量 = 状态变量 //引用 数组（Arrays） T[k]、T[]、bytes、string 示例： int[] memory a = new int[](3); //内存变量可使用new创建数组，存储变量不行 int[][5] memory a = [1,2,3,4,5]; //声明时与其他语言不同，长度从右向左读 int b = a[5][0] ; //访问时和其他语言一样，索引从左向右读 new创建的数组和数组字面常数[1,2,3]都是定长的内存类型 内存类型数组只能赋给状态变量或声明了memory的局部变量 数组的成员变量：length，push() .length获取长度，但只有存储数组才能给length赋值来改变数组长度 push()只有变长数组或bytes才能使用 数组的删除： delete a[0]; delete a; //只有非引用变量才可删除 结构体 struct Funder { address a; uint b; } Funder f = Funder({a:msg.sender, b:10}); Funder f = Funder(msg.sender, 10); 结构体不能包含本身 映射类型（Mappings） 可视为哈希表，但实际上不存储 key，而是存储它的 keccak256 哈希值 所以没有key集合和value集合 只有状态变量能使用映射 键值不能是映射、变长数组、合约、枚举、结构体 mapping(address => uint) public balances; LValues LValues是一个变量或者其它可以被赋值的东西 非引用类型的Lvalue变量可以使用delete初始化值（会递归delete） 初始化结果： 静态数组：重置所有元素 动态数组：将长度设为0 映射：遇到映射则无效跳过，但可以使用delete a[xxx]删除单个键值 基本类型转化 隐式转化 一般来说，只要值类型之间的转换在语义上行得通，而且转换的过程中没有信息丢失，那么隐式转换基本都是可以实现的 uint16 a = 0; 显式转化 会发生一些无法预料的后果，因此一定要进行测试，确保结果是你想要的 int8 y = -3; uint x = uint(y); 类型推断 编译器会根据分配该变量的第一个表达式的类型自动推断该变量的类型 var a = 0; //a为uint8 uint24 x = 0x123; var y = x; //y为uint24 以太币单位 wei（默认）、finney、szabo、ether 时间单位 seconds、minutes、hours、days、weeks、years（不再支持） 单位后缀不能直接用在变量后面 控制结构 与C语言和Javascript类似的关键词 if、else、while、do、for、break、continue、return、? : 没有switch和goto ​ Solidity中非布尔类型数值不能转为布尔类型，如不能 if(1) {...} 函数详解 function () = {internal | external | public | private} [pure | constant | view | payable] [modifierfunc()] [returns ()] 函数参数 输入参数 输入参数的声明方式与变量相同。但是有一个例外，未使用的参数可以省略参数名 输出参数 输出参数的声明方式在关键词 returns 之后，与输入参数的声明方式相同，可命名，可多个 function a(int x, int y) public returns (int m, int n){ m = x; n = y; //或 return (x, y) ; //或 (m, n) = (x, y) ; } 元组 元组使用小括号，可用于解构赋值和返回多个结果 var (x, y, z) = f(); (int x, int y, int z) = f(); ( , y, z) = f(); (x, ) = (1, 2); (x, z) = (z, x); 可见性 public（默认） 声明了public的函数是合约接口的一部分，即可内部调用，也可外部调用，比external消耗的gas更多 external 是合约接口的一部分，只能使用外部调用 internal 只能是内部访问（即当前合约或继承的合约里调用），不使用 this 调用 private 仅在当前定义它们的合约中使用，并且不能被继承的合约使用 声明类型 view/constant 视图函数 将函数声明为 view 类型，这种情况下要保证不修改状态 constant 是 view 的别名 Getter 方法被标记为 view 编译器没有强制 view 方法不能修改状态 下面的语句被认为是修改状态： 修改状态变量 产生事件 创建其它合约 使用 selfdestruct 通过调用发送以太币 调用任何没有标记为 view 或者 pure 的函数 使用低级调用 使用包含特定操作码的内联汇编 pure 纯函数 函数可以声明为 pure ，在这种情况下，承诺不读取或修改状态 以下被认为是从状态中读取： 读取状态变量。 访问 this.balance 或者 .balance。 访问 block，tx， msg 中任意成员 （除 msg.sig 和 msg.data 之外）。 调用任何未标记为 pure 的函数。 使用包含某些操作码的内联汇编。 payable 可支付函数 如果一个函数需要进行货币操作，必须要带上payable关键字 调用该函数时，可使用.value(x).gas(y)来设置与函数调用一起发送的 Wei 值和 gas 的数量 contract InfoFeed { function info() public payable returns (uint ret) { return 42; } } contract Consumer { InfoFeed feed; function setFeed(address addr) public { feed = InfoFeed(addr); } function callFeed() public { feed.info.value(10).gas(800)(); } } 修饰器 使用修饰器modifier可以轻松改变函数的行为。 例如，它们可以在执行函数之前自动检查某个条件。 修饰器是合约的可继承属性， 并可能被派生合约覆盖。 如果同一个函数有多个修饰器，它们之间以空格隔开，修饰器会依次检查执行。 修饰器或函数体中显式的 return 语句仅仅跳出当前的修饰器和函数体。 返回变量会被赋值，但整个执行逻辑会从前一个 修饰器中的定义的 “_” 之后继续执行。 修饰器的参数可以是任意表达式，在此上下文中，所有在函数中可见的符号，在 修饰器中均可见。 在 修饰器中引入的符号在函数中不可见（可能被重载改变）。 // 修改器可以接收参数： modifier costs(uint price) { if (msg.value >= price) { _; } } function register() public payable costs(price) { registeredAddresses[msg.sender] = true; } 函数调用类型 内部函数调用 当前合约中的函数可以直接（“从内部”）调用，也可以递归调用 外部函数调用 会产生一个EVM 调用或称为“消息调用” (contact).funcname.value(10).gas(800)(); //使用指定合约变量调用 this.funcname.value(10).gas(800)(); //使用当前合约调用 函数重载 合约可以具有多个不同参数的同名函数。这也适用于继承函数。 重载函数也存在于外部接口中。如果两个外部可见函数仅区别于 Solidity 内的类型而不是它们的外部类型则会导致错误。 通过将当前范围内的函数声明与函数调用中提供的参数相匹配，可以选择重载函数。 如果所有参数都可以隐式地转换为预期类型，则选择函数作为重载候选项。如果一个候选都没有，解析失败。 若参数通过隐式转换能同时匹配多个函数，调用时会导致类型错误。 区块和交易属性函数 block.blockhash(uint blockNumber) returns (bytes32) 指定区块的区块哈希——仅可用于最新的 256 个区块且不包括当前区块；而 blocks 从 0.4.22 版本开始已经不推荐使用，由 blockhash(uint blockNumber) 代替 block.coinbase (address) 挖出当前区块的矿工地址 block.difficulty (uint) 当前区块难度 block.gaslimit (uint) 当前区块 gas 限额 block.number (uint) 当前区块号 block.timestamp (uint) 自 unix epoch 起始当前区块以秒计的时间戳 gasleft() returns (uint256) 剩余的 gas msg.data (bytes) 完整的 calldata msg.gas (uint) 剩余 gas - 自 0.4.21 版本开始已经不推荐使用，由 gesleft() 代替 msg.sender (address) 消息发送者（当前调用） msg.sig (bytes4) calldata 的前 4 字节（也就是函数标识符） msg.value (uint) 随消息发送的 wei 的数量 now (uint) 目前区块时间戳（block.timestamp） tx.gasprice (uint) 交易的 gas 价格 tx.origin (address) 交易发起者（完全的调用链） ABI 编码函数 Application Binary Interface(ABI)：应用二进制接口 abi.encode(...) returns (bytes)： ABI - 对给定参数进行编码 abi.encodePacked(...) returns (bytes) 对给定参数执行 紧打包编码 abi.encodeWithSelector(bytes4 selector, ...) returns (bytes) ABI - 对给定参数进行编码，并以给定的函数选择器作为起始的 4 字节数据一起返回 abi.encodeWithSignature(string signature, ...) returns (bytes) 等价于 abi.encodeWithSelector(bytes4(keccak256(signature), ...) 错误处理函数 错误处理方式：回退所有状态 assert(bool condition) 会消耗gas 如果条件不满足，则使当前交易没有效果 — 用于检查内部错误。 require(bool condition): 不会消耗gas 如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误。 require(bool condition, string message) 如果条件不满足则撤销状态更改 - 用于检查由输入或者外部组件引起的错误，可以同时提供一个错误消息。 revert() 终止运行并撤销状态更改。 revert(string reason) 终止运行并撤销状态更改，可以同时提供一个解释性的字符串。 数学和密码学函数 addmod(uint x, uint y, uint k) returns (uint) 计算 (x + y) % k，加法会在任意精度下执行，并且加法的结果即使超过 2**256 也不会被截取。从 0.5.0 版本的编译器开始会加入对 k != 0 的校验（assert）。 mulmod(uint x, uint y, uint k) returns (uint) 计算 (x * y) % k，乘法会在任意精度下执行，并且乘法的结果即使超过 2**256 也不会被截取。从 0.5.0 版本的编译器开始会加入对 k != 0 的校验（assert）。 keccak256(...) returns (bytes32) 计算 (tightly packed) arguments 的 Ethereum-SHA-3 （Keccak-256）哈希。 sha256(...) returns (bytes32) 计算 (tightly packed) arguments 的 SHA-256 哈希。 sha3(...) returns (bytes32) 等价于 keccak256。 ripemd160(...) returns (bytes20) 计算 (tightly packed) arguments 的 RIPEMD-160 哈希。 ecrecover(bytes32 hash, uint8 v, bytes32 r, bytes32 s) returns (address) 利用椭圆曲线签名恢复与公钥相关的地址，错误返回零值。 (example usage) 地址相关函数 .balance (uint256) 以 Wei 为单位的 地址类型的余额。 .transfer(uint256 amount) 向 地址类型发送数量为 amount 的 Wei，失败时抛出异常，发送 2300 gas 的矿工费，不可调节。 .send(uint256 amount) returns (bool) 向地址类型发送数量为 amount 的 Wei，失败时返回 false，发送 2300 gas 的矿工费用，不可调节。 .call(...) returns (bool) 发出低级函数 CALL，失败时返回 false，发送所有可用 gas，可调节。 .callcode(...) returns (bool) 发出低级函数 CALLCODE，失败时返回 false，发送所有可用 gas，可调节。 .delegatecall(...) returns (bool) 发出低级函数 DELEGATECALL，失败时返回 false，发送所有可用 gas，可调节。 状态变量 可见性 public 会自动创建一个访问器（Getter函数） private 仅在当前定义它们的合约中使用，并且不能被继承的合约使用 internal（默认） 只能是内部访问（即当前合约或继承的合约里调用），不使用 this 调用 Getter函数 编译器自动为所有 public 状态变量创建 getter 函数 pragma solidity ^0.4.0; contract C { uint public data = 42; } contract Caller { C c = new C(); function f() public { uint local = c.data(); } } getter 函数具有外部可见性。如果在内部访问 getter（即没有 this. ），它被认为一个状态变量。 如果它是外部访问的（即用 this. ），它被认为为一个函数。 pragma solidity ^0.4.0; contract C { uint public data; function x() public { data = 3; // 内部访问 uint val = this.data(); // 外部访问 } } 下一个例子稍微复杂一些： pragma solidity ^0.4.0; contract Complex { struct Data { uint a; bytes3 b; mapping (uint => uint) map; } mapping (uint => mapping(bool => Data[])) public data; } 这将会生成以下形式的函数： function data(uint arg1, bool arg2, uint arg3) public returns (uint a, bytes3 b) { a = data[arg1][arg2][arg3].a; b = data[arg1][arg2][arg3].b; } 因为没有好的方法来提供映射的键，所以结构中的映射被省略。 合约详解 创建合约 构造函数 constructor (uint a) public { } 回退函数（Fallback） 合约可以有一个未命名的函数。这个函数不能有参数也不能有返回值。 如果在一个到合约的调用中，没有其他函数与给定的函数标识符匹配（或没有提供调用数据），那么这个函数（fallback 函数）会被执行。 每当合约收到以太币（没有任何数据），这个函数就会执行。此外，为了接收以太币，fallback 函数必须标记为 payable。 如果不存在这样的函数，则合约不能通过常规交易接收以太币。 function() public payable { } 一个合约只能有一个 若合约的调用找不到匹配函数则会调用回退函数 若合约要接收以太币，则必须有声明了payable的回退函数 每当合约接收以太币时，会自动调用回退函数 回退函数应该尽量减少gas消耗（低于 2300 个 gas） 事件 继承 抽象合约 接口 库 代币实现标准ERC-20 EIP是提议，ERC是结果 https://eips.ethereum.org/EIPS/eip-20 https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20.md contract ERC20Interface { uint256 public totalSupply; // //获取token名字，比如：“jiarenminbi” // function name() view returns (string name); // //获取token简称，比如：\"JRMB\" // function symbol() view returns (string symbol); // //获取小数位，比如以太坊的decimals为18：10^18 // function decimals() view returns (uint8 decimals); // //获取token发布的总量,比如：EOS 10亿 // function totalSupply() view returns (uint256 totalSupply); //获取_owner地址的余额 function balanceOf(address _owner) view returns (uint256 balance); //转帐：调用方向_to转_value个token function transfer(address _to, uint256 _value) returns (bool success); //转帐：从_from向_to转_value个token function transferFrom(address _from, address _to, uint256 _value) returns (bool success); //允许_spender从自己（调用方）帐户转走_value个token function approve(address _spender, uint256 _value) returns (bool success); //自己（_owner）查询_spender地址一共可以转走自己多少个token function allowance(address _owner, address _spender) view returns (uint256 remaining); //转帐的时候必须要调用的事件，如transfer,transferFrom方法 event Transfer(address indexed _from, address indexed _to, uint256 _value); //成功执行approve后调用的事件 event Approval(address indexed _owner, address indexed _spender, uint256 _value); } Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-15 12:27:34 "},"ethereum/develop.html":{"url":"ethereum/develop.html","title":"开发","keywords":"","body":"开发 Geth Geth是Go Ethereum开源项目的简称，它是使用Go语言编写且实现了Ethereum协议的客户端软件 创建账号： 使用geth account new 使用geth控制台 > personal.newAccount() 使用Mist以太坊钱包 更新账号： geth account update xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 备份/恢复账号：直接复制/覆盖keystore中的账号钥匙文件 导入未加密私钥： geth account import / 查看以太坊数据： https://EthStats.net https://www.EtherNodes.org 检查连接和ENODE身份 > admin.peers > admin.nodeInfo 更快下载区块链 geth –fast –cache=1024 –jitvm console 导出/导入区块链 geth export filename geth import filename Whisper 以太坊开发人员开发的去中心化的通讯协议 Swarm 以太坊开发人员开发的去中心化的文件系统 Truffle：以太坊智能合约开发环境，测试框架，以太坊的资源管理通道 Ganache：以太坊节点仿真器软件 Truffle 安装Truffle npm install --global --production windows-build-tools //Windows环境需要先安装依赖 npm install -g truffle 创建Truffle项目 truffle unbox xxxxx //or truffle init Truflle项目目录结构 contracts/:智能合约目录，sol文件 migrations/:用作移植的脚本文件，js文件 test/: 测试文件目录，sol或js文件 truffle-config.js: Truffle 配置文件 编译 truffle compile 部署 migrations/中编写移植脚本，然后： truffle migrate 测试 test/中编写测试代码 JS中Web3初始化 设置provider，创建一个web3实例 if (typeof web3 !== 'undefined') { App.web3Provider = web3.currentProvider; } else { // set the provider you want from Web3.providers App.web3Provider = new Web3.providers.HttpProvider(\"http://localhost:8545\"); web = new Web3(App.web3Provider); } JS中初始化合约 获取build/contracts/中的合约json（data） App.contracts.conxxxx = TruffleContract(data); App.contracts.conxxxx.setProvider(App.web3Provider); 合约交互 //获取当前以太坊账户 web3.eth.getAccounts(function(error, accounts){ var account = accounts[0]; //获取合约实例： App.contracts.conxxxx.deployed().then(function(conxxxxInstance){ //调用合约方法： return conxxxxInstance.funname.call(); //or return conxxxxInstance.funname(arg... , {from: account}); }).then(function(resulet){ //TODO }).catch(function(err){ //console.log(err.message); }) }) 交易中的Nonce详解 在比特币中，nonce主要用于调整pow挖矿的难度，而在以太坊中，除了调整挖矿难度外，在外部账户的每笔交易中也都存在一个nonce。这个nonce是一个连续的整数，在每个账户发送交易时所产生，其主要设计目的是为防止双花。 以太坊中有两种nonce，一种是在区块中的nonce，主要是调整挖矿难度；一种是每笔交易中nonce。 每个外部账户（私钥控制的账户）都有一个nonce值，从0开始连续累加，每累加一次，代表一笔交易。 某一地址的某一交易的nonce值如果大于当前的nonce，该交易会被放到交易池的queued列表中，直到缺失的nonce被提交到交易池中。 地址的nonce值是一个连续的整数，起设计的主要目的是防止双花。 在发生一笔交易时，如果不指定nonce值时，节点会根据当前交易池的交易自动计算该笔交易的nonce。有可能会出现节点A和节点B计算的nonce值不一样的情况。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-18 12:50:08 "},"hyperledger/":{"url":"hyperledger/","title":"超级账本","keywords":"","body":"超级账本 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"hyperledger/operation.html":{"url":"hyperledger/operation.html","title":"运行机制","keywords":"","body":"运行机制 区块技术名词 交易（Transaction），一次状态转移操作 区块（Block），交易的集合 链（Chain），区块的顺序排列 区块链类型 公有链 联盟链 * 私有链 区块链特点 去中心化 去信任化 数据共享 不可篡改 区块链平台 比特币，区块链1.0 以太坊，区块链2.0 EOS（企业级区块链操作系统），区块链3.0 超级账本（Fabric） 应用场景 去信任（去中介） 价值转移 数据共享 Hyperledger Fabric 企业级联盟链基础设施 可插拔的共识机制（solo、kafka…） 多链多通道隔离 智能合约 合约协议的数字化代码表达 分布式有限状态机 执行环境安全隔离、不受第三方干扰（EVM、Docker） 链码（Fabric智能合约） Fabric应用层基石（中间件） 编程接口：Init()，Invoke() 系统架构 gRPC：基于HTTP/2、ProtoBuf，多语言支持的RPC框架，可以让客户端应用直接调用服务端应用的方法。 智能合约是业务逻辑的声明和定义，交易是业务逻辑的一次调用 CAP原理 Consistency:一致性 Availability:可用性 Partition tolerance 网络拓扑 节点类型 客户端（应用程序/SDK/命令行工具）节点，连接orderer节点和peer节点 Peer（Anchor/Endorser/Committer）节点 Anchor锚节点/主节点：一个组织只有一个，组织内部唯一与orderer节点通讯的节点 Endorser背书节点：为交易做担保， Commiter记账节点：所有Peer都是，用于验证区块的有效性和交易的有效性 Orderer排序节点：从全网客户端接收交易，将交易进行排序，并将结果打包成区块 Solo排序、Kafka排序... CA节点（可选）：证书颁发机构，鉴明一个区块链的身份是否有效 交易流程 交易背书（模拟@Endorser） 应用程序提交交易提案给背书节点 背书节点进行各种验证检查，然后模拟执行交易提案并签名 背书节点返回模拟执行结果给应用程序 交易排序（排序@Orderer） 应用程序提交带有结果和签名的交易给排序节点 排序节点将交易进行排序并打包成区块 排序节点广播打包好的区块 交易验证/交易存储（验证/存储@Committer） 主节点收到区块验证交易有效性，然后保存区块、更新世界状态 组织内部进行区块同步 记账节点保存区块、更新世界状态 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 18:27:27 "},"hyperledger/consensus.html":{"url":"hyperledger/consensus.html","title":"共识排序","keywords":"","body":"共识排序 Orderer节点从全网客户端接收交易，将交易进行排序，并将结果打包成区块，完成共识 交易排序 目的：保证系统交易顺序的一致性（有限状态机） 排序类型：solo、kafka 区块分发 打包的区块是中间状态区块（非落盘区块/临时区块） 有效交易&无效交易 多通道数据隔离 Orderer节点排序代码解析（solo模式） orderer接口图： chainID 链ID block 区块 （cb.Block） message 交易信封 （cb.Envelope） configTx 配置交易 ​ （cb.Envelope） cb.Envelope Payload + Signature ledgerFactory 账本读写集工厂，可GetOrCreate(chainID)一个ledger （ledger.Factory） ledger 账本读写对象，可用来获取最新configTx，可append(block) （ledger.ReadWriter） ledgerResource 账本资源对象，包含一个ledger （api.Manager） （api.Resouce） （configupdate.Support） multiLedger （multichain.Manager） （multichain.chainCreator） 多链manager实现类，包含一个ledgerFactory、一个chainSupport集、一个Consenter集、一个 systemChannel系统链 可newLedgerResources(configTx)一个ledgerResouce 可newChain(configTx)一个chainSupport 可GetChain(chainID)获取chainSupport chainSupport 链对象代理实现类，包含一个ledgerResouce、一个chain、一个cutter （multichain.ChainSupport）， （multichain.ConsenterSupport） 可CreateNextBlock(messages)将交易打包成一个区块 可WriteBlock(block, committers, encodedMetadataValue)将区块写入账本 可Enqueue(message) 将交易排入队列 可start()启动chain的main函数 cutter 区块切割对象 （blockcutter.Receiver） Ordered(message) 对message交易进行排序并返回要打包的交易数组 Cut() 直接返回所有待切割交易（意味着直接打包） 切割规则依据： 配置交易需要单独切割成区块 非单个交易的区块不能大于区块预设大小 单个区块的交易数量不能大于等于区块预设交易数量 solo.chain solo模式链对象实例 （multichain.Chain） main()： 监听交易队列 -> 新交易排序 -> 排序时有切割则持久化区块 有待切割交易且区块超时 -> 直接切割持久化区块 solo.consenter solo模式共识机制实例 （multichain.Consenter） 可HandleChain(cs, metadata)创建chain broadcast.Handle 实现orderer的broadcast服务，收到消息验证后调用Enqueue deliver.Handle 实现orderer的deliver服务，收到消息验证后返回区块 kafka模式的设计思路 在Hyperledger Fabric最新发布的1.0版本里，分拆出来Orderer组件用于交易的排序及共识。现阶段提供solo及kafka两种方式的实现。solo模式不用多讲，即整个集群就一个Orderer节点，区块链的交易顺序即为它收到交易的顺序。而kafka模式的Orderer相对较复杂，在实现之初都有多种备选方案，但最终选择了现在大家所看到的实现方式。那么其中的选型过程是怎么样的呢？我想将开发者Kostas Christidis的设计思路给大家解析一番，既是翻译也是我自身的理解。 Kafka模式的Orderer服务包含Kafka集群及相关联的Zookeeper集群，以及许多OSN（ordering service node）。 ordering service client可以与多个OSN连接，OSN之间并不直接通信，他们仅仅和Kafka集群通信。 OSN的主要作用： client认证 允许client使用SDK与Channel交互 过滤并验证configure transactions，比如重新配置channel或者创建新channel的transaction。 我们都知道，Messages(Records)是被写入到Kafka的某个Topic Partition。Kafka集群可以有多个Topic，每个Topic也可以有多个Partition。每个Partition是一个排序的、持久化的Record序列，并可以持续添加。 假设每个channel有不同的Partition。那么OSNs通过client认证及transaction过滤之后，可以将发过来的transaction放到特定channel的相关Partition中。之后，OSNs就可以消费这些Partition的数据，并得到经过排序后的Transaction列表。这对所有的OSN都是通用的。 在这种情况下，每一TX都是不同的Block。OSNs将每一个TX都打包成一个区块，区块的编号就是Kafka集群分配给TX的偏移编号，然后签名该区块。任意建立了Kafka消费者的Deliver RPCs都可以消费该区块。 这种解决方案是可以运行的，但是会有以下问题： 假设1秒有1000个Transactions，Ordering 现在就必须1秒生成1000个签名。并且接收端的clients必须能够在1秒里验证1000个签名。但通常签名和验证都是非常耗时的，这种情况下会非常棘手。所以为了避免一个区块只有一个交易的情况，引入batch机制。假设一个batch包含1000个交易，那么Ordering现在只需要生成1个签名，client也只需要验证1个签名。 如果发往Ordering的交易速度并不均匀，假设Ordering需要发出包含1000个交易的batch，现在已经有了999个交易存储在内存中，只需要等待1个交易就可以生成新的batch，但就是没有交易发往Ordering了。这时候前面的999个交易就被动延迟了，这当然是不可接受的。所以我们需要batch定时器，当有交易作为新batch的首个交易时启动定时器，只要batch达到最大交易数量或者定时器到点了，该batch都会形成新的区块。 但是呢，基于时间分割区块需要在Orderer之间协调时间。以交易数量分割区块是容易的，对任意的OSN来说，都会得到相同的区块。现在假设batch定时器设置为1秒，有两个OSN。刚刚生成了batch，这时候一笔新的交易通过OSN1进入到Kafka中。OSN2在时间t=5s的时候读取该交易，并设置了在t=6s的时候timeout。OSN1在时间t=5.6s的时候读取该交易，并设置了自己相应的timeout时间。下一笔交易被发送到Partition的末端，OSN2在t=6.2s的时候读取了该tx，而OSN1在t=6.5s的时候读取了该交易。这时候就会发现，OSN1的当前区块包含了2笔交易，而OSN2的区块只包含了前一笔交易。现在这两个OSN产生了不同的区块序列，这是不可接受的。因此，依照时间分割区块需要明确的协调信号。我们假设每个OSN在分割区块之前都向Partition发出消息“是时候分割区块X啦”（X是区块序列的下一个编号，TTC-X），并且不会真正的分割区块直到接收到任意TTC-X消息。接受到的这个消息不必一定是自己发出的，如果每个OSN都等待自己的消息，我们又得不到相同序列了。每个OSN分割区块，要么获取batchSize笔交易，或者接收到第一个TTC-X消息，无论哪种方式都会得到一致的区块，这也意味着所有的子序列TTC-X消息都会被忽略。 与例子中的每笔交易放在不同的区块不同，区块的编号现在没有被转换为Kafka的偏移量编号。所以如果Ordering服务接收到一个Deliver请求，让从区块5开始返回区块，这时候就根本不知道让消费者查找哪个偏移量。或许我们可以使用区块消息里的Metadata字段，让OSN标记该区块的偏移量区间（区块4的Metadata：offsets：63-64）。这样如果client想获取从区块5到区块9的数据，这样就可以从65开始读取，OSN重置Partition的日志到偏移量65，按照之前定义的batchsize和batchtimeout读取区块。但是有两个问题，1、我们违背了Deliver API协议，需要区块编号作为参数；2、如果client已经丢失了很多区块，并只想从区块 X开始同步区块，这时候就不知道正确的偏移量编号了，OSN也同样不能解决这个问题。所以每个OSN需要每个channel维护一张表，内容为区块编号到该区块的偏移量起始值的映射。这也就意味着一个OSN除非维护一张lookup表，否则不能应答Deliver请求。lookup表移除了区块metadata，也能快速定位区块偏移编号。OSN将请求的区块编号转换成正确的偏移编号，并启动Kafka消费者获取该区块。 无论何时OSN收到Deliver请求，都会从请求的区块编号开始查询所有的交易，并签名。打包操作和签名操作每次都被重复触发，代价很高。为解决这个问题，我们创建另一个Partition（Partition1），之前的Partition我们标记为Partition0。现在无论什么时候OSN分割区块的时候，都将分割后的结果放入Partition1，这样所有的Deliver请求都使用Partition1. 因为每个OSN都将其分割区块结果放入到Partition1中，因此Partition1中的区块序列并不是真正的channel的区块序列，且有重复。 这就意味着Kafka的偏移编号不能和OSN的区块编号对应起来，所以也需要建立区块编号到偏移量的lookup表。 现在在Partition1中现在有冗余的区块。Deliver请求不仅仅是建立Kafka消费者，从偏移量开始向后查找交易记录那么简单。lookup表需要随时被查询，deliver的逻辑变得更加复杂，查询lookup表增加了额外的延迟。是什么造成了Partition接受了冗余的数据呢？是Partition0的TTC-X消息么？还是被发往Partition1的消息和之前的消息一致或者相似？如何解决冗余的消息呢？我们先定义一条规则：如果Partition1已经接收到相同的消息（不算签名），那么就不再向Partition1添加该消息。在上面的例子中，如果OSN1已经知道Block3已经被OSN2放入到Partition1中了，OSN1将终止该操作。那么这样就可以降低冗余消息。当然不能完全消除他们，因为肯定有OSNs在相同时间插入相同的消息，这是无法避免的。 如果我们选举Leader OSN，它负责将区块写入到Partition1呢？有几种方法选举Leader：可以让所有的OSNs竞争ZooKeeper的znode，或者第一个发送TTC-X消息到Partition0的OSN。另外一个有趣的方法就是让所有的OSNs都属于相同的Kafka消费者组，意味着每笔交易只会被消费一次，那么无论哪个OSN消费了该交易，都会生成相同的区块序列。 如果Leader发送区块X消息，消息还未到达Partition1时Leader崩溃了，这时候会如何呢？其他OSNs意识到Leader崩溃了，因为Leader已经不再拥有znode，这时候会选举新的Leader。这时候新的Leader发现区块X还在他这里，还没有被发送到Partition1，所以他发送区块X到Partition1。同时，旧Leader的区块X消息也发送到了Partition1，消息又冗余了。 我们可以使用Kafka的日志压缩功能。 如果我们启用日志压缩，我们完全可以删除所有的冗余消息。当然我们假设所有的区块X消息拥有相同的key，X不同时，key也不同。但是因为日志压缩保存的是最新版本的key，所以OSNs可能会拥有陈旧的lookup表。假设上图的中key对应的是区块。OSN收到的前两个消息在本地的lookup表中有映射关系，同时，Partition被压缩成上图下方的部分，这时候查询偏移0/1会返回错误消息。另外一个问题就是Partition1中的区块不能逆向存储，所以Deliver逻辑同样复杂。事实上，仅仅考虑到lookup表的过期问题，日志压缩就不是一个好的方案。 所以没有一个很好的解决方案解决这个问题，我们回到问题5，创建另一个Partition1，解决重复分割、签名block的问题，我们可以摒弃这种方案，让每个OSN在本地保存每个channel的区块文件。 Delivery请求现在只需要顺序的读取本地ledger，没有冗余数据，没有lookup表。OSN只需要保存最后读取的偏移量，这样在重联之后就可以知道从哪里开始重新消费Kafka的消息。 一个缺点可能就是比直接通过Kafka提供服务慢，但是我们也从来不是直接从Kafka提供服务，本来就有一些操作需要OSNs本地进行，比如签名。 综上，ordering 服务使用一个单Partition（每channel）接收客户端的交易消息和TTC-X消息，在本地存储区块（每channel），这种解决方案能够在性能和复杂度之间取得较好的平衡。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-12 18:24:33 "},"hyperledger/ledger_storage.html":{"url":"hyperledger/ledger_storage.html","title":"账本存储","keywords":"","body":"账本存储 概要 交易流程 交易模拟 -> 产出读写集（TxRwSet），交易中读取了什么写入了什么 交易排序 交易验证 -> 产出更新包（UpdateBatch），并执行更新 验证 读集版本号（算上未提交的前序有效写集交易后） ?== 世界状态版本号，若不等于则无效 交易读写集（TxRwSet） 读集：读取的已提交的状态健（值） 写集：将要更新的状态键值对、状态键值对删除标记、多次更新以最后一次为准 版本号：二元组（区块高度、交易编号） 区块提交 保存区块文件 更新世界状态 更新历史状态（可选） 存储方式 区块链：文件系统 区块索引：LevelDB 状态数据库：LevelDB/CouchDB，区块链上的最新数据 历史状态索引：LevelDB，历史数据，存储状态更新的交易索引 世界状态 交易执行后的所有键的最新值 显著提升链码执行效率 状态时所有交易日志的快照可随时重构 LevelDB or CouchDB，可切换 ​ CouchDB可以存储结构化数据，支持模糊查询，支持更多应用场景，但需要网络接入 LevelDB组合键（namespace + 0x00 + key）（namespace = 账本ID+链码ID） 历史数据索引（可选） 记录某键在某区块的某条交易中被改变 只记录改变动作，不记录具体改变 历史读取 --> 历史数据索引 + 区块读取 LevelDB组合键（namespace + 0x00 + key + 0x00 +blocknum + trannum） 区块存储 区块以文件块形式存储（Blockfile_xxxxxx） 文件块大小：64M（硬编码） 账本最大容量：64M*1000000 区块读取 区块文件流（blockfileStream）：读取文件块 区块流（blockStream）：在一个文件块中读取区块 区块迭代器（blocksItr）：在整个链条中读取区块 区块索引 快速定位区块 索引键：区块高度/区块哈希/交易哈希/... 索引值：区块文件编号+文件内偏移量+区块数据长度 账本简单的说，是一系列有序的、不可篡改的状态转移记录日志。状态转移是链码（chaincode）执行（交易）的结果，每个交易都是通过增删改操作提交一系列键值对到账本。一系列有序的交易被打包成块，这样就将账本串联成了区块链。同时，一个状态数据库维护账本当前的状态，因此也被叫做世界状态。现阶段，每个通道都有其账本，每个Peer节点都保存着其加入的通道的账本。 链 链实际上是交易日志，被结构化成哈希串起来的块，每个块包含N个有序交易。区块头信息里包含该区块所包含的所有交易的哈希（通过默克尔树实现），同时也包含前一个区块的哈希。这样，账本里的所有交易都被有序存储，并使用密码学强关联在一起。换句话说，账本的数据不可能被篡改，除非破坏哈希链。最新区块的哈希值实际上包含了从创始区块以来的所有交易，任何细微的改变都会使得当前区块的哈希变得不同。 状态数据库 账本当前状态数据实际上就是所有曾经在交易中出现的键值对的最新值。调用链码执行交易可以改变状态数据，为了高效的执行链码调用，所有数据的最新值都被存放在状态数据库中。就逻辑上来说，状态数据库仅仅是有序交易日志的快照，因此在任何时候都可以根据交易日志重新生成。状态数据库会在peer节点启动的时候自动恢复或重构，未完备前，该节点不会接受新的交易。 状态数据库的选择 状态数据库可以使用LevelDB或者CouchDB。LevelDB是默认的内置的数据库，CouchDB是额外的第三方数据库。跟LevelDB一样，CouchDB也能够存储任意的二进制数据，但是作为JSON文件存储数据库，CouchDB额外的支撑JSON富文本查询，如果链码的键值对存储的是JSON，那么可以很好的利用CouchDB的富文本查询功能。 两个数据库都支持链码的基本接口，设置键值对，获取键值对，键查询，区间键查询，组合键查询等等。 如果使用JSON结构化链码数据，可以使用CouchDB的JSON查询语言进行富文本查询，这样可以简单直观的理解账本里的数据。但是，虽然富文本查询对客户端应用程序来说是直观有效的，但是对Orderer不是很友好，不能保证结果的正确性，因为链码的模拟和区块提交是有时差的，中间的数据改变是富文本查询感知不到的。因此建议只在链码查询接口里使用富文本查询。 CouchDB是外置的第三方数据库，因此需要额外的管理成本，所以建议开始时使用内置LevelDB存储，在需要富文本查询时再切换成CouchDB。再者，最好使用JSON结构化链码数据结构，这样未来的扩展性会很好。 源码分析 接口定义 上面简要分析了Fabric的账本要点，为了更深入的理解，源代码分析必不可少。先看接口： PeerLedgerProvider // PeerLedgerProvider用于管理账本 type PeerLedgerProvider interface { // Create方法创建一个新账本，参数为创始块。创建账本&提交创世块这两个操作是原子的。 // 创世块其实是一个配置信息块，包含Configure Transaction，具体可看configtxgen Create(genesisBlock *common.Block) (PeerLedger, error) // Open方法打开已存在的账本 Open(ledgerID string) (PeerLedger, error) // Exists方法判断某个账本是否存在 Exists(ledgerID string) (bool, error) // List方法列出当前节点的所有账本名字 List() ([]string, error) // Close方法关闭该接口 Close() } PeerLedger // PeerLedger type PeerLedger interface { commonledger.Ledger // 从0.6版本继承过来的接口，用于管理本地的区块 // GetTransactionByID方法根据交易id获取交易详情 GetTransactionByID(txID string) (*peer.ProcessedTransaction, error) // GetBlockByHash方法根据区块哈希获取区块详情 GetBlockByHash(blockHash []byte) (*common.Block, error) // GetBlockByTxID方法根据交易ID获取区块详情 GetBlockByTxID(txID string) (*common.Block, error) // GetTxValidationCodeByTxID方法根据交易ID获取交易验证编码 GetTxValidationCodeByTxID(txID string) (peer.TxValidationCode, error) // NewTxSimulator返回交易模拟器，客户端可以并行的获取多个交易模拟器 NewTxSimulator() (TxSimulator, error) // NewQueryExecutor返回查询执行器，客户端可以并行的获取多个查询执行器 NewQueryExecutor() (QueryExecutor, error) // NewHistoryQueryExecutor返回历史数据查询执行器，客户端可以并行的获取多个历史数据查询执行器 NewHistoryQueryExecutor() (HistoryQueryExecutor, error) //Prune方法根据传递的削减策略削减区块/交易 Prune(policy commonledger.PrunePolicy) error } QueryExecutor // QueryExecutor用于执行查询 // Get*方法支持KV数据模型的查询. ExecuteQuery方法用于富文本查询 type QueryExecutor interface { // GetState方法查找特定namespace下某key的值，对链码来说，namespace就是chaincodeId GetState(namespace string, key string) ([]byte, error) // GetStateMultipleKeys方法查找特定namespace下一系列key的值 GetStateMultipleKeys(namespace string, keys []string) ([][]byte, error) // GetStateRangeScanIterator方法返回一个迭代器，其包含给定的key区间里所有的键值对（startKey包含在内，endKey排除在外）。空字符串的startKey表示第一个可用的key，空字符串的endKey表示最后一个可用的key GetStateRangeScanIterator(namespace string, startKey string, endKey string) (commonledger.ResultsIterator, error) // ExecuteQuery方法执行传递的查询语句并返回包含相关数据集的迭代器 ExecuteQuery(namespace, query string) (commonledger.ResultsIterator, error) // Done方法释放资源 Done() } TxSimulator // TxSimulator模拟执行交易 // Set*相关方法执行KV数据模型的执行. ExecuteUpdate方法支持富文本操作 type TxSimulator interface { QueryExecutor // 交易模拟器包含查询执行器 // SetState方法设置对应namespace下的key的当前value SetState(namespace string, key string, value []byte) error // DeleteState方法删除指定namespace下对应的key DeleteState(namespace string, key string) error // SetMultipleKeys方法设置对应namespace下多个key的value SetStateMultipleKeys(namespace string, kvs map[string][]byte) error // ExecuteUpdate方法支持富文本操作 ExecuteUpdate(query string) error // GetTxSimulationResults方法包裹交易模拟结果 GetTxSimulationResults() ([]byte, error) } HistoryQueryExecutor // HistoryQueryExecutor执行历史查询 type HistoryQueryExecutor interface { // GetHistoryForKey方法返回key的历史数据迭代器 GetHistoryForKey(namespace string, key string) (commonledger.ResultsIterator, error) } Ledger // Ledger接口 type Ledger interface { // GetBlockchainInfo返回区块链基本信息 GetBlockchainInfo() (*common.BlockchainInfo, error) // GetBlockByNumber根据区块编号返回区块信息 GetBlockByNumber(blockNumber uint64) (*common.Block, error) // GetBlocksIterator返回区块迭代器，区块起始位置为startBlockNumber GetBlocksIterator(startBlockNumber uint64) (ResultsIterator, error) // Close方法关闭账本 Close() // Commit方法提交新的区块到账本里 Commit(block *common.Block) error } 接口实现 至此，Fabric的账本接口基本介绍完毕，应该能大致看出其账本的设计思路。但还未涉及到具体的实现。接下来，我们深入到具体实现里，去看看基于LevelDB的状态数据库实现、历史数据库实现及本地账本的实现。 首先，深入kv_ledger_provider.go文件： // Provider实现了接口ledger.PeerLedgerProvider type Provider struct { idStore *idStore blockStoreProvider blkstorage.BlockStoreProvider vdbProvider statedb.VersionedDBProvider historydbProvider historydb.HistoryDBProvider } type idStore struct { db *leveldbhelper.DB } 可以看到，该Provider里包含了本地账本Provider，状态数据库Provider，历史数据库Provider以及idStore。idStore内部封装了LevelDB的接口，存储的是多通道的标识。KVLedgerProvider的层次还是在多链多通道的高度，剥离ledgerID，我们进入单链结构。一个链由账本数据库、状态数据库及历史数据库组成。 历史数据库 // HistoryDBProvider provides an instance of a history DB type HistoryDBProvider interface { // GetDBHandle returns a handle to a HistoryDB GetDBHandle(id string) (HistoryDB, error) // Close closes all the HistoryDB instances and releases any resources held by HistoryDBProvider Close() } // HistoryDBProvider implements interface HistoryDBProvider type HistoryDBProvider struct { dbProvider *leveldbhelper.Provider } HistoryDBProvider实现了HistoryDBProvider接口，内部封装了一个LevelDB对象，可根据dbName返回不同的历史数据库。 // HistoryDB - an interface that a history database should implement type HistoryDB interface { NewHistoryQueryExecutor(blockStore blkstorage.BlockStore) (ledger.HistoryQueryExecutor, error) Commit(block *common.Block) error GetLastSavepoint() (*version.Height, error) ShouldRecover(lastAvailableBlock uint64) (bool, uint64, error) CommitLostBlock(block *common.Block) error } // historyDB implements HistoryDB interface type historyDB struct { db *leveldbhelper.DBHandle dbName string } HistoryDB接口定义了历史数据库可以进行的操作，而内部类historyDB实现了该接口。 GetLastSavepoint方法获取历史数据库最后一次更新的区块编号及交易索引（封装在Height类中），LastSavepoint的记录实现方法就是在commit区块的时候，更新savePointKey键值对，然后由GetLastSavepoint方法读取该键值对，得到最后提交点数据。 ShouldRecover方法判断是否需要重构历史数据库，返回值为1:、是否需要；2、需要从哪个块开始重构；3、错误消息。实现方法很简单，就是将参数lastAvailableBlock跟GetLastSavepoint方法返回的区块编号进行对比，如果不一样就需要重构，重构点为savepoint的区块编号+1。 CommitLostBlock方法是Commit方法的一层封装。下面我们详细剖析Commit方法的实现： // Commit implements method in HistoryDB interface func (historyDB *historyDB) Commit(block *common.Block) error { blockNo := block.Header.Number // 当前处理区块的编号 var tranNo uint64 // 初始化交易编号为0，代表区块xx的第0个交易 dbBatch := leveldbhelper.NewUpdateBatch() // 数据库批量更新事物 txsFilter := util.TxValidationFlags(block.Metadata.Metadata[common.BlockMetadataIndex_TRANSACTIONS_FILTER]) if len(txsFilter) == 0 { txsFilter = util.NewTxValidationFlags(len(block.Data.Data)) block.Metadata.Metadata[common.BlockMetadataIndex_TRANSACTIONS_FILTER] = txsFilter } // 获取区块交易的状态过滤，（区块中的交易不是所有都是有效的，但历史数据库中只记录有效交易） // 循环读取交易 for _, envBytes := range block.Data.Data { // If the tran is marked as invalid, skip it if txsFilter.IsInvalid(int(tranNo)) { tranNo++ continue } // 如果该交易是无效的，略过，并自增交易编号 env, err := putils.GetEnvelopeFromBlock(envBytes) if err != nil { return err } // 反序列化交易信封 payload, err := putils.GetPayload(env) if err != nil { return err } // 反序列化交易负载 chdr, err := putils.UnmarshalChannelHeader(payload.Header.ChannelHeader) if err != nil { return err } // 反序列化交易头 // 如果不是endorser交易，则略过 if common.HeaderType(chdr.Type) == common.HeaderType_ENDORSER_TRANSACTION { respPayload, err := putils.GetActionFromEnvelope(envBytes) if err != nil { return err } // 反序列化交易背书结果 txRWSet := &rwsetutil.TxRwSet{} if err = txRWSet.FromProtoBytes(respPayload.Results); err != nil { return err } // 从背书交易结果中反序列化交易读写集 // 循环交易读写集 for _, nsRWSet := range txRWSet.NsRwSets { ns := nsRWSet.NameSpace // 链码id // 循环交易读写集的写集 for _, kvWrite := range nsRWSet.KvRwSet.Writes { writeKey := kvWrite.Key // 将ns、写key、区块编号、交易编号合并成一个组合key compositeHistoryKey := historydb.ConstructCompositeHistoryKey(ns, writeKey, blockNo, tranNo) // 将组合key写入事物 dbBatch.Put(compositeHistoryKey, emptyValue) } } } tranNo++ // 处理完一个交易，自增交易编号 } // 处理完一个区块，就更新savepoint height := version.NewHeight(blockNo, tranNo) dbBatch.Put(savePointKey, height.ToBytes()) // 向db写数据 if err := historyDB.db.WriteBatch(dbBatch, false); err != nil { return err } return nil } 需要注意的是，历史数据库并不存储key的值，而只存储在某个区块的某个交易里，某key变动了一次。后续需要查询的时候，根据变动历史去查询实际变动的值，这就是HistoryQueryExecutor的作用。NewHistoryQueryExecutor方法接受一个实际存储数据的账本作为参数，返回HistoryQueryExecutor。 // LevelHistoryDBQueryExecutor is a query executor against the LevelDB history DB type LevelHistoryDBQueryExecutor struct { historyDB *historyDB blockStore blkstorage.BlockStore } // GetHistoryForKey implements method in interface `ledger.HistoryQueryExecutor` func (q *LevelHistoryDBQueryExecutor) GetHistoryForKey(namespace string, key string) (commonledger.ResultsIterator, error) { if ledgerconfig.IsHistoryDBEnabled() == false { return nil, errors.New(\"History tracking not enabled - historyDatabase is false\") } var compositeStartKey []byte var compositeEndKey []byte compositeStartKey = historydb.ConstructPartialCompositeHistoryKey(namespace, key, false) compositeEndKey = historydb.ConstructPartialCompositeHistoryKey(namespace, key, true) // range scan to find any history records starting with namespace~key dbItr := q.historyDB.db.GetIterator(compositeStartKey, compositeEndKey) return newHistoryScanner(compositeStartKey, namespace, key, dbItr, q.blockStore), nil } //historyScanner implements ResultsIterator for iterating through history results type historyScanner struct { compositePartialKey []byte //compositePartialKey includes namespace~key namespace string key string dbItr iterator.Iterator blockStore blkstorage.BlockStore } GetHistoryForKey方法将传递过来的key组合后，生成一个startKey和一个endKey，LevelDB可以进行key的模糊查询，基于此功能，从historyDB的LevelDB接口中获取key区间的迭代器，然后生成historyScanner，该类实现了ResultsIterator接口，基于此接口，就可以进行key的历史数据查询了。 func (scanner *historyScanner) Next() (commonledger.QueryResult, error) { if !scanner.dbItr.Next() { return nil, nil } // LevelDB的迭代器没数据了，直接就返回 historyKey := scanner.dbItr.Key() // ns+key+区块编号+交易编号 _, blockNumTranNumBytes := historydb.SplitCompositeHistoryKey(historyKey, scanner.compositePartialKey) // 分割出区块编号+交易编号 blockNum, bytesConsumed := util.DecodeOrderPreservingVarUint64(blockNumTranNumBytes[0:]) tranNum, _ := util.DecodeOrderPreservingVarUint64(blockNumTranNumBytes[bytesConsumed:]) // 获取区块编号、交易编号（二进制分割） tranEnvelope, err := scanner.blockStore.RetrieveTxByBlockNumTranNum(blockNum, tranNum) if err != nil { return nil, err } // 获取跟当前key相关的交易信息 queryResult, err := getKeyModificationFromTran(tranEnvelope, scanner.namespace, scanner.key) if err != nil { return nil, err } // 获取当前查询结果 return queryResult, nil } // getTxIDandKeyWriteValueFromTran inspects a transaction for writes to a given key func getKeyModificationFromTran(tranEnvelope *common.Envelope, namespace string, key string) (commonledger.QueryResult, error) { payload, err := putils.GetPayload(tranEnvelope) if err != nil { return nil, err } tx, err := putils.GetTransaction(payload.Data) if err != nil { return nil, err } _, respPayload, err := putils.GetPayloads(tx.Actions[0]) if err != nil { return nil, err } chdr, err := putils.UnmarshalChannelHeader(payload.Header.ChannelHeader) if err != nil { return nil, err } txID := chdr.TxId timestamp := chdr.Timestamp txRWSet := &rwsetutil.TxRwSet{} if err = txRWSet.FromProtoBytes(respPayload.Results); err != nil { return nil, err } // 在之前的分析中已存在 // 在交易读写集中查询该key，得到就返回查询结果，如果没有，就报错 for _, nsRWSet := range txRWSet.NsRwSets { if nsRWSet.NameSpace == namespace { for _, kvWrite := range nsRWSet.KvRwSet.Writes { if kvWrite.Key == key { return &queryresult.KeyModification{TxId: txID, Value: kvWrite.Value, Timestamp: timestamp, IsDelete: kvWrite.IsDelete}, nil } } return nil, errors.New(\"Key not found in namespace's writeset\") } } return nil, errors.New(\"Namespace not found in transaction's ReadWriteSets\") } 至此，我们应当对历史数据库的实现有了一定的认识。下面介绍状态数据库： 状态数据库 状态数据库的实现现在有两种方式，LevelDB以及CouchDB。这里暂时不剖析CouchDB实现的状态数据库。 // VersionedDBProvider接口定义如何管理VersionedDB type VersionedDBProvider interface { GetDBHandle(id string) (VersionedDB, error) Close() } // VersionedDB接口定义状态数据库应该有哪些操作 type VersionedDB interface { // GetState方法返回key当前值 GetState(namespace string, key string) (*VersionedValue, error) // GetStateMultipleKeys方法多个key的当前值 GetStateMultipleKeys(namespace string, keys []string) ([]*VersionedValue, error) // GetStateRangeScanIterator方法返回key区间的键值对迭代器 GetStateRangeScanIterator(namespace string, startKey string, endKey string) (ResultsIterator, error) // ExecuteQuery方法执行富文本查询，LevelDB版本未实现该方法，略过 ExecuteQuery(namespace, query string) (ResultsIterator, error) // ApplyUpdates方法更新数据库 ApplyUpdates(batch *UpdateBatch, height *version.Height) error // GetLatestSavePoint方法返回最后一次更新的区块交易编号 GetLatestSavePoint() (*version.Height, error) // ValidateKey方法校验key，LevelDB略过 ValidateKey(key string) error // Open opens the db Open() error // Close closes the db Close() } 在阅读源码时还需注意，状态数据库的kv不仅仅是string，他们是特定类型的序列化： // CompositeKey包括ns和key type CompositeKey struct { Namespace string Key string } // VersionedValue包含值和当前的version，version跟区块编号相关 type VersionedValue struct { Value []byte Version *version.Height } // VersionedKV 联合 key 和 value type VersionedKV struct { CompositeKey VersionedValue } 下面看LevelDB版本的StateDB，代码里叫VersionedDB。 // GetState implements method in VersionedDB interface func (vdb *versionedDB) GetState(namespace string, key string) (*statedb.VersionedValue, error) { compositeKey := constructCompositeKey(namespace, key) // 将ns和key组合成一个key dbVal, err := vdb.db.Get(compositeKey) if err != nil { return nil, err } // 通过LevelDB接口获取key的值 if dbVal == nil { return nil, nil } // 解析数据库中的value，封装成VersionedValue val, ver := statedb.DecodeValue(dbVal) return &statedb.VersionedValue{Value: val, Version: ver}, nil } GetStateMultipleKeys方法即循环调用GetState，无需详解 GetStateRangeScanIterator方法利用LevelDB的key模糊查询，返回LevelDB迭代器。再使用kvScanner封装读操作。 // ApplyUpdates implements method in VersionedDB interface func (vdb *versionedDB) ApplyUpdates(batch *statedb.UpdateBatch, height *version.Height) error { dbBatch := leveldbhelper.NewUpdateBatch() // 数据库事物 namespaces := batch.GetUpdatedNamespaces() // 更新batch的ns列表 for _, ns := range namespaces { // 循环ns列表 updates := batch.GetUpdates(ns) for k, vv := range updates { // 循环ns的更新列表 compositeKey := constructCompositeKey(ns, k) if vv.Value == nil { dbBatch.Delete(compositeKey) } else { dbBatch.Put(compositeKey, statedb.EncodeValue(vv.Value, vv.Version)) } // 根据更新，将对应操作插入数据库事物中 } } dbBatch.Put(savePointKey, height.ToBytes()) if err := vdb.db.WriteBatch(dbBatch, false); err != nil { return err } // 更新savepoint return nil } 相较历史状态数据库，状态数据库更简单，它不用关心区块或者交易，仅仅只关心key的最新值就可以了。 账本数据库 Fabric的账本是基于文件系统，将区块存储于文件块中，在LevelDB中存储区块交易对应的文件块及其偏移。账本数据库同样有Provider和相应的DB实现，翻阅代码发现实际上主体是blockfileMgr这个类实现相关的业务逻辑。该管理器有以下管理功能： 管理文件存储路径 管理存储区块的独立文件 追踪最新文件的 checkpoint 管理区块和交易的索引 当管理器启动的时候，它会去检测当前是第一次启动还是重启。区块文件在文件系统中以顺序编号存储，同时每个文件块都有固定的大小，例如：blockfile_000000，blockfile_000001等。 每个交易在存储的时候都记录了该交易的大小： Adding txLoc [fileSuffixNum=0, offset=3, bytesLength=104] for tx [1:0] to index Adding txLoc [fileSuffixNum=0, offset=107, bytesLength=104] for tx [1:1] to index 区块在存储的时候，不仅存储区块交易的信息，同时存储交易位置偏移量信息。 在该manager启动的时候，会执行以下操作： 检查存储文件的路径是否存在，不存在则创建 检查索引数据库是否存在，不存在则创建 设置checkpoint： 从数据库读取cpinfo，如果不存在，创建新的cpinfo 如果cpinfo是从数据库中读取的，则开始和文件系统比较 如果cpinfo和文件系统不同步，那么从文件系统重新生成cpinfo 启动新的文件writer，在checkpoint截断文件 处理区块和交易的索引信息 实例化新的blockIdxInfo 如果数据库中存在索引了，载入blockIdxInfo 同步索引 通过APIs更新区块链信息 以上6点就是初始化mananger的过程。接下来，我们分拆fsblkstorage的底层支撑类。 首先看区块是如何序列化的。 // 序列化block类，包含三个字段，区块头信息、区块元信息以及区块里包含的交易信息 type serializedBlockInfo struct { blockHeader *common.BlockHeader txOffsets []*txindexInfo metadata *common.BlockMetadata } //交易索引类标识了该交易在当前区块的偏移量以及交易数据长度 type txindexInfo struct { txID string loc *locPointer } // 该方法揭示了如何序列化区块。简单的说就是将区块头、交易数据、元数据以顺序的方式通过protobuffer的序列化后拼接在一起，形成byte数组，二进制数据流。随后就可将该数据流通过文件writer写入文件块 func serializeBlock(block *common.Block) ([]byte, *serializedBlockInfo, error) { buf := proto.NewBuffer(nil) var err error info := &serializedBlockInfo{} info.blockHeader = block.Header info.metadata = block.Metadata if err = addHeaderBytes(block.Header, buf); err != nil { return nil, nil, err } if info.txOffsets, err = addDataBytes(block.Data, buf); err != nil { return nil, nil, err } if err = addMetadataBytes(block.Metadata, buf); err != nil { return nil, nil, err } return buf.Bytes(), info, nil } // 该类同时还有些序列化，反序列化方法。基本是Protobuffer的序列化方法的封装，不深究 上面揭示了区块是如何序列化以及反序列化的。下面介绍文件块是如何读取的： // blockfileStream类从单个文件读取区块 type blockfileStream struct { fileNum int // 文件块编号（000000,000001） file *os.File // 文件对象 reader *bufio.Reader // 缓存读对象 currentOffset int64 // 当前文件读取偏移量 } // blockStream类读取多个文件块 type blockStream struct { rootDir string // 文件块的目录 currentFileNum int // 当前文件块编号 endFileNum int // 结束文件块编号 currentFileStream *blockfileStream // 封装的当前文件块的读取流对象 } // blockPlacementInfo类封装了区块在文件块中的位置信息 type blockPlacementInfo struct { fileNum int // 文件块编号 blockStartOffset int64 // 区块在文件块的起始偏移量 blockBytesOffset int64 // 区块的长度 } blockfileStream 和 blockStream 都有 nextBlockBytes、nextBlockBytesAndPlacementInfo和close方法。分别是获取下一个区块的数据流、和区块相对位置以及关闭文件块流。 同时，封装了文件块的writer和reader，方法基本同标准库保持一致。 接下来，剖析账本数据库的索引系统，文件模式的区块存储方式如果没有快速定位的索引信息，那么查询区块交易信息可能是噩梦。Fabric使用LevelDB作为文件块的索引实现方式。下面详解： 现阶段支持的索引有： 区块编号 区块哈希 交易ID索引交易 区块交易编号 交易ID索引区块 交易ID索引交易验证码 同时，Fabric定义了index接口，可以定制索引的实现： type index interface { getLastBlockIndexed() (uint64, error) // 获取最后被索引的区块编号 indexBlock(blockIdxInfo *blockIdxInfo) error // 创建区块索引 getBlockLocByHash(blockHash []byte) (*fileLocPointer, error) // 通过区块哈希获取区块位置 getBlockLocByBlockNum(blockNum uint64) (*fileLocPointer, error) // 通过区块编号获取区块位置 getTxLoc(txID string) (*fileLocPointer, error) // 通过交易ID获取交易位置 getTXLocByBlockNumTranNum(blockNum uint64, tranNum uint64) (*fileLocPointer, error) // 通过区块交易编号获取交易位置 getBlockLocByTxID(txID string) (*fileLocPointer, error) // 通过交易ID获取区块位置 getTxValidationCodeByTxID(txID string) (peer.TxValidationCode, error) // 通过交易ID获取交易验证码 } getLastBlockIndexed方法的实现就是在LevelDB中存储了个键值对，每次创建区块索引后更新该键值对； indexBlock方法是创建索引的唯一方法，它接收blockIdxInfo类为参数，依次生成6个索引，方式就是组合查询键，值为所在文件偏移位置。交易偏移是区块偏移和交易相对偏移的组合。 剩下的几个方法就是读取索引了，略过。 最后还剩下一个迭代器，其实现就是整合上面介绍类的整合应用。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-15 22:15:59 "},"hyperledger/develop.html":{"url":"hyperledger/develop.html","title":"开发","keywords":"","body":"开发 环境准备 Docker环境（Docker、Docker Compose） GO语言环境 Fabric组件Docker镜像 ​ fabric-peer、fabric-orderer、fabric-tools、fabric-baseos # docker pull hyperledger/fabric-peer:latest # docker pull hyperledger/fabric-orderer:latest # docker pull hyperledger/fabric-tools:latest # docker pull hyperledger/fabric-ccenv:latest # docker pull hyperledger/fabric-baseos:latest # docker pull hyperledger/fabric-kafka:latest # docker pull hyperledger/fabric-zookeeper:latest # docker pull hyperledger/fabric-couchdb:latest # docker pull hyperledger/fabric-ca:latest Fabric源码库 -> release-1.0（go get） cryptogen、configtxgen工具编译（go install） 官方示例 fabric-samples（go get） ​ first-network/ -> ​ ./byfn.sh -m generate -c hikari //生成相应证书和创世区块 ​ ./byfn.sh -m up -c hikari //通过docker compose启动网络 网络启动 配置crypto-config.yaml设置组织、节点、成员结构 使用crytogen生成公私钥和证书文件 配置configtx.yaml设置联盟、系统链、组织的结构、组织和锚节点的访问地址和MSP地址 使用configtxgen生成系统链创世区块、生成通道创世交易、生成锚节点交易（可选） 创建docker-compose.yaml文件，配置order节点容器、各peer节点容器、cli容器 启动docker-compose docker-compose up -d //关闭是 docker-compose down docker exec -it cli bash //进入客户端容器(cli)控制台 peer /与peer节点交互的工具 利用peer工具： 利用通道创世交易创建通道 peer channel create 将当前cli连接的peer节点加入通道 peer channel join 设置主节点 peer channel update 安装链码 peer chaincode install 实例化链码 peer chaincode instantiate 指令笔记 设置工作路径 export FABRIC_CFG_PATH=$GOPATH/src/github.com/hyperledger/fabric/imocc/deploy 环境清理 rm -fr config/* rm -fr crypto-config/* 生成证书文件 cryptogen generate --config=./crypto-config.yaml 生成创世区块 configtxgen -profile OneOrgOrdererGenesis -outputBlock ./config/genesis.block 生成通道的创世交易 configtxgen -profile TwoOrgChannel -outputCreateChannelTx ./config/mychannel.tx -channelID mychannel configtxgen -profile TwoOrgChannel -outputCreateChannelTx ./config/assetschannel.tx -channelID assetschannel 生成组织关于通道的锚节点（主节点）交易 configtxgen -profile TwoOrgChannel -outputAnchorPeersUpdate ./config/Org0MSPanchors.tx -channelID mychannel -asOrg Org0MSP configtxgen -profile TwoOrgChannel -outputAnchorPeersUpdate ./config/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 启动容器 docker-compose up -d 进入客户端容器cli控制台 docker exec -it cli bash 创建通道 peer channel create -o orderer.imocc.com:7050 -c mychannel -f /etc/hyperledger/config/mychannel.tx peer channel create -o orderer.imocc.com:7050 -c assetschannel -f /etc/hyperledger/config/assetschannel.tx 加入通道 peer channel join -b mychannel.block peer channel join -b assetschannel.block 设置主节点 peer channel update -o orderer.imocc.com:7050 -c mychannel -f /etc/hyperledger/config/Org1MSPanchors.tx 链码安装 peer chaincode install -n badexample -v 1.0.0 -l golang -p github.com/chaincode/badexample peer chaincode install -n assets -v 1.0.0 -l golang -p github.com/chaincode/assetsExchange 链码实例化 peer chaincode instantiate -o orderer.imocc.com:7050 -C mychannel -n badexample -l golang -v 1.0.0 -c '{\"Args\":[\"init\"]}' peer chaincode instantiate -o orderer.imocc.com:7050 -C assetschannel -n assets -l golang -v 1.0.0 -c '{\"Args\":[\"init\"]}' 链码交互 peer chaincode invoke -C assetschannel -n assets -c '{\"Args\":[\"userRegister\", \"user1\", \"user1\"]}' peer chaincode invoke -C assetschannel -n assets -c '{\"Args\":[\"assetEnroll\", \"asset1\", \"asset1\", \"metadata\", \"user1\"]}' peer chaincode invoke -C assetschannel -n assets -c '{\"Args\":[\"userRegister\", \"user2\", \"user2\"]}' peer chaincode invoke -C assetschannel -n assets -c '{\"Args\":[\"assetExchange\", \"user1\", \"asset1\", \"user2\"]}' peer chaincode invoke -C assetschannel -n assets -c '{\"Args\":[\"userDestroy\", \"user1\"]}' 链码升级 peer chaincode install -n assets -v 1.0.1 -l golang -p github.com/chaincode/assetsExchange peer chaincode upgrade -C assetschannel -n assets -v 1.0.1 -c '{\"Args\":[\"\"]}' 链码查询 peer chaincode query -C mychannel -n badexample -c '{\"Args\":[]}' peer chaincode query -C assetschannel -n assets -c '{\"Args\":[\"queryUser\", \"user1\"]}' peer chaincode query -C assetschannel -n assets -c '{\"Args\":[\"queryAsset\", \"asset1\"]}' peer chaincode query -C assetschannel -n assets -c '{\"Args\":[\"queryUser\", \"user2\"]}' peer chaincode query -C assetschannel -n assets -c '{\"Args\":[\"queryAssetHistory\", \"asset1\"]}' peer chaincode query -C assetschannel -n assets -c '{\"Args\":[\"queryAssetHistory\", \"asset1\", \"all\"]}' 命令行模式的背书策略 在链码实例化peer chaincode instantiate时，添加-P 参数值： EXPR(E[,E...]) EXPR = OR AND E = EXPR(E[,E...]) MSP.ROLE MSP 组织名 org0MSP org1MSP ROLE admin member 示例： -P “OR('org0MSP.member','org1MSP.admin')” 打印日志 docker ps -a //查看容器名 docker logs 容器名 链码调试 dev模式省去了编译链码镜像的过程 在docker-compose.yaml中的peer.base里添加dev模式配置： command: peer node start --peer-chaincodedev=true environment: - CORE_CHAINCODE_MODE=dev CORE_CHAINCODE_ID_NAME=assets:1.0.1 CORE_PEER_ADDRESS=0.0.0.0:27051 CORE_CHAINCODE_LOGGING_LEVEL=DEBUG go run -tags=nopkcs11 assetsExchange.go 外部服务剖析 如何提供服务？ 决定于应用场景 终端用户 智能硬件 socket/tcp 太阳能发电 游戏、电商、社交 web/app http 企业内部 rpc(grpc) 如何选择SDK? nodejs 4星 java 3星 golang 1星 构造交易、发送交易、数据查询 SDK的模块 区块链管理 通道创建&加入 链码的安装、实例化、升级等 admin | 云服务提供商 数据查询 区块 交易 区块浏览器 ethscan eospark block-explorer 区块链交互 发起交易 invoke query 事件监听 业务事件 SendEvent 系统事件 block/trancastion Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-16 01:07:05 "},"hyperledger/chaincode.html":{"url":"hyperledger/chaincode.html","title":"链码","keywords":"","body":"链码 生命周期 打包：智能合约代码编码 安装：上传到背书节点 实例化：执行Init() 升级：对链码进行版本升级 交互：查询写入 5种系统链码 LSCC（Lifecycle System Chaincode）生命周期管理链码，安装、实例化、升级 CSCC（Configuration System Chaincode）配置管理链码，如允许节点加入链 QSCC（Query System Chaincode）账本查询链码，区块索引的外部服务 ESCC（Endorsement System Chaincode）交易背书链码，对交易模拟结果进行封装、签名 VSCC（Validation System Chaincode）交易验证链码 链码编程接口（shim.Chaincode） 链码要继承shim.Chaincode接口 Init(stub shim.ChaincodeStubInterface) pb.Response //用于链码初始化 Invoke(stub shim.ChaincodeStubInterface) pb.Response //应用程序与链码交互的入口 stub shim.ChaincodeStubInterface是链码SDK接口 链码SDK接口（shim.ChaincodeStubInterface） 参数解析 GetArgs() [][]byte //以byte数组的数组的形式获得传入的参数列表 GetStringArgs() []string //以字符串数组的形式获得传入的参数列表 GetFunctionAndParameters() (string, []string) //将字符串数组的参数分为两部分，数组第一个字是Function，剩下的都是Parameter GetArgsSlice() ([]byte, error) //以byte切片的形式获得参数列表 交易信息 GetTxID() string //获取交易ID 状态操作 GetState(key string) ([]byte, error) //获取状态 PutState(key string, value []byte) error //更新状态 DelState(key string) error //删除状态 GetStateByRange(startKey, endKey string) (StateQueryIteratorInterface, error) //获取状态区间 GetStateByPartialCompositeKey(objectType string, keys []string) (StateQueryIteratorInterface, error) //部分复合键的查询 CreateCompositeKey(objectType string, attributes []string) (string, error) //生成复合键 SplitCompositeKey(compositeKey string) (string, []string, error) //拆分复合键 GetQueryResult(query string) (StateQueryIteratorInterface, error) //富查询 GetHistoryForKey(key string) (HistoryQueryIteratorInterface, error) //历史数据查询 链码互操作(只读) InvokeChaincode(chaincodeName string, args [][]byte, channel string) pb.Response //调用另外的链码 事件相关 SetEvent(name string, payload []byte) error //发送事件 其他 GetCreator() ([]byte, error) //获取当前用户的用户证书 GetSignedProposal() (*pb.SignedProposal, error) //获得签名的提案 GetTransient() (map[string][]byte, error) //获得Transient对象 GetTxTimestamp() (*timestamp.Timestamp, error) //获得交易时间戳 GetBinding() ([]byte, error) //获得Binding对象 交互方法套路 检查参数的个数 验证参数的正确性 验证数据是否存在 应该存在 or 不应该存在 其他逻辑验证 写入状态 链码编程禁忌 分布式系统、多节点隔离执行，必须保证执行结果一致 随机函数 系统时间 不稳定的外部依赖 应用开发流程 需求整理（数据上链、交互方法） 链码编写 链码交互 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-15 22:27:34 "},"blockchain/":{"url":"blockchain/","title":"区块链","keywords":"","body":"Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-18 12:58:36 "},"blockchain/blockchainwallet.html":{"url":"blockchain/blockchainwallet.html","title":"区块链钱包","keywords":"","body":"区块链钱包 开发钱包之前，我们需要有以下的预备知识。 第一，什么是钱包，以及相关的分类。 本文站在开发者的角度，给读者讲解下怎么样和钱包进行交互，以及如何开发一个钱包。 我们怎么样理解钱包呢？简单讲它是连接区块链的一个入口。目前比较成熟的公链，如比特币、以太坊都有很多钱包可以选择。一般钱包需要完全访问你的用户资产，也就是会要求你输入私钥。钱包的作恶成本极低，这也是笔者建议选择开源钱包的原因之一。 第二，需要了解下什么是 RPC、JSON-RPC 以及 JSON。 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。[1] RPC 的主要功能目标是让构建分布式计算（应用）更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。 RPC 调用分为以下两种： 同步调用，客户方等待调用执行完成并返回结果。 异步调用，客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果。 异步和同步的区分在于是否等待服务端执行完成并返回结果。 远程过程调用是一个分布式计算的客户端 - 服务器（Client/Server）的例子，它简单而又广受欢迎。远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。由于存在各式各样的变体和细节差异，对应地派生了各式远程过程调用协议，而且它们并不互相兼容。其中我们广为使用的是一个叫做 JSON-RPC 的协议。 JSON-RPC，是一个无状态且轻量级的远程过程调用（RPC）传送协议，其传递内容通过 JSON 为主。相较于一般的 REST 通过网址（如 GET /user）调用远程服务器，JSON-RPC 直接在内容中定义了欲调用的函数名称（如 {“method”: “getUser”}），这也令开发者不会陷于该使用 PUT 或者 PATCH 的问题之中。 本规范主要定义了一些数据结构及其相关的处理规则。它允许运行在基于 Socket、HTTP 等诸多不同消息传输环境的同一进程中。其使用 JSON（RFC 4627）作为数据格式。[2] JSON-RPC 使用了 JSON 格式，那 JSON 是什么呢？ JSON（JavaScript Object Notation）是一种轻量级的数据交换语言。 使用 JSON 做数据交换的好处在于，一是兼容性高，二是可阅读性高，三是支持较多的数据格式（比如 number, string, booleans, nulls, array, associative array），四是支持的语言较多。 第三，了解区块链相关的基础知识。 了解区块链，书籍资料不用，一本 精通比特币 足矣。这里就不赘述了。 第四，掌握一门开发语言。 如果你是一门经验丰富的程序员，此条预备知识可以忽略。如果你是一名非计算机科班出身的区块链技术爱好者，建议从 Python 入手。同时，多了解下 JavaScript。 0x01 怎么样开发 假设我们把预备知识都了解了，接下来我们需要阅读比特币和以太坊的 RPC 接口。 我们以比特币为例，根据 Original Bitcoin client/API calls list 文档我们可以得到 RPC 接口提供的函数列表。 以 sendrawtransaction 为例，这个函数列表提供了四列（Command、Parameters、Description、Requires unlocked wallet? ），分别表示函数名、传入参数、描述、是否需要解锁钱包。 我们把这个函数列表掌握之后，可以选择某一种语言，然后进行区块链钱包相关的开发。 当然，你还需要知道怎么样去部署一个比特币的完全节点和测试网络，这样就可以利用 RPC 进行接口调用，来和区块链网络进行交互。 0x02 相关文档以及源码 这里列出主流项目相关的 RPC 接口以及开源钱包项目，以供读者参考。 2.1 Bitcoin 2.1.1 RPC Original Bitcoin client/API calls list API reference (JSON-RPC)) JSON RPC API 2.1.2 Wallet Bitcoin Core，官方出品 bitcoinj，比特币协议 Java 版 bither，简单安全的比特币钱包 Electrum，全平台轻钱包 bread，iOS 钱包 Mycelium，Android 钱包 Copay，同时支持 Bitcoin 和 Bitcoin Cash bitcoin-wallet，又一款 Android 钱包 DotNetWallet，.NET 实现的钱包 Coinpunk，基于浏览器的钱包 btcwallet，Go 实现的钱包 2.2 Ethereum/ERC20 2.2.1 RPC JSON RPC JSON RPC API Management APIs ethjsonrpc web3.py 2.2.2 Wallet go-ethereum，以太坊协议 Go 版 Mist，官方出品 Parity，支持 Windows、Mac、PC 的钱包 MetaMask MyEtherWallet，基于浏览器的钱包 eth-lightwallet，轻量级 JavasSript 版本钱包 ethaddress.org，纸质版钱包生成器 Иeureal Wallet，支持 Windows、Mac、PC 的钱包 2.3其他 2.3.1 Zcash Zcash，官方出品 2.3.2 BitShares BitShares，官方出品 2.3.3 Sia Sia，官方出品 2.3.4 Nem NanoWallet，官方出品 2.3.5 Dash Dash，官方出品 2.3.6 Qtum Qtum Core Wallet，官方出品 2.3.7 Litecoin Litecoin，官方出品 2.3.8 IOTA IOTA Wallet，官方出品 2.3.9 Monero Monero，官方出品 2.3.10 GXS GXS Wallet for mobile，官方出品 2.3.11 Ethereum Classic Ethereum Classic Wallet，官方出品 0x03 小结 本文讲解了开发钱包的预备知识，包括第一是什么是钱包，以及相关的分类，第二是 RPC、JSON-RPC 以及 JSON，第三是了解区块链相关的基础知识，第四是掌握一门开发语言。接着浅谈了怎么样开发，最后列出了主流项目相关的 RPC 接口以及开源钱包项目。如果读者对钱包开发感兴趣，希望本文能够给读者一个指引。 数字货币交易所钱包，主要业务就是对接各个虚拟币的主链，进行消息通信，交易上链。 主要的实现核心都是： 开启RPC，http 访问接口 分配用户唯一钱包地址，标识不同用户 获取交易列表，确认用户充值信息 发送金额至不同的钱包地址（提币） 类似于支付宝，支付宝对接的是银行，交易所钱包对接的是虚拟币主链。有过支付中心设计的小伙伴完全可以把设计支付中心的各种设计应用于交易所钱包设计 私钥是保证你数字货币安全的最重要的一环，当你生成一个普通私钥的同时，它就会保存到你手机上，当你用你这个私钥对应的地址进行交易的同时，会要求你输入钱包密码，实际上就是对私钥进行解密的过程，用你这个私钥进行签名，交易就会广播出去，完成交易。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-21 23:41:47 "},"network/":{"url":"network/","title":"网络安全","keywords":"","body":"网络 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-21 22:12:39 "},"network/protocol.html":{"url":"network/protocol.html","title":"TCP/IP、UDP、HTTP协议","keywords":"","body":"TCP/IP、UDP、HTTP协议 OSI（Open System Interconnect）七层参考模型 物理层 – 数据链路层 – 网络层 – 传输层 – 会话层 – 表示层 – 应用层 网中各节点都有相同的层次 不同节点的同等层具有相同的功能 同一节点内相邻层之间通过接口通信 每一层使用下层提供的服务，并向其上层提供服务 不同节点的同等层按照协议实现对等层之间的通信 物理层协议： 负责0、1 比特流（0/1序列）与电压的高低、逛的闪灭之间的转换。规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性；该层为上层协议提供了一个传输数据的物理媒体，只是说明标准。 在这一层，数据的单位称为比特（bit）（注：bit和字节Byte，我们常说的1字节8位2进制即：1B=8bit）。属于物理层定义的典型规范代表包括：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45、fddi令牌环网。 数据链路层协议： 负责物理层面上的互联的、节点间的通信传输（例如一个以太网项链的2个节点之间的通信）；该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 在这一层，数据的单位称为帧（frame）。数据链路层协议的代表包括：ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等。 网络层协议： 将数据传输到目标地址；目标地址可以使多个网络通过路由器连接而成的某一个地址，主要负责寻找地址和路由选择，网络层还可以实现拥塞控制、网际互连等功能。 在这一层，数据的单位称为数据包（packet）。网络层协议的代表包括：IP、IPX、RIP、OSPF等。 传输层协议（核心层）： 传输层是OSI中最重要、最关键的一层,是唯一负责总体的数据传输和数据控制的一层； 传输层提供端到端的交换数据的机制，检查分组编号与次序，传输层对其上三层如会话层等，提供可靠的传输服务,对网络层提供可靠的目的地站点信息主要功能。在这一层，数据的单位称为数据段（segment）。主要功能： ①：为端到端连接提供传输服务。 ②：这种传输服务分为可靠和不可靠的,其中Tcp是典型的可靠传输,而Udp则是不可靠传输。 ③：为端到端连接提供流量控制,差错控制,服务质量(Quality of Service,QoS)等管理服务。 包括的协议如下： TCP：传输控制协议，传输效率低，可靠性强。 UDP：用户数据报协议，适用于传输可靠性要求不高，数据量小的数据。 DCCP、SCTP、RTP、RSVP、PPTP等协议。 会话层协议： 负责建立和断开通信连接（数据流动的逻辑通路），记忆数据的分隔等数据传输相关的管理。 表示层协议：将数据格式转换为标准格式 　　将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式；主要负责数据格式的转换，确保一个系统的应用层信息可被另一个系统应用层读取。具体来说，就是将设备固有的数据格式转换为网络标准传输格式，不同设备对同一比特流解释的结果可能会不同；因此，主要负责使它们保持一致。 应用层协议： ①：超文本传输协议HTTP：这是一种最基本的客户机/服务器的访问协议；浏览器向服务器发送请求，而服务器回应相应的网页。 ②：文件传送协议FTP：提供交互式的访问，基于客户服务器模式，面向连接 使用TCP可靠的运输服务。主要功能:减少/消除不同操作系统下文件的不兼容性。 ③：远程登录协议TELNET：客户服务器模式，能适应许多计算机和操作系统的差异，网络虚拟终端NVT的意义。 ④：简单邮件传送协议SMTP：Client/Server模式，面向连接。基本功能：写信、传送、报告传送情况、显示信件、接收方处理信件。 ⑤：DNS域名解析协议：DNS是一种用以将域名转换为IP地址的Internet服务。 ⑥：简单文件传送协议TFTP：客户服务器模式，使用UDP数据报，只支持文件传输，不支持交互，TFTP代码占内存小。 ⑦：简单网络管理协议（SNMP）: SNMP模型的4个组件：被管理结点、管理站、管理信息、管理协议。SNMP代理：运行SNMP管理进程的被管理结点。 ⑧：DHCP动态主机配置协议: 发现协议中的引导文件名、空终止符、属名或者空,DHCP供应协议中的受限目录路径名 Options –可选参数字段，参考定义选择列表中的选择文件。 TCP/IP（Transmission Control Protocol/Internet Protocol）协议 传输控制协议/因特网互联协议，又名网络通讯协议，是Internet最基本的协议、Internet国际互联网络的基础。包括 ARP，ICMP，IGMP，UDP，以及让域名访问成为可能的DNS，以及电脑/手机可以自动获取IP地址的DHCP，还有形形色色的应用层的协议如 HTTP / SMTP / FTP 等。 通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台电脑规定一个地址。 TCP/IP的四层模型： IP（Internet Protocol）协议 IP协议是将多个包交换网络连接起来，它在源地址和目的地址之间传送一种称之为数据包的东西，它还提供对数据大小的重新组装功能，以适应不同网络对包大小的要求。IP协议在OSI参考模型中应用于网络层，以“数据包（Package）”为单位。 IP协议特点 IP协议是一种无连接、不可靠的分组传送服务的协议。 IP协议是点-点线路的网络层通信协议。IP协议是针对原主机-路由器、路由器-路由器、路由器-目的主机之间的数据传输的点-点线路的网络层通信协议。 IP协议屏蔽了网络在数据链路层、物理层协议与实现技术上的差异。：通过IP协议，网络层向传输层提供的是统一的IP分组，传输层不需要考虑互联网在数据链路层、物理层协议与实现技术上的差异，IP协议使得异构网络的互联变得容易了。 IPV4 地址32位，数据报首部的长度是以4个字节为单位，长度可以是20-60字节，这跟首部的HLEN字段有关，格式如下： 首部长度：这个4位字段定义了数据报首部的长度，以4字节的字为单位。当首部没有选项时，首部长度位20字节；当这个字段值位最大值F时，首部长度最大为60字节。 服务类型：在最初这个字段有一部分用于定义数据报的优先级，剩下的一部分定义了服务类型。IETF已经改变了这个8位字段的解释，现在定义了一组区分服务。在这种解释种，前6位构成了码点（codepoint），最后两位未使用。当码点字段最右边的3位不全为0时，这6位定义了54种服务，低延时，高吞吐量等等。 总长度：这个16位字段定义了数据报总长度，其以字节为单位。故IPv4数据报总长度上限值位65536字节。注：为什么需要这个字段？在许多情况下，我们确实不需要这个字段值。但是有些情况下，封装在一个帧里的并不仅仅是数据报，还可能附加了一些填充。比如，以太网协议对帧的数据有最大值（1500字节）和最小值（46字节）的限制，当数据小于46字节时，数据将含有填充数据。 标识（identification）：这个16位字段标志了从源主机发出的一个数据报，这样就确定了数据报的唯一性。这样使得数据报被分片后，在到达终点时终点能根据标识号将同一个数据报的分片重新组装成一个数据报。 标志（flag）：第一位保留（未用），第二位为“不分片（do not fragment）”，第三位位“还有分片（more fragment）”。 分片偏移：这个13位字段表示的是分片在整个数据报中的相对位置。这是数据在原始数据报中的偏移量，以8字节位单位。 生存时间：这个8位字段用来控制数据报所经过的最大跳数（路由器），每经过一个路由器，这个字段数值都减1，减1后变位0时，路由器就丢弃这个数据报。 · 协议：这个8位字段定义了使用IPv4服务的高层协议，如TCP，UDP，ICMP，IGMP，OSPF等的数据都将被封装到IP数据报中。这个字段指明数据报必须交付给哪个最终目的协议。 检验和：检验IP数据报首部。 源地址：定义了源点的IP地址，这个字段始终保持不变。 目的地址：定义了终点的IP地址，这个字段始终保持不变。 IP地址分为A、B、C、D 、E五类，把32位的地址分为两个部分：前面的部分代表网络地址，后面部分是主机地址（局域网地址）。网络掩码(Netmask) 限制了网络的范围，1代表网络部分，0代表设备地址部分。A类保留给政府机构，B类分配给中等规模的公司，C类分配给任何需要的人，D类用于组播，E类用于实验。 A类地址： 1.0.0.1~126.155.255.254，以“0”开始，1字节网络地址3字节主机地址 10.X.X.X是私有地址（在互联网上不使用，而被用在局域网络中的地址） 127.X.X.X是保留地址，用做循环测试用的 默认子网掩码：255.0.0.0 B类地址： 128.0.0.1~191.255.255.254，以“10”开始，2字节网络地址2字节主机地址 默认子网掩码：255.255.0.0 172.16.0.0~172.31.255.255是私有地址 169.254.X.X是保留地址。如果你的IP地址是自动获取IP地址，而你在网络上又没有找到可用的DHCP服务器，就会得到其中一个IP C类地址： 192.0.0.1~223.255.255.254，网络地址的最高位必须是“110”，3字节网络地址1字节主机地址 192.168.X.X是私有地址 默认子网掩码：255.255.255.0 D类地址： 224.0.0.1~239.255.255.254，以“1110”开始，不分网络地址和主机地址，用于多点广播 E类地址： 240.0.0.1~255.255.255.254，以“11110”开始，不分网络地址和主机地址，将来使用 IPV6 地址128位， 冒分十六进制表示法： 格式为X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示 0位压缩表示法： 在某些情况下，一个IPv6地址中问可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中”::”只能出现一次。 内嵌IPv4地址表示法： 为了实现IPv4-IPv6互通，IPv4地址会嵌入IPv6地址中，此时地址常表示为：X:X:X:X:X:X:d.d.d.d 报文格式如下： TCP（Transmission Control Protocol）协议 TCP工作在网络OSI的七层模型中的第四层——Transport层（传输层），IP在第三层——Network层，ARP 在第二层——Data Link层。在第二层的数据，我们把它叫Frame（数据帧），在第三层的数据叫Packet（数据包），第四层的数据叫Segment（数据段）。 同时，我们需要简单的知道，数据从应用层发下来，会在每一层都会加上头部信息，进行封装，然后再发送到数据接收端。所以数据的发送和接收其实就是数据的封装和解封装的过程。 TCP报文格式： Source Port和Destination Port：分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程， 而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接； Sequence Number：用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的第一个数据 字节在数据流中的序号；主要用来解决网络报乱序的问题； Acknowledgment Number：32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志(下面介绍)为1时该确认序列号的字 段才有效。主要用来解决不丢包的问题； Offset：给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit(最多能 表示15个32bit的字，即4*15=60个字节的首部长度)，因此TCP最多有60字节的首部。然而，没有任选字段， 正常的长度是20字节； TCP Flags: TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次 为URG，ACK，PSH，RST，SYN，FIN。 URG：此标志表示TCP包的紧急指针域(后面马上就要说到)有效，用来保证TCP连接不被中断，并且督促 中间层设备要尽快处理这些数据； ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0； PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队； RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包； SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1， ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手； Window：窗口大小，也就是有名的滑动窗口，用来进行流量控制。这是一个复杂的问题，本文不再论述。 TCP协议的三次握手： 　　TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。如下图TCP的通信过程所示： 三次握手具体过程（状态）如下（其实可以类比打电话的过程：甲打电话，并等待接听→乙收到来电显示，“并表示可以接听”→“甲收到乙可以接听的信息”，甲接听电话。注：引号部分是打电话过程中没有的，但在TCP三次握手中存在）： 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认。（客户的建立连接并等待确认） 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段(即SYN+ACK报文段)中，一并发送给客户端，此时服务器进入SYN_RECV状态。（服务器端发送相关报文段信息并等待连接） 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。（客户的接收到服务端信息并实现连接） 　　然后，客户端和服务端就能实现正常的数据传输啦！ TCP协议的四次分手： 具体过程（状态）如下（同样也可以看做挂电话的过程：我说完了，挂？→我也说完了，挂吧？→好，拜拜→bye。简言之就是确认通信双方都交流完毕再确认断开连接）： 第一次分手：主机1(可以是客户端，也可以是服务器端)，设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了。（一方数据发送完成） 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我也没有数据要发送了，可以进行关闭连接了。（另一方数据发送完成） 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入CLOSE_WAIT状态。（请求关闭连接并等待） 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL（Maximum Segment Lifetime，“最长报文段寿命”）后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。（关闭连接） 现在，我们也应该理解为什么TCP协议是面向连接的、可靠的、基于IP协议的“通信控制协议”了。TCP的三次握手保证了数据的可靠性，保证资源不被浪费，而四次分手保证连接的可靠性而不至于随意断开连接，但TCP协议也由其可靠性，数据传输效率变得较低，而不像UDP那样进行实时快速传输。 UDP（User Datagram Protocol）协议 UDP （User Datagram Protocol的简称），用户数据报协议，是OSI参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，IETF RFC 768是UDP的正式规范。UDP在IP报文的协议号是17。 与TCP协议一样，UDP协议直接位于IP协议的顶层。根据OSI参考模型，UDP和TCP都属于传输层协议。UDP协议的主要作用是将网络数据流量压缩成数据包的形式。一个典型的数据包就是一个二进制数据的传输单位。每一个数据包的前8个字节用来包含报头信息，剩余字节则用来包含具体的传输数据。 UDP报文格式 与TCP协议不同，UDP协议是非面向连接的不可靠协议，因此没有了SYN等处理两端等待或连接的报文段，相比之下，UDP的报文格式更为简单，主要由报文头（由均16位的源端口号、目的端口号、UDP长度和UDP校验和组成）和具体传输数据组成。如图所示： UDP长度：UDP报文的整个大小，最小为8个字节（16*4位）（仅为首部）。 UDP检验和：在进行检验和计算时，会添加一个伪首部一起进行运算。伪首部（占用12个字节）为：4个字节的源IP地址、4个字节的目的IP地址、1个字节的0、一个字节的数字17、以及占用2个字节UDP长度。这个伪首部不是报文的真正首部，只是引入为了计算校验和。相对于IP协议的只计算首部，UDP检验和会把首部和数据一起进行校验。接收端进行的校验和与UDP报文中的校验和相与，如果无差错应该全为1。如果有误，则将报文丢弃或者发给应用层、并附上差错警告。 UDP特性 UDP是一个无连接协议，传输数据之前源端和终端不建立连接，当 UDP想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息。 UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小。 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制。 UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表（这里面有许多参数）。 UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界，因此，应用程序需要选择合适的报文大小。 虽然UDP是一个不可靠的协议，但它是分发信息的一个理想协议。例如，在屏幕上报告股票市场、在屏幕上显示航空信息等等。UDP也用在路由信息协议RIP（Routing Information Protocol）中修改路由表。在这些应用场合下，如果有一个消息丢失，在几秒之后另一个新的消息就会替换它。UDP广泛用在多媒体应用中，例如，Progressive Networks公司开发的RealAudio软件，它是在因特网上把预先录制的或者现场音乐实时传送给客户机的一种软件，该软件使用的RealAudio audio-on-demand protocol协议就是运行在UDP之上的协议，大多数因特网电话软件产品、聊天用的ICQ和QQ也都运行在UDP之上。 TCP协议和UDP协议的区别 1. 一般区别 TCP是面向连接的，传输数据保证可靠性和安全性；UDP协议是非面向连接的，是不可靠但高效率的协议。 TCP占用资源多而UDP占用少。 TCP是流模式而UDP是数据报模式。 TCP是面向连接的，用打电话的过程来类比，就是通信双方是互相明确的，所以进行的是“你一句我一句”的交流，TCP整个通信过程间有一个缓存区，由于通信主体明确，因此可以断断续续地进行交流，数据好比水流，知道源头和目的地，因此称为流模式。反过来，UDP是非面向连接的，好比写信的过程，假设我们只要知道佩奇的地址，我们就能写信给佩奇，而佩奇却不认识我们。这样发起通信方的身份是不明确的，每个发送端的信息都不能和别的发送端混淆，不然会造成数据失效，所以UDP要对数据进行“打包”发送，是面向报文的，就像写信需要用信封套起来，不然只发送数据甚至数据混合会变得毫无意义。 TCP和UDP的应用场景和编程方式也有很大差别。 2. TCP的粘包和UDP的丢包 TCP粘包现象：TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。 粘包原因： 发送端：TCP默认会使用Nagle算法。而Nagle算法主要做两件事：1）只有上一个分组得到确认，才会发送下一个分组；2）收集多个小分组，在一个确认到来时一起发送。所以，正是Nagle算法造成了发送方有可能造成粘包现象。 接收端：TCP接收到分组时，并不会立刻送至应用层处理，或者说，应用层并不一定会立即处理；实际上，TCP将收到的分组保存至接收缓存里，然后应用程序主动从缓存里读收到的分组。这样一来，如果TCP接收分组的速度大于应用程序读分组的速度，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包。 粘包处理：如果黏在一起的包是同一个整体，即同意部分数据分割而来的，那么就不用进行处理。如果是不同部分的数据粘到一起，就需要进行粘包解决： 发送端导致：使用TCP_NODELAY选项来关闭Nagle算法。 接收端导致：暂无。 统一解决（应用层）：可以解决接收方造成的粘包问题，还能解决发送方造成的粘包问题。 解决方法就是循环处理：应用程序在处理从缓存读来的分组时，读完一条数据时，就应该循环读下一条数据，直到所有的数据都被处理；但是如何判断每条数据的长度呢？ 两种途径： 　　1）格式化数据：每条数据有固定的格式（开始符、结束符），这种方法简单易行，但选择开始符和结束符的时候一定要注意每条数据的内部一定不能出现开始符或结束符； 2）**发送长度（推荐）**：发送每条数据的时候，**将数据的长度一并发送**，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以**根据长度来判断每条数据的开始和结束**。 UDP丢包现象：丢包现象即使用UDP发送时，由于不可靠连接方式，收到各种因素影响，数据包可能会在接受过程中丢失一部分，从而导致数据不完整。 UDP丢包原因： 发送端：发送的包太大导致send方法无法正常切割为小包导致丢包、发送的包太大超过缓存设置也会出现对包、发送频率太快导致接收端未接受或溢出缓冲区而丢包。 接收端：处理时间过长导致丢包。 其他：网络等问题。 UDP丢包处理： UDP的缺陷在于丢包和乱序问题，一般视情况进行处理，而发送的时候也需要注意上述导致丢包的问题。 HTTP（HyperText Transfer Protocol）协议 HTTP，超文本传输协议，是互联网上应用最为广泛的一种网络协议。所有的万维网WWW（World Wide Web）文件都必须遵守这个标准。 HTTP基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等） HTTP是一个属于应用层的面向对象的协议 HTTP协议工作于客户端-服务端架构为上 HTTP特点 HTTP是一个客户端和服务器端请求和应答的标准，通常，由HTTP客户端发起一个请求，建立一个到服务器指定端口（默认是80端口）的TCP连接。HTTP服务器则在那个端口监听客户端发送过来的请求。一旦收到请求，服务器（向客户端）发回一个状态行。 HTTP协议的网页 HTTP协议的网页 HTTP使用TCP而不是UDP的原因在于（打开）一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。 通过HTTP或者HTTPS协议（HTTP协议+SSL协议）请求的资源由统一资源标示符（Uniform Resource Identifiers）（或者，更准确一些，URLs）来标识。HTTP有以下特点： 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 支持B/S及C/S模式。 HTTP的URL地址 URL（UniformResourceLocator，统一资源定位符）是一种特殊类型的URI，包含了用于查找某个资源的足够的信息，是互联网上用来标识某一处资源的地址。 URL的各部分组成： http://www.heyaguang.com:8080/EarthStudy/index.html?var1=1&var2=2#name 协议部分：一般为HTTP或Https，后接//作为分隔符。 域名部分：www.heyaguang.com为网站域名。 端口号部分：此网址为8080。跟在域名后面的是端口号，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口。 虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。 文件名部分：从域名后的最后一个“/”开始到后面一个“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.html”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名。 参数部分：从“？”开始到“#”为止之间的部分为参数部分。本例中的参数部分为“var1=1&var2=2”。不是必要部分。 锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分。 HTTP请求之request 客户端通过HTTP协议进行请求时遵循一定的格式，请看下面的请求报文格式（由请求行、请求头、空行、请求体组成）： 各部分组成如下所示： HTTP响应之response 在客户端发送请求后服务端进行响应，将信息发送给客户端，以实现功能服务，报文格式如下（包含状态行、响应头、空行、消息体）： HTTP状态码分类： 分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 HTTP状态码列表： 英文名称 中文描述 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-26 21:41:24 "},"network/byzantine.html":{"url":"network/byzantine.html","title":"拜占庭将军问题","keywords":"","body":"拜占庭将军问题 什么是拜占庭将军问题 “拜占庭将军问题”也被称为“拜占庭容错”，是Leslie Lamport（2013年的图灵讲得主）用来为描述分布式系统一致性问题（Distributed Consensus）在论文中抽象出来一个著名的例子： 拜占庭帝国想要进攻一个强大的敌人，为此派出了10支军队去包围这个敌人。这个敌人虽不比拜占庭帝国，但也足以抵御5支常规拜占庭军队的同时袭击。这10支军队在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少6支军队（一半以上）同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵骑马相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们才能保证有多于6支军队在同一时间一起发起进攻，从而赢取战斗？ 注：“ 拜占庭将军问题中并不去考虑通信兵是否会被截获或无法传达信息等问题，即消息传递的信道绝无问题。 通俗分析 先看在没有叛徒情况下，假如一个将军A提一个进攻提议（如：明日下午1点进攻，你愿意加入吗？）由通信兵通信分别告诉其他的将军，如果幸运中的幸运，他收到了其他6位将军以上的同意，发起进攻。如果不幸，其他的将军也在此时发出不同的进攻提议（如：明日下午2点、3点进攻，你愿意加入吗？），由于时间上的差异，不同的将军收到（并认可）的进攻提议可能是不一样的，这是可能出现A提议有3个支持者，B提议有4个支持者，C提议有2个支持者等等。 再加一点复杂性，在有叛徒情况下，一个叛徒会向不同的将军发出不同的进攻提议（通知A明日下午1点进攻， 通知B明日下午2点进攻等等），一个叛徒也会可能同意多个进攻提议（即同意下午1点进攻又同意下午2点进攻）。 叛徒发送前后不一致的进攻提议，被称为“拜占庭错误”，而能够处理拜占庭错误的这种容错性称为「Byzantine fault tolerance」，简称为BFT。 问题抽象 求解拜占庭将军问题，隐含要满足以下两个条件： 每个忠诚的将军必须收到相同的命令值vi（vi是第i个将军的命令）。 如果第i个将军是忠诚的，那么他发送的命令和每个忠诚将军收到的vi相同。 于是，拜占庭将军问题的可以描述为：一个发送命令的将军要发送一个命令给其余n-1个将军，使得： IC1. 所有忠诚的接收命令的将军遵守相同的命令；（一致性） IC2. 如果发送命令的将军是忠诚的，那么所有忠诚的接收命令的将军遵守所接收的命令。（正确性）　 Lamport对拜占庭将军问题的研究表明，当n>3m时，即叛徒的个数m小于将军总数n的1/3时，通过口头同步通信（假设通信是可靠的），可以构造同时满足IC1和IC2的解决方案，即将军们可以达成一致的命令。但如果通信是可认证、防篡改伪造的（如采用PKI认证，消息签名等），则在任意多的叛徒（至少得有两个忠诚将军）的情况下都可以找到解决方案。 而Fischer-Lynch-Paterson定理证明了，异步通信情况下，只要有一个叛徒存在，拜占庭将军问题就无解。翻译成分布式计算语言，在一个多进程异步系统中，只要有一个进程不可靠，那么就不存在一个协议，此协议能保证有限时间内使所有进程达成一致。 拜占庭将军问题在一个分布式系统中，是一个非常有挑战性的问题。因为分布式系统不能依靠同步通信，否则性能和效率将非常低。因此寻找一种实用的解决拜占庭将军问题的算法一直是分布式计算领域中的一个重要问题。 在这里，我们先给出分布式计算中有关拜占庭缺陷和故障的两个定义： 定义1：拜占庭缺陷（Byzantine Fault）：任何观察者从不同角度看，表现出不同症状的缺陷。 定义2：拜占庭故障（Byzantine Failure）：在需要共识的系统中由于拜占庭缺陷导致丧失系统服务。 在分布式系统中，不是所有的缺陷或故障都能称作拜占庭缺陷或故障。像死机、丢消息等缺陷或故障不能算为拜占庭缺陷或故障。拜占庭缺陷或故障是最严重缺陷或故障，拜占庭缺陷有不可预测、任意性的缺陷，例如遭黑客破坏，中木马的服务器就是一个拜占庭服务器。 在一个有拜占庭缺陷存在的分布式系统中，所有的进程都有一个初始值。在这种情况下，共识问题（Consensus Problem），就是要寻找一个算法和协议，使得该协议满足以下三个属性。 一致性（Agreement）：所有的非缺陷进程都必须同意同一个值。 正确性（Validity）：如果所有的非缺陷的进程有相同的初始值，那么所有非缺陷的进程所同意的值必须是同一个初始值。 可结束性（Termination）：每个非缺陷的进程必须最终确定一个值。 根据Fischer-Lynch-Paterson的理论，在异步通信的分布式系统中，只要有一个拜占庭缺陷的进程，就不可能找到一个共识算法，可同时满足上述要求的一致性、正确性和可结束性要求。在实际情况下，根据不同的假设条件，有很多不同的共识算法被设计出来。这些算法各有优势和局限。算法的假设条件有以下几种情况： 故障模型：非拜占庭故障/拜占庭故障。 通信类型：同步/异步。 通信网络连接：节点间直连数。 信息发送者身份：实名/匿名。 通信通道稳定性：通道可靠/不可靠。 消息认证性：认证消息/非认证消息。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-01 18:30:52 "},"network/consensus.html":{"url":"network/consensus.html","title":"共识算法","keywords":"","body":"共识算法 BFT：Byzantine Fault Tolerance，拜占庭容错技术 拜占庭容错技术（Byzantine Fault Tolerance，BFT）是一类分布式计算领域的容错技术。拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或中断以及遭到恶意攻击等原因，计算机和网络可能出现不可预料的行为。拜占庭容错技术被设计用来处理这些异常行为，并满足所要解决的问题的规范要求。 拜占庭容错技术来源于拜占庭将军问题。 在分布式系统中，特别是在区块链网络环境中，也和拜占庭将军的环境类似，有运行正常的服务器（类似忠诚的拜占庭将军），有故障的服务器，还有破坏者的服务器（类似叛变的拜占庭将军）。共识算法的核心是在正常的节点间形成对网络状态的共识。 通常，这些发生故障节点被称为拜占庭节点，而正常的节点即为非拜占庭节点。 拜占庭容错系统是一个拥有n台节点的系统，整个系统对于每一个请求，满足以下条件： 所有非拜占庭节点使用相同的输入信息，产生同样的结果； 如果输入的信息正确，那么所有非拜占庭节点必须接收这个信息，并计算相应的结果。 拜占庭系统普遍采用的假设条件包括： 拜占庭节点的行为可以是任意的，拜占庭节点之间可以共谋； 节点之间的错误是不相关的； 节点之间通过异步网络连接，网络中的消息可能丢失、乱序并延时到达，但大部分协议假设消息在有限的时间里能传达到目的地； 服务器之间传递的信息，第三方可以嗅探到，但是不能篡改、伪造信息的内容和验证信息的完整性。 原始的拜占庭容错系统由于需要展示其理论上的可行性而缺乏实用性。另外，还需要额外的时钟同步机制支持，算法的复杂度也是随节点增加而指数级增加。 PBFT：Practical Byzantine Fault Tolerance，实用拜占庭容错算法 实用拜占庭容错系统（PBFT）降低了拜占庭协议的运行复杂度，从指数级别降低到多项式级别（Polynomial），使拜占庭协议在分布式系统中应用成为可能。 PBFT是一种状态机副本复制算法，即服务作为状态机进行建模，状态机在分布式系统的不同节点进行副本复制。每个状态机的副本都保存了服务的状态，同时也实现了服务的操作。将所有的副本组成的集合使用大写字母R表示，使用0到|R|-1的整数表示每一个副本。为了描述方便，通常假设故障节点数为m个，整个服务节点数为|R| = 3m+1个，这里m是有可能失效的副本的最大个数。尽管可以存在多于3m+1个副本，但是额外的副本除了降低性能之外不能提高可靠性。 PBFT要求共同维护一个状态，所有节点采取的行动一致。为此，需要运行三类基本协议，包括一致性协议、检查点协议和视图更换协议。我们主要关注支持系统日常运行的一致性协议。一致性协议至少包含若干个阶段：请求（request）、序号分配（pre-prepare）和响应（reply）。根据协议设计的不同，可能包含相互交互（prepare），序号确认（commit）等阶段。 PBFT协议通信模式： 上图为PBFT协议通信模式，每一个客户端的请求需要经过5个阶段，通过采用两次两两交互的方式在服务器达成一致之后再执行客户端的请求。由于客户端不能从服务器端获得任何服务器运行状态的信息，PBFT中主节点是否发生错误只能由服务器监测。如果服务器在一段时间内都不能完成客户端的请求，则会触发视图更换协议。其中C为客户端，N0~N3表示服务节点，特别的，N0为主节点，N3为故障节点。整个协议的基本过程如下： 客户端发送请求，激活主节点的服务操作。 当主节点接收请求后，启动三阶段的协议以向各从节点广播请求。 序号分配阶段，主节点给请求赋值一个序列号n，广播序号分配消息和客户端的请求消息m，并将构造PRE-PREPARE消息给各从节点； 交互阶段，从节点接收PRE-PREPARE消息，向其他服务节点广播PREPARE消息； 序号确认阶段，各节点对视图内的请求和次序进行验证后，广播COMMIT消息，执行收到的客户端的请求并给客户端以响应。 客户端等待来自不同节点的响应，若有m+1个响应相同，则该响应即为运算的结果。 PBFT在很多场景都有应用，在区块链场景中，一般适合于对强一致性有要求的私有链和联盟链场景。例如，在IBM主导的区块链超级账本项目中，PBFT是一个可选的共识协议。在Hyperledger的Fabric项目中，共识模块被设计成可插拔的模块，支持像PBFT、Raft等共识算法。 Paxos算法 Paxos算法是莱斯利·兰伯特（英语：Leslie Lamport，LaTeX中的“La”）于1990年提出的一种基于消息传递且具有高度容错特性的一致性算法。 分布式系统中的节点通信存在两种模型：共享内存（Shared memory）和消息传递（Messages passing）。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础Paxos场景中，先不考虑可能出现消息篡改即拜占庭错误的情况。Paxos算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。 算法 首先将议员的角色分为proposers，acceptors，和learners（允许身兼数职）。 proposers提出提案，提案信息包括提案编号和提议的value； acceptor收到提案后可以接受（accept）提案，若提案获得多数acceptors的接受，则称该提案被批准（chosen）； learners只能“学习”被批准的提案。 划分角色后，就可以更精确的定义问题： 决议（value）只有在被proposers提出后才能被批准（未经批准的决议称为“提案（proposal）”）； 在一次Paxos算法的执行实例中，只批准（chosen）一个value； learners只能获得被批准（chosen）的value。 P1：一个acceptor必须接受（accept）第一次收到的提案。 P2：一旦一个具有value v的提案被批准（chosen），那么之后批准（chosen）的提案必须具有value v。 P2a：一旦一个具有value v的提案被批准（chosen），那么之后任何acceptor再次接受（accept）的提案必须具有value v。 P2b：一旦一个具有value v的提案被批准（chosen），那么以后任何proposer提出的提案必须具有value v。 P2c：如果一个编号为n的提案具有value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于n 的任何提案，要么他们已经接受（accept）的所有编号小于n的提案中编号最大的那个提案具有value v。 P1a：当且仅当acceptor没有回应过编号大于n的prepare请求时，acceptor接受（accept）编号为n的提案。 最终算法需遵循P2c与P1a 决议的提出与批准 通过一个决议分为两个阶段： prepare阶段： proposer选择一个提案编号n并将prepare请求发送给acceptors中的一个多数派； acceptor收到prepare消息后，如果提案的编号大于它已经回复的所有prepare消息，则acceptor将自己上次接受的提案回复给proposer，并承诺不再回复小于n的提案；同时通知编号小的proposer，提醒其中断这次提案。 批准阶段： 当一个proposer收到了多数acceptors对prepare的回复后，就进入批准阶段。它要向回复prepare请求的acceptors发送accept请求，包括编号n和根据P2c决定的value（如果根据P2c没有已经接受的value，那么它可以自由决定value）。 在不违背自己向其他proposer的承诺的前提下，acceptor收到accept请求后即接受这个请求。 决议的发布 一个显而易见的方法是当acceptors批准一个value时，将这个消息发送给所有learner。但是这个方法会导致消息量过大。 由于假设没有Byzantine failures，learners可以通过别的learners获取已经通过的决议。因此acceptors只需将批准的消息发送给指定的某一个learner，其他learners向它询问已经通过的决议。这个方法降低了消息量，但是指定learner失效将引起系统失效。 因此acceptors需要将accept消息发送给learners的一个子集，然后由这些learners去通知所有learners。 但是由于消息传递的不确定性，可能会没有任何learner获得了决议批准的消息。当learners需要了解决议通过情况时，可以让一个proposer重新进行一次提案。注意一个learner可能兼任proposer。 Progress的保证 根据上述过程当一个proposer发现存在编号更大的提案时将终止提案。这意味着提出一个编号更大的提案会终止之前的提案过程。如果两个proposer在这种情况下都转而提出一个编号更大的提案，就可能陷入活锁，违背了Progress的要求。这种情况下的解决方案是选举出一个leader，仅允许leader提出提案。但是由于消息传递的不确定性，可能有多个proposer自认为自己已经成为leader。Lamport在The Part-Time Parliament一文中描述并解决了这个问题。 Raft协议 动画版Raft讲解 模拟器 Raft是Paxos的一种简化实现或变种，是由Stanford提出的一种更易理解的一致性算法，意在取代广为使用的Paxos算法。目前，在各种主流语言中都有了一些开源实现，比如本文中将使用的基于JGroups的Raft协议实现。 Raft最初是一个用于管理复制日志的共识算法，它是一个为真实世界应用建立的协议，主要注重协议的落地性和可理解性。Raft是在非拜占庭故障下达成共识的强一致协议。 在区块链系统中，使用Raft实现记账共识的过程可以描述如下：首先选举一个leader，接着赋予leader完全的权力管理记账。leader从客户端接收记账请求，完成记账操作，生成区块，并复制到其他记账节点。有了leader简化了记账操作的管理。例如，leader能够决定是否接受新的交易记录项而无需考虑其他的记账节点，leader可能失效或与其他节点失去联系，这时，系统就会选出新的leader。 在Raft中，每个节点会处于下面三种状态中的一种： Follower：所有结点都以follower的状态开始。如果没收到leader消息则会变成candidate状态 Candidate：会向其他结点“拉选票”，如果得到大部分的票则成为leader。这个过程就叫做Leader选举(Leader Election) Leader：所有对系统的修改都会先经过leader。每个修改都会写一条日志(Log Entry)。leader收到修改请求后的过程如下，这个过程叫做日志复制(Log Replication)： 复制日志到所有follower结点(replicate entry) 大部分结点响应时才提交日志 通知所有follower结点日志已提交 所有follower也提交日志 现在整个系统处于一致的状态 term逻辑时钟： Term相当于paxos中的proposerID，相当于一个国家的朝代。term是一段任意的时间序号。每一任Leader都有一个与之前不同的term。 当Leader选举成功之后，一个节点成为了Leader，就会产生一个新的term，并且直到Leader故障，整个集群都会一直在这个term下执行操作。 如果leader选举失败了，则会再生成出一个term，再开启一轮leader选举。 Quorum多数派： 多数派，意思是超过一半的机器存活，则这个机器可用，这个Quorums指的就是集群可用的指标。例如：集群中的节点数为2N，如果有N+1的机器存活，则代表集群可用，可接受请求，写入log，应用到状态机中去，执行操作。如果少于N+1个机器存活，则代表集群可用，可接受请求，可写入log，但不应用到状态机中去，不执行操作。 Raft阶段主要分为两个，首先是leader选举过程，然后在选举出来的leader基础上进行正常操作，比如日志复制、记账等。 1. Leader Election 当follower在随机选举超时时间（randomize election timeout）内未收到leader的心跳消息，则转换为candidate状态。为了避免选举冲突，这个超时时间是一个150~300ms之间的随机数。 一般而言，在Raft系统中： 1. 任何一个服务器都可以成为一个候选者candidate，它向其他服务器follower发出要求选举自己的请求。 2. 投票要满足cadidate的term大于follower的term，或者两个term相等但cadidate的index大于follower的index。 3. 投票请求若满足条件则先到先得，后到的请求予以否决。 4. follower服务器同意了，发出OK。注意，如果在这个过程中，有一个follower宕机，没有收到请求选举的要求，此时候选者可以自己选自己，只要达到N/2+1的大多数票，候选人还是可以成为leader的。 5. 这样这个候选者就成为了leader领导人，它可以向选民也就是follower发出指令，比如进行记账。 6. 以后通过**心跳（heartbeat timeout）**进行记账的通知。 7. 一旦这个leader崩溃了，那么follower中会出现新的候选者，并发出邀票选举。follower同意后，其成为leader，继续承担记账等指导工作。 2. Log Replication Raft的记账过程按以下步骤完成： 1. 假设leader领导人已经选出，这时客户端发出增加一个日志的要求。 2. leader要求follower遵从他的**指令（Entry）**，都将这个新的日志内容追加到他们各自日志中。 3. follower服务器将交易记录写入账本后，返回确认追加成功的消息 4. leader接收到多数（**Quorums**）follower的回应后进行**提交（Commit）**处理，并向客户端发出确认成功信息。 5. 在下一个心跳中，leader会通知所有follower更新确认的项目。 对于每个新的交易记录，重复上述过程。 在这一过程中，若发生网络通信故障，使得leader不能访问大多数follower了，那么leader只能正常更新它能访问的那些follower服务器。而大多数的服务器follower因为没有了leader，他们将重新选举一个候选者作为leader，然后这个leader作为代表与外界打交道，如果外界要求其添加新的交易记录，这个新的leader就按上述步骤通知大多数follower。当网络通信恢复，原先的leader就变成follower，在失联阶段，这个老leader的任何更新都不能算确认，必须全部回滚，接收新的leader的新的更新。 安全性 Raft的安全性，体现在如下几个方面： Election safety：在一个term下，最多只有一个Leader。 Leader Append-Only：一个Leader只能追加新的entries，不能重写和删除entries。 Log Matching：集群中各个节点的log都是相同一致的。 Leader Completeness：如果一个log entry被committed了，则这个entry一定会出现在Leader的log里。 State Machine Safety：如果一个节点服务器的state machine执行了一个某个log entry命令，则其他节点服务器，也会执行这个log entry命令，不会再执行其他命令。 POW：Proof of Work，工作量证明 从去中心化账本系统的角度看，每个加入这个系统的节点都要保存一份完整的账本，但每个节点却不能同时记账，因为节点处于不同的环境，接收到不同的信息，如果同时记账的话，必然会导致账本的不一致，造成混乱。因此，需要有共识来达成哪个节点有权记账。比特币区块链通过竞争记账的方式解决去中心化的记账系统的一致性问题，即以每个节点的计算能力即“算力”来竞争记账权的机制。 在比特币（Bitcoin）系统中，大约每10分钟进行一轮算力竞赛，竞赛的胜利者，就获得一次记账的权力，并向其他节点同步新增账本信息。然而，在一个去中心化的系统中，谁有权判定竞争的结果呢？比特币系统是通过一个称为“工作量证明”（Proof of Work，PoW）的机制完成的。 简单地说，PoW就是一份确认工作端做过一定量工作的证明。PoW系统的主要特征是计算的不对称性。工作端需要做一定难度的工作得出一个结果，验证方却很容易通过结果来检查工作端是不是做了相应的工作。 举个例子，给定字符串“blockchain”，我们给出的工作量要求是，可以在这个字符串后面连接一个称为nonce的整数值串，对连接后的字符串进行SHA256哈希运算，如果得到的哈希结果（以十六进制的形式表示）是以若干个0开头的，则验证通过。为了达到这个工作量证明的目标，我们需要不停地递增nonce值，对得到的新字符串进行SHA256哈希运算。按照这个规则，需要经过2688次计算才能找到前3位均为0的哈希值，而要找到前6位均为0的哈希值，则需进行620969次计算。 1 blockchain1 → 4bfb943cba9fb9926df93f33c17d64b378d56714e8a29c6ba8bdc9690cea8e27 2 blockchain2 → 01181212a283e760929f6b1628d903127c65e6fb5a9ad7fe94b790e699269221 …… 3 blockchain515 → 0074448bea8027bebd6333d3aa12fd11641e051911c5bab661a9b849b83958a7…… 4 blockchain2688 → 0009b257eb8cf9eba179ab2be74d446fa1c59f0adfa8814260f52ae0016dd50f…… 5 blockchain48851: 00000b3d96b4db1a976d3a69829aabef8bafa35ab5871e084211a16d3a4f385c…… 6 blockchain6200969: 000000db7fa334aef754b51792cff6c880cd286c5f490d5cf73f658d9576d424 1. 工作量证明函数 及 区块数据计算过程 比特币系统中使用的工作量证明函数是SHA256。 比特币区块结构如下图所示： 比特币的区块由区块头及该区块所包含的交易列表组成。区块头的大小为80字节，由4字节的版本号、32字节的上一个区块的哈希值、32字节的Merkle根哈希值、4字节的时间戳（当前时间）、4字节的当前难度值、4字节的随机数组成。区块包含的交易列表则附加在区块头后面，其中的第一笔交易是coinbase交易，这是一笔为了让矿工获得奖励及手续费的特殊交易。 拥有80字节固定长度的区块头，就是用于比特币工作量证明的输入字符串。因此，为了使区块头能体现区块所包含的所有交易，在区块的构造过程中，需要将该区块要包含的交易列表，通过Merkle树算法生成Merkle根哈希值，并以此作为交易列表的哈希值存到区块头中。其中Merkle树的算法图解如下图所示。 　　 　　 上图展示了一个具有4个交易记录的Merkle树的根哈希值的计算过程。首先以这4个交易作为叶子结点构造一棵完全二叉树，然后通过哈希值的计算，将这棵二叉树转化为Merkle树。 首先对4个交易记录：Txa~Txc，分别计算各自的哈希值HA~HC，然后计算两个中间节点的哈希值HAB = Hash(HA+HB) 和 HCD = Hash(HC+HD)，最后计算出根节点的哈希值HABCD = Hash(HAB+HCD)。 而构造出来的简化的区块链结构如上图所示。We find that: 所有在给定时间范围需要记录的交易信息被构造成一个Merkle树，区块中包含了指向这个Merkle树的哈希指针，关联了与该区块相关的交易数据，同时，区块中也包含了指向前一区块的哈希指针，使得记录了不同交易的单个区块被关联起来，形成区块链。 2. 挖矿难度 挖矿难度值是比特币系统中的节点在生成区块时的重要参考指标，它决定了节点大约需要经过多少次哈希运算才能产生一个合法的区块。比特币的区块大约每10分钟生成一个，如果要在不同的全网算力条件下，新区块的产生都基本保持这个速率，难度值必须根据全网算力的变化进行调整。简单地说，难度值被设定在无论节点计算能力如何，新区块产生速率都保持在每10分钟一个。 难度的调整是在每个完整节点中独立自动发生的。每2016个区块，所有节点都会按统一的公式自动调整难度，这个公式是由最新2016个区块的花费时长与期望时长（期望时长为20160分钟，即两周，是按每10分钟一个区块的产生速率计算出的总时长）比较得出的，根据实际时长与期望时长的比值，进行相应调整（或变难或变易）。也就是说，如果区块产生的速率比10分钟快则增加难度，比10分钟慢则降低难度。　 这个公式可以总结为： 新难度值 = 旧难度值 × ( 过去2016个区块花费时长 / 20160分钟 ) 工作量证明需要有一个目标值。比特币工作量证明的目标值（Target）的计算公式：目标值=最大目标值/难度值 其中最大目标值为一个恒定值：0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF 目标值的大小与难度值成反比。比特币工作量证明的达成就是矿工计算出来的区块哈希值必须小于目标值。 3. PoW过程　 比特币PoW的过程，可以简单理解成就是将不同的nonce值作为输入，尝试进行SHA256哈希运算，找出满足给定数量前导0的哈希值的过程。而要求的前导0的个数越多，代表难度越大。比特币节点求解工作量证明问题的步骤大致归纳如下： 生成铸币交易，并与其他所有准备打包进区块的交易组成交易列表，通过Merkle树算法生成Merkle根哈希； 把Merkle根哈希及其他相关字段组装成区块头，将区块头的80字节数据作为工作量证明的输入； 不停地变更区块头中的随机数，即nonce的数值，并对每次变更后的区块头做双重SHA256运算（即SHA256（SHA256（Block_Header））），将结果值与当前网络的目标值做对比，如果小于目标值，则解题成功，工作量证明完成。 比特币的工作量证明，就是俗称“挖矿”所做的主要工作。 4. PoW能否解决拜占庭将军问题　 关于比特币PoW共识机制能否解决拜占庭将军问题一直在业界有争议。2015年，Juan Garay对比特币的PoW共识算法进行了正式的分析，得出的结论是比特币的PoW共识算法是一种概率性的拜占庭协议（Probabilistic BA）。Garay对比特币共识协议的两个重要属性分析如下。 一致性（Agreement） 在不诚实节点总算力小于50%的情况下，同时每轮同步区块生成的几率很少的情况下，诚实的节点具有相同的区块的概率很高。用数学的严格语言说应该是：当任意两个诚实节点的本地链条截取K个节点，两条剩下的链条的头区块不相同的概率随着K的增加呈指数型递减。 正确性（Validity） 大多数的区块必须由诚实节点提供。严格来说，当不诚实算力非常小的时候，才能使大多数区块由诚实节点提供。 可以看到，当不诚实的算力小于网络总算力的50%时，同时挖矿难度比较高，在大约10分钟出一个区块情况下，比特币网络达到一致性的概念会随确认区块的数目增多而呈指数型增加。但当不诚实算力具一定规模，甚至不用接近50%的时候，比特币的共识算法并不能保证正确性，也就是，不能保证大多数的区块由诚实节点来提供。 因此，比特币的共识算法不适合于私有链和联盟链。其原因首先是它是一个最终一致性共识算法，不是一个强一致性共识算法。第二个原因是其共识效率低。提供共识效率又会牺牲共识协议的安全性。另外，比特币通过巧妙的矿工奖励机制来提升网络的安全性。矿工挖矿获得比特币奖励以及记账所得的交易费用使得矿工更希望维护网络的正常运行，而任何破坏网络的非诚信行为都会损害矿工自身的利益。因此，即使有些比特币矿池具备强大的算力，它们都没有作恶的动机，反而有动力维护比特币的正常运行，因为这和它们的切实利益相关。 PoW机制存在明显的弊端。一方面，PoW的前提是，节点和算力是均匀分布的，因为通过CPU的计算能力来进行投票，拥有钱包（节点）数和算力值应该是大致匹配的，然而随着人们将CPU挖矿逐渐升级到GPU、FPGA，直至ASIC矿机挖矿，节点数和算力值也渐渐失配。另一方面，PoW太浪费了。比特币网络每秒可完成数百万亿次SHA256计算，但这些计算除了使恶意攻击者不能轻易地伪装成几百万个节点和打垮比特币网络，并没有更多实际或科学价值。当然，相对于允许世界上任何一个人在瞬间就能通过去中心化和半匿名的全球货币网络，给其他人几乎没有手续费地转账所带来的巨大好处，它的浪费也许只算是很小的代价有鉴于此，人们提出了权益证明（Proof of Stake，PoS）。 POS：Proof of Stake，股权证明 PoS类似于财产储存在银行，这种模式会根据你持有数字货币的量和时间，分配给你相应的利息。 简单来说，就是一个根据你持有货币的量和时间，给你发利息的一个制度，在股权证明PoS模式下，有一个名词叫币龄，每个币每天产生1币龄，比如你持有100个币，总共持有了30天，那么，此时你的币龄就为3000，这个时候，如果你发现了一个PoS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的利息(假定利息可理解为年利率5%)，那么在这个案例中，利息 = 3000 * 5% / 365 = 0.41个币，这下就很有意思了，持币有利息。 点点币（Peercoin）是首先采用权益证明的货币，点点币在SHA256的哈希运算的难度方面引入了币龄的概念，使得难度与交易输入的币龄成反比。在点点币中，币龄被定义为币的数量与币所拥有的天数的乘积，这使得币龄能够反映交易时刻用户所拥有的货币数量。实际上，点点币的权益证明机制结合了随机化与币龄的概念，未使用至少30天的币可以参与竞争下一区块，越久和越大的币集有更大的可能去签名下一区块。 然而，一旦币的权益被用于签名一个区块，则币龄将清为零，这样必须等待至少30日才能签署另一区块。同时，为防止非常老或非常大的权益控制区块链，寻找下一区块的最大概率在90天后达到最大值，这一过程保护了网络，并随着时间逐渐生成新的币而无需消耗大量的计算能力。点点币的开发者声称这将使得恶意攻击变得困难，因为没有中心化的挖矿池需求，而且购买半数以上的币的开销似乎超过获得51%的工作量证明的哈希计算能力。 权益证明必须采用某种方法定义任意区块链中的下一合法区块，依据账户结余来选择将导致中心化，例如单个首富成员可能会拥有长久的优势。为此，人们还设计了其他不同的方法来选择下一合法区块。 PoS机制虽然考虑到了PoW的不足，但依据权益结余来选择，会导致首富账户的权力更大，有可能支配记账权。股份授权证明机制（Delegated Proof of Stake，DPoS）的出现正是基于解决PoW机制和PoS机制的这类不足。 DPOS：Delegated Proof of Stake，委任权益证明 比特股（Bitshare）是一类采用DPoS机制的密码货币，它期望通过引入一个技术民主层来减少中心化的负面影响。 比特股的DPoS机制，中文名叫做股份授权证明机制（又称受托人机制），它的原理是让每一个持有比特股的人进行投票，由此产生101位代表 , 我们可以将其理解为101个超级节点或者矿池，而这101个超级节点彼此的权利是完全相等的。从某种角度来看，DPOS有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责（当轮到他们时，没能生成区块），他们会被除名，网络会选出新的超级节点来取代他们。DPOS的出现最主要还是因为矿机的产生，大量的算力在不了解也不关心比特币的人身上，类似演唱会的黄牛，大量囤票而丝毫不关心演唱会的内容。 比特股引入了见证人这个概念，见证人可以生成区块，每一个持有比特股的人都可以投票选举见证人。得到总同意票数中的前N个（N通常定义为101）候选者可以当选为见证人，当选见证人的个数（N）需满足：至少一半的参与投票者相信N已经充分地去中心化。 见证人的候选名单每个维护周期（1天）更新一次。见证人然后随机排列，每个见证人按序有2秒的权限时间生成区块，若见证人在给定的时间片不能生成区块，区块生成权限交给下一个时间片对应的见证人。DPoS的这种设计使得区块的生成更为快速，也更加节能。 DPoS充分利用了持股人的投票，以公平民主的方式达成共识，他们投票选出的N个见证人，可以视为N个矿池，而这N个矿池彼此的权利是完全相等的。持股人可以随时通过投票更换这些见证人（矿池），只要他们提供的算力不稳定，计算机宕机，或者试图利用手中的权力作恶。 比特股还设计了另外一类竞选，代表竞选。选出的代表拥有提出改变网络参数的特权，包括交易费用、区块大小、见证人费用和区块区间。若大多数代表同意所提出的改变，持股人有两周的审查期，这期间可以罢免代表并废止所提出的改变。这一设计确保代表技术上没有直接修改参数的权利以及所有的网络参数的改变最终需得到持股人的同意。 POA：Proof of Authority，权威证明 权威证明（Proof-of-Authority）或者PoA是一种算法。通过基于身份权益（identity as a stake）的共识机制，它可以提供更快的交易速率（与PoW相比）。这个术语是由以太坊（Ethereum）和Parity Technologies公司的联合创始人Gavin Wood创建的，并且目前用于Kovan——以太坊的测试网络（testnet networks）之一。 交易和块通过被批准的帐户（称为验证器）来验证。该过程是自动化的，并且激励被批准和被信任的验证者保持网络的安全性和一致性。 建立权威，必须满足三个主要条件： 必须在链上验证身份。 为了使验证过程有价值并提供足够的激励，应使资格很难获得。 建立权威时，在其检查和程序上必须具有完全的一致性。 使用案例 一个流行的利用PoA机制的区块链项目是 Oracle Network。作为一个基于以太坊的公共网络，它允许更快地执行智能合同（Smart Contract），并使用受尊敬的个人共识，使区块链对于从小商家到大企业的每个人来说,都是负担得起的而且是可访问的。 此外，还有一个正在使用PoA机制进行新代币开发和交易速度提升的新项目。Lindax是一个去中心化平台，用于交易与创造定制化的数字资产，是Go & CPP 以太坊的一个分支。当公司在LindaX网络上创建代币时，它们还将帮助确认交易的有效性，从而减少在区块链上的不当行为，同时消除消耗性成本。 RPCA：Ripple Protocol consensus algorithm，瑞波协议共识算法 Ripple（瑞波）是一种基于互联网的开源支付协议，可以实现去中心化的货币兑换、支付与清算功能。 基本概念 服务节点（Rippled）：可以接收交易的区块链节点，包括追踪节点和验证节点。客户端应用提交交易请求给服务节点（Rippled），服务节点以最近验证过的帐本为依据进行交易检查，检查通过的交易进入候选交易集合。 追踪节点（tracking node）：主要功能是分发交易信息以及响应客户端的账本请求。 验证节点（validating node）：被其它节点接入到信任列表中的节点，除包含追踪节点的所有功能外，还参与共识过程。 区块用于记录交易，在RPCA中有两种区块比较关键： 最新关闭区块（Last Closed Ledger）：也就是最新被共识过的区块 开放区块：也就是当前正在被共识的区块，当开放区块被共识过，也就成了最新关闭区块 信任节点列表UNL（unique node list）：每个服务节点都会维护一个信任节点列表，这里信任并不是指信任每一个节点， 而是指信任这个列表中的节点不会联合起来作弊。在共识过程中，我们只接受来自信任节点列表中的节点投票。在Ripple中，使用配置文件中加入其它验证节点的公钥的方式来制定UNL。 RPCA共识过程 Ripple网络每隔几秒就会产生一个新的区块，这个区块的产生过程就是所有网络节点RPCA共识的过程。假设共识过程是成功的，并且网络中没有分叉产生，那么新生成的区块就是全网唯一的 整个RPCA共识过程分为如下两个阶段： 交易共识，形成交易集 区块打包，再共识 1. 交易共识，形成交易集 每个验证节点会不断收到从网络发送过来的交易，通过与本地账本数据验证后，不合法的交易直接丢弃，合法的交易将汇总成交易候选集（candidate set）。交易候选集里面还包括之前共识过程无法确认而遗留下来的交易。 每个验证节点把自己的交易候选集作为提案发送给其他验证节点。 验证节点在收到其他节点发来的提案后，如果不是来自UNL上的节点，则忽略该提案；如果是来自UNL上的节点，就会对比提案中的交易和本地的交易候选集，如果有相同的交易，该交易就获得一票。在一定时间内，当交易获得超过50%的票数时，则该交易进入下一轮。没有超过50%的交易，将留待下一次共识过程去确认。 验证节点把超过50%票数的交易作为提案发给其他节点，同时提高所需票数的阈值到60%，重复步骤3、步骤4，直到阈值达到80%。 验证节点把经过80%UNL节点确认的交易正式写入本地的账本数据中，称为最后关闭账本。 2. 区块打包，再共识 形成交易集后，每个节点开始打包新的区块，打包区块的过程如下： 把当前区块号、共识交易集的Merkle树根Hash、父区块Hash、当前时间戳等内容放到一起，计算一个区块哈希。 每个节点广播自己得出的区块哈希到它可见的节点，这里的可见节点不仅仅指可信列表中的节点，而是通过节点发现过程能发现的节点。 节点收集到它所有可信列表中节点广播过来的区块哈希后，结合自己生成的区块哈希，对每个区块哈希计算一个比例，如果某一哈希的比例超过一个阈值（一般是80%），则认为这个哈希是共识通过的区块哈希。如果自己的哈希与之相同，则说明自己打包的区块得到了确认，是新的被共识过的区块，直接存到本地，并且更新状态。如果自己的哈希与共识通过的哈希不同，那就需要去某个区块哈希正确的节点索要新的区块信息，要到之后存储到本地并且更新当前状态。 如果上面没有对某一区块哈希超过设定的阈值，那么重新开始共识过程，直到满足条件。 验证 正确性 RPCA中正确性的验证方式很简单，因为共识需要80%的阈值，那么只要UNL中有80%的诚实节点，就能达成共识，另外即使有超过20%的欺诈节点，也不能破坏正确性，因为欺诈节点也必须达到80%以上才能达成共识。无论欺诈节点还是诚实节点，达不到80%，都无法通过共识。 一致性 RPCA中一致性是通过子网络与其它子网络的连通性来保证的，要保证区块链不分叉，必须确保每个子网络必须至少与整个网络节点中的20%保持连通性。达到20%连通性的前提下，如果一个子网络中得出的共识区块哈希与整个网络得出的不一致，也就无法达成80%的共识要求，也就无法产生分叉。 可用性 在每一轮投票过程中，节点会搜集它UNL中每个节点的响应时间，一直响应时间慢的节点将会被剔除出去，这样UNL就能保持一个较高的沟通效率。在高效沟通的前提下，RPCA算法能保证每3秒左右就能产生一个区块，Ripple官方给出的tps数据是1500。这样的性能基本能满足一般的生产需求。 在Ripple的共识算法中，参与投票节点的身份是事先知道的，因此，算法的效率比PoW等匿名共识算法要高效，交易的确认时间只需几秒钟。当然，这点也决定了该共识算法只适合于权限链（Permissioned chain）的场景。Ripple共识算法的拜占庭容错（BFT）能力为( n-1 ) / 5，即可以容忍整个网络中20%的节点出现拜占庭错误而不影响正确的共识。 总结 “ 在区块链网络中，由于应用场景的不同，所设计的目标各异，不同的区块链系统采用了不同的共识算法。一般来说，在私有链和联盟链情况下，对一致性、正确性有很强的要求。一般来说要采用强一致性的共识算法。而在公有链情况下，对一致性和正确性通常没法做到百分之百，通常采用最终一致性（Eventual Consistency）的共识算法。” 通俗点就是：共识算法的选择与应用场景高度相关，可信环境使用paxos或者raft，带许可的联盟可使用pbft ，非许可链可以是pow，pos，ripple共识等，根据对手方信任度分级，自由选择共识机制。 Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-07-15 12:51:26 "},"markdown/":{"url":"markdown/","title":"Markdown","keywords":"","body":"Markdown Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 12:29:09 "},"markdown/markdown.html":{"url":"markdown/markdown.html","title":"markdown语法","keywords":"","body":"Markdown基本语法 一、标题 在想要设置为标题的文字前面加#来表示 一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 示例： # 这是一级标题 ## 这是二级标题 ### 这是三级标题 #### 这是四级标题 ##### 这是五级标题 ###### 这是六级标题 效果如下： 这是一级标题 这是二级标题 这是三级标题 这是四级标题 这是五级标题 这是六级标题 二、字体 加粗 要加粗的文字左右分别用两个*号包起来 斜体 要倾斜的文字左右分别用一个*号包起来 斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来 删除线 要加删除线的文字左右分别用两个~~号包起来 示例： **这是加粗的文字** *这是倾斜的文字*` ***这是斜体加粗的文字*** ~~这是加删除线的文字~~ 效果如下： 这是加粗的文字 这是倾斜的文字 这是斜体加粗的文字 这是加删除线的文字 三、引用 在引用的文字前加>即可。引用也可以嵌套，如加两个>>三个>>> 示例： >这是引用的内容 >>这是引用的内容 >>>>>>>>>>这是引用的内容 效果如下： 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线 三个或者三个以上的 - 或者 * 都可以。 示例： --- ---- *** ***** 效果如下： 可以看到，显示效果是一样的。 --- 五、图片 语法： ![图片alt](图片地址 \"图片title\") 图片alt就是显示在图片下面的文字，相当于对图片内容的解释。 图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： ![blockchain](6860761-fd2f51090a890873.webp \"区块链\") 效果如下： 六、超链接 语法： [超链接名](超链接地址 \"超链接title\") title可加可不加 示例： [百度](http://baidu.com) 效果如下： 百度 注：Markdown本身语法不支持链接在新页面中打开，如果想要在新页面中打开的话可以用html语言的a标签代替。 超链接名 示例 百度 七、列表 无序列表 语法： 无序列表用 - + * 任何一种都可以 - 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格 效果如下： 列表内容 列表内容 列表内容 有序列表 语法： 数字加点 1. 列表内容 2. 列表内容 3. 列表内容 注意：序号跟内容之间要有空格 效果如下： 列表内容 列表内容 列表内容 列表嵌套 上一级和下一级之间敲三个空格即可 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 八、表格 语法： 表头|表头|表头 ---|:--:|---: 内容|内容|内容 内容|内容|内容 第二行分割表头和内容。 - 有一个就行，为了对齐，多加了几个 文字默认居左 -两边加：表示文字居中 -右边加：表示文字居右 注：原生的语法两边都要用 | 包起来。此处省略 示例： 姓名|技能|排行 --|:--:|--: 刘备|哭|大哥 关羽|打|二哥 张飞|骂|三弟 效果如下： 姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 九、代码 语法： 单行代码：代码之间分别用一个反引号包起来 `代码内容` 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 (```) 代码... 代码... 代码... (```) 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。 示例： 单行代码 `create database hero;` 代码块 (```) function fun(){ echo \"这是一句非常牛逼的代码\"; } fun(); (```) 效果如下： 单行代码 create database hero; 代码块 function fun(){ echo \"这是一句非常牛逼的代码\"; } fun(); Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-23 15:49:25 "},"markdown/gitbook.html":{"url":"markdown/gitbook.html","title":"GitBook","keywords":"","body":"GitBook GitBook 是一个使用 Git 和 Markdown 来构建书籍的工具。它可以将你的书输出很多格式：PDF，ePub，mobi，或者输出为静态网页。 Git 方式： 作为一枚程序员，Git 当然是日常生活中的必备工具。使用 Git 的方式去管理文档，除了其自身的优越性外，还大大降低了额外的学习成本，非常便捷。 Markdown：Markdown 的优秀之处可以浓缩为一句：“简单通用，让你只需专注于内容创作”。 多种格式输出：可以一键生成静态文件，非常便于静态站点的搭建。 其他：有丰富的插件、支持多语言、组织结构极为清晰等等。 安装 环境：NodeJS(v4.0.0 及以上) 通过 npm 快速安装。gitbook-cli 一个用于在同一系统上安装和使用多个版本的 GitBook 的管理程序。它将自动安装所需版本的 GitBook 来构建一本书。 $ npm install gitbook-cli -g 安装指定版本： $ gitbook fetch 3.2.3 查看当前安装版本： $ gitbook -V 查看已安装版本： $ gitbook -ls 管理 gitbook-cli 和 gitbook 是两个软件 , 通过 gitbook-cli 来管理 gitbook。 列出 gitbook 帮助信息： $ gitbook help 列出 gitbook-cli 帮助信息： $ gitbook --help 初始化文档结构 (根据 SUMMARY.md 文件生成目录结构)： $ gitbook init 生成 HTML 文件： $ gitbook build 本地预览 (会默认在本地运行 HTTP Server 监听 4000 端口，并生成 HTML 文件至 _book/ ）： $ gitbook serve 使用 目录结构： . ├── book.json ##存放站点配置信息，例如:标题、作者、描述、插件、语言、版本、导航等├── README.md ##书籍的简单介绍├── SUMMARY.md ##定义目录结构的文件，文档左侧的目录就是根据这个文件来生成的，是用Markdown语法来定义目录树的父子关系的。├── Glossary.md ##词汇表文件，用于常用存储词汇信息。├── chapter-1/ | └── something.md └── chapter-2/ └── something.md 案例：Summary.md 文件 # Summary ## 介绍 * [Introduction](README.md)## 文档使用手册 * [简单使用三步走](simple_three_step.md) * [Markdown常用语法](markdown_use.md) * [Gitbook详解](gitbook.md) * [安装](gitbook/install.md) * [命令](gitbook/command.md) * [目录结构](gitbook/structure.md) * [常用插件](gitbook/plugin.md) * [book.json样例](gitbook/book_json.md) * [文档设计](design.md) * [架构逻辑](design/framework.md) * [监控及维护](design/monitor_operation.md) 生成的文件目录结构： ├── book.json ├── design │ ├── framework.md │ └── monitor_operation.md ├── design.md ├── gitbook │ ├── book_json.md │ ├── command.md │ ├── install.md │ ├── plugin.md │ └── structure.md ├── gitbook.md ├── GLOSSARY.md ├── markdown_use.md ├── README.md ├── simple_three_step.md └── SUMMARY.md book.json 样例简介： { \"title\": \"Common\", ##标题 \"description\": \"公共文档\", ##简述 \"author\": \"Common\", ##作者 \"language\": \"zh-hans\", ##语言 \"gitbook\": \"3.2.3\", ##版本 \"root\": \".\", \"structure\": { \"readme\": \"README.md\" }, \"links\": { ##左侧导航栏信息\"sidebar\": { \"Home\": \"xxx\" } }, \"plugins\": [ ##-：表示关闭此插件\"-lunr\", \"-search\", \"highlight\", ##语法高亮\"-livereload\", \"-sharing\", \"search-plus\", ##支持中文搜索 \"simple-page-toc\", ##自动生成本页目录结构 \"advanced-emoji\", ##支持emoji表情 \"anchors\", ##Github 风格的锚点样式 \"include-codeblock\", ##插入代码块 \"ace\", ##支持ace \"emphasize\", ##文字加底色 \"katex\", ##数学公式插件 \"splitter\", ##侧边栏宽度可自由调节 \"tbfed-pagefooter\", ##添加脚页 \"expandable-chapters-small\", ##目录可折叠 \"sectionx\", ##页面分块显示 \"local-video\", ##视频插件(Video.js播放) \"anchor-navigation-ex\", ##悬浮导航 \"todo\", ##ToDo显示功能 \"git-author\", ##显示创建、修改记录 \"alerts\", ##不同alerts样式(info, warning, danger,success) \"include-csv\" ##支持展示csv文件 ], \"pluginsConfig\": { \"theme-default\": { \"showLevel\": true}, \"prism\": { \"css\": [ \"prism-themes/themes/prism-base16-ateliersulphurpool.light.css\" ] }, \"include-codeblock\": { \"template\": \"ace\", \"unindent\": true, \"edit\": true}, \"tbfed-pagefooter\": { \"copyright\": \"Copyright © xiaomi.com 2017\", \"modify_label\": \"文档修订时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" }, \"simple-page-toc\": { \"maxDepth\": 3, \"skipFirstH1\": true}, \"anchor-navigation-ex\": { \"showLevel\": false, \"multipleH1\":true, \"multipleH2\":true, \"multipleH3\":true, \"mode\": \"float\", \"float\": { \"showLevelIcon\": true, \"level1Icon\": \"fa fa-hand-o-right\", \"level2Icon\": \"fa fa-hand-o-right\", \"level3Icon\": \"fa fa-hand-o-right\" }, \"pageTop\": { \"showLevelIcon\": true, \"level1Icon\": \"fa fa-hand-o-right\", \"level2Icon\": \"fa fa-hand-o-right\", \"level3Icon\": \"fa fa-hand-o-right\" } }, \"sectionx\": { \"tag\": \"b\" }, \"favicon\": { \"shortcut\": \"favicon.ico\", \"bookmark\": \"favicon.ico\" }, \"git-author\":{ \"position\": \"bottom\", \"createTpl\": \"Created by {user}：{timeStamp}\", \"modifyTpl\": \"Modified by {user}：{timeStamp}\", \"timeStampFormat\": \"YYYY-MM-DD\" }, \"styles\": { \"website\": \"./styles/website.css\" }, \"pluginsConfig\": { \"include-codeblock\": { \"template\": \"ace\", \"unindent\": \"true\", \"theme\": \"monokai\" } } } } 可以在本地运行如下命令来分别生成 pdf, epub, mobi 格式文件 gitbook pdf gitbook epub gitbook mobi GitHub Pages GitHub Pages提供静态网站托管服务。 GitHub 上的每个仓库都可以拥有一个 GitHub Pages，对应的 URL 如下： https://.github.io// GitHub Pages 的静态资源支持下面 3 个来源： master 分支 master 分支的 /docs 目录 gh-pages 分支 执行下面命令，将 _book 目录推送到 GitHub 仓库的 gh-pages 分支。 $ git subtree push --prefix=_book origin gh-pages 或者在生成静态网页时，将保存的目录指定为 ./docs $ gitbook build ./ ./docs 然后直接推送到 GitHub 仓库的。 $ git push origin master Copyright © heyaguang.com 2019 all right reserved，powered by Gitbook文档修订时间： 2019-06-22 18:36:19 "}}